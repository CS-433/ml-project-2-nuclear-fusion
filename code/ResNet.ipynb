{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/Kaan-wq/ml_tokamak/blob/main/NN_general.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wnJP6X6bVhZQ",
    "outputId": "30fb24eb-636d-4f95-f7c5-402321f67a15"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.patches as mpatches\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "from typing import Iterable\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "from scipy.fft import fft, ifft\n",
    "from statsmodels.tsa.stattools import acf, pacf\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import keras\n",
    "import keras_tuner as kt\n",
    "from kerastuner import RandomSearch\n",
    "import tensorflow_addons as tfa\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import regularizers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#**I - Preprocessing of the data**\n",
    "\n",
    "Below is the preprocessing pipeline of the data. \\\\\n",
    "Essentially, we feature engineer a few columns, normalize the data and finally, we split it into a training and testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "louv_dDDVk0h"
   },
   "outputs": [],
   "source": [
    "# load dataset using pickle\n",
    "import pickle\n",
    "with open(\"../data/dataset_disruption_characterization.pickle\", \"rb\") as f:\n",
    "    dataset = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ME0mg-qbzWRC"
   },
   "source": [
    "Here we load the data from the drive and put it into a more practical **data structure**. \\\\\n",
    "We add a column <code>['IPE']</code> which represents the current difference between the reference and actual currents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 504
    },
    "id": "xhsprZ_wi8-9",
    "outputId": "02ca27a5-c7ee-46b8-b5b2-6f7abc478f1f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IPLA</th>\n",
       "      <th>IPref</th>\n",
       "      <th>ECEcore</th>\n",
       "      <th>SSXcore</th>\n",
       "      <th>LI</th>\n",
       "      <th>Q95</th>\n",
       "      <th>ZMAG</th>\n",
       "      <th>Vloop</th>\n",
       "      <th>IPE</th>\n",
       "      <th>IPLA_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>Vloop_der</th>\n",
       "      <th>Vloop_der2</th>\n",
       "      <th>Vloop_acf</th>\n",
       "      <th>Vloop_pacf</th>\n",
       "      <th>Time</th>\n",
       "      <th>Frame</th>\n",
       "      <th>Event</th>\n",
       "      <th>Label</th>\n",
       "      <th>Shot</th>\n",
       "      <th>Window</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1989456.750</td>\n",
       "      <td>1999500.0</td>\n",
       "      <td>1740.929077</td>\n",
       "      <td>0.008850</td>\n",
       "      <td>1.191489</td>\n",
       "      <td>3.874169</td>\n",
       "      <td>0.30388</td>\n",
       "      <td>-0.519496</td>\n",
       "      <td>10043.250</td>\n",
       "      <td>1989371.00</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.238922</td>\n",
       "      <td>-0.019993</td>\n",
       "      <td>0.034098</td>\n",
       "      <td>-0.074084</td>\n",
       "      <td>10.361</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>81206</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1989606.250</td>\n",
       "      <td>1999500.0</td>\n",
       "      <td>1744.737427</td>\n",
       "      <td>0.008850</td>\n",
       "      <td>1.191489</td>\n",
       "      <td>3.874169</td>\n",
       "      <td>0.30388</td>\n",
       "      <td>-0.758418</td>\n",
       "      <td>9893.750</td>\n",
       "      <td>1989371.00</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.258915</td>\n",
       "      <td>0.119461</td>\n",
       "      <td>0.034098</td>\n",
       "      <td>-0.074084</td>\n",
       "      <td>10.362</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>81206</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1988484.000</td>\n",
       "      <td>1999500.0</td>\n",
       "      <td>1756.823730</td>\n",
       "      <td>0.008698</td>\n",
       "      <td>1.191489</td>\n",
       "      <td>3.874169</td>\n",
       "      <td>0.30388</td>\n",
       "      <td>-1.037327</td>\n",
       "      <td>11016.000</td>\n",
       "      <td>1989371.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.448103</td>\n",
       "      <td>0.034098</td>\n",
       "      <td>-0.074084</td>\n",
       "      <td>10.363</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>81206</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1989329.625</td>\n",
       "      <td>1999500.0</td>\n",
       "      <td>1756.823730</td>\n",
       "      <td>0.008469</td>\n",
       "      <td>1.191489</td>\n",
       "      <td>3.874169</td>\n",
       "      <td>0.30388</td>\n",
       "      <td>-0.758418</td>\n",
       "      <td>10170.375</td>\n",
       "      <td>1989371.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.637292</td>\n",
       "      <td>-0.159448</td>\n",
       "      <td>0.034098</td>\n",
       "      <td>-0.074084</td>\n",
       "      <td>10.364</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>81206</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1990532.250</td>\n",
       "      <td>1999500.0</td>\n",
       "      <td>1746.057251</td>\n",
       "      <td>0.008850</td>\n",
       "      <td>1.191489</td>\n",
       "      <td>3.874169</td>\n",
       "      <td>0.30388</td>\n",
       "      <td>0.237256</td>\n",
       "      <td>8967.750</td>\n",
       "      <td>1989371.00</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.318896</td>\n",
       "      <td>-0.537741</td>\n",
       "      <td>0.034098</td>\n",
       "      <td>-0.074084</td>\n",
       "      <td>10.365</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>81206</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17975</th>\n",
       "      <td>3993662.500</td>\n",
       "      <td>4000500.0</td>\n",
       "      <td>6282.263672</td>\n",
       "      <td>1.416517</td>\n",
       "      <td>0.808256</td>\n",
       "      <td>2.898196</td>\n",
       "      <td>0.32961</td>\n",
       "      <td>-0.316564</td>\n",
       "      <td>6837.500</td>\n",
       "      <td>3996622.75</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.138622</td>\n",
       "      <td>0.138705</td>\n",
       "      <td>0.039632</td>\n",
       "      <td>0.056425</td>\n",
       "      <td>8.622</td>\n",
       "      <td>15</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>98005</td>\n",
       "      <td>905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17976</th>\n",
       "      <td>3995614.250</td>\n",
       "      <td>4000500.0</td>\n",
       "      <td>6303.055664</td>\n",
       "      <td>1.410871</td>\n",
       "      <td>0.808256</td>\n",
       "      <td>2.898196</td>\n",
       "      <td>0.32961</td>\n",
       "      <td>-0.237256</td>\n",
       "      <td>4885.750</td>\n",
       "      <td>3996622.75</td>\n",
       "      <td>...</td>\n",
       "      <td>0.038821</td>\n",
       "      <td>0.198435</td>\n",
       "      <td>0.039632</td>\n",
       "      <td>0.056425</td>\n",
       "      <td>8.623</td>\n",
       "      <td>16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>98005</td>\n",
       "      <td>905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17977</th>\n",
       "      <td>3994348.000</td>\n",
       "      <td>4000500.0</td>\n",
       "      <td>6277.216309</td>\n",
       "      <td>1.402783</td>\n",
       "      <td>0.808256</td>\n",
       "      <td>2.898196</td>\n",
       "      <td>0.32961</td>\n",
       "      <td>-0.238922</td>\n",
       "      <td>6152.000</td>\n",
       "      <td>3996622.75</td>\n",
       "      <td>...</td>\n",
       "      <td>0.258249</td>\n",
       "      <td>0.000416</td>\n",
       "      <td>0.039632</td>\n",
       "      <td>0.056425</td>\n",
       "      <td>8.624</td>\n",
       "      <td>17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>98005</td>\n",
       "      <td>905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17978</th>\n",
       "      <td>3997734.500</td>\n",
       "      <td>4000500.0</td>\n",
       "      <td>6286.124512</td>\n",
       "      <td>1.391034</td>\n",
       "      <td>0.808256</td>\n",
       "      <td>2.898196</td>\n",
       "      <td>0.32961</td>\n",
       "      <td>0.279242</td>\n",
       "      <td>2765.500</td>\n",
       "      <td>3996622.75</td>\n",
       "      <td>...</td>\n",
       "      <td>0.039654</td>\n",
       "      <td>-0.348553</td>\n",
       "      <td>0.039632</td>\n",
       "      <td>0.056425</td>\n",
       "      <td>8.625</td>\n",
       "      <td>18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>98005</td>\n",
       "      <td>905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17979</th>\n",
       "      <td>3995231.500</td>\n",
       "      <td>4000500.0</td>\n",
       "      <td>6317.835449</td>\n",
       "      <td>1.415449</td>\n",
       "      <td>0.808256</td>\n",
       "      <td>2.898196</td>\n",
       "      <td>0.32961</td>\n",
       "      <td>-0.159614</td>\n",
       "      <td>5268.500</td>\n",
       "      <td>3996622.75</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.438856</td>\n",
       "      <td>-0.478510</td>\n",
       "      <td>0.039632</td>\n",
       "      <td>0.056425</td>\n",
       "      <td>8.626</td>\n",
       "      <td>19</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>98005</td>\n",
       "      <td>905</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17980 rows Ã— 132 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              IPLA      IPref      ECEcore   SSXcore        LI       Q95  \\\n",
       "0      1989456.750  1999500.0  1740.929077  0.008850  1.191489  3.874169   \n",
       "1      1989606.250  1999500.0  1744.737427  0.008850  1.191489  3.874169   \n",
       "2      1988484.000  1999500.0  1756.823730  0.008698  1.191489  3.874169   \n",
       "3      1989329.625  1999500.0  1756.823730  0.008469  1.191489  3.874169   \n",
       "4      1990532.250  1999500.0  1746.057251  0.008850  1.191489  3.874169   \n",
       "...            ...        ...          ...       ...       ...       ...   \n",
       "17975  3993662.500  4000500.0  6282.263672  1.416517  0.808256  2.898196   \n",
       "17976  3995614.250  4000500.0  6303.055664  1.410871  0.808256  2.898196   \n",
       "17977  3994348.000  4000500.0  6277.216309  1.402783  0.808256  2.898196   \n",
       "17978  3997734.500  4000500.0  6286.124512  1.391034  0.808256  2.898196   \n",
       "17979  3995231.500  4000500.0  6317.835449  1.415449  0.808256  2.898196   \n",
       "\n",
       "          ZMAG     Vloop        IPE   IPLA_mean  ...  Vloop_der  Vloop_der2  \\\n",
       "0      0.30388 -0.519496  10043.250  1989371.00  ...  -0.238922   -0.019993   \n",
       "1      0.30388 -0.758418   9893.750  1989371.00  ...  -0.258915    0.119461   \n",
       "2      0.30388 -1.037327  11016.000  1989371.00  ...   0.000000    0.448103   \n",
       "3      0.30388 -0.758418  10170.375  1989371.00  ...   0.637292   -0.159448   \n",
       "4      0.30388  0.237256   8967.750  1989371.00  ...  -0.318896   -0.537741   \n",
       "...        ...       ...        ...         ...  ...        ...         ...   \n",
       "17975  0.32961 -0.316564   6837.500  3996622.75  ...  -0.138622    0.138705   \n",
       "17976  0.32961 -0.237256   4885.750  3996622.75  ...   0.038821    0.198435   \n",
       "17977  0.32961 -0.238922   6152.000  3996622.75  ...   0.258249    0.000416   \n",
       "17978  0.32961  0.279242   2765.500  3996622.75  ...   0.039654   -0.348553   \n",
       "17979  0.32961 -0.159614   5268.500  3996622.75  ...  -0.438856   -0.478510   \n",
       "\n",
       "       Vloop_acf  Vloop_pacf    Time  Frame  Event  Label   Shot  Window  \n",
       "0       0.034098   -0.074084  10.361      0    0.0      0  81206       0  \n",
       "1       0.034098   -0.074084  10.362      1    0.0      0  81206       0  \n",
       "2       0.034098   -0.074084  10.363      2    0.0      0  81206       0  \n",
       "3       0.034098   -0.074084  10.364      3    0.0      0  81206       0  \n",
       "4       0.034098   -0.074084  10.365      4    0.0      0  81206       0  \n",
       "...          ...         ...     ...    ...    ...    ...    ...     ...  \n",
       "17975   0.039632    0.056425   8.622     15    0.0      0  98005     905  \n",
       "17976   0.039632    0.056425   8.623     16    0.0      0  98005     905  \n",
       "17977   0.039632    0.056425   8.624     17    0.0      0  98005     905  \n",
       "17978   0.039632    0.056425   8.625     18    0.0      0  98005     905  \n",
       "17979   0.039632    0.056425   8.626     19    0.0      0  98005     905  \n",
       "\n",
       "[17980 rows x 132 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels count:\n",
      "Label\n",
      "0    12840\n",
      "1     4140\n",
      "2     1000\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Define columns to perform feature engineering on\n",
    "columns = ['IPLA', 'IPref', 'IPE', 'ECEcore', 'SSXcore', 'LI', 'Q95', 'ZMAG', 'Vloop']\n",
    "\n",
    "# Define the operations to perform on each column\n",
    "operations = {\n",
    "    'mean': np.mean,\n",
    "    'std': np.std,\n",
    "    'var': np.var,\n",
    "    'min': np.min,\n",
    "    'max': np.max,\n",
    "    'median': np.median,\n",
    "    'skew': pd.Series.skew,\n",
    "    'kurt': pd.Series.kurtosis,\n",
    "    'fft_abs': lambda x: np.abs(np.fft.fft(x)),\n",
    "    'der': np.gradient,\n",
    "    'der2': lambda x: np.gradient(np.gradient(x)),\n",
    "    'acf': lambda x: 0 if x.isna().any() or np.isinf(x).any() or x.nunique() <= 1 else acf(x).mean(),\n",
    "    'pacf': lambda x: 0 if x.isna().any() or np.isinf(x).any() or x.nunique() <= 1 else pacf(x).mean()\n",
    "}\n",
    "\n",
    "df_data = pd.DataFrame()\n",
    "\n",
    "# Loop through each entry in the dataset\n",
    "for i, entry in enumerate(dataset):\n",
    "    # Extract data and label from the current entry\n",
    "    d = entry['x']\n",
    "    label = entry['y']\n",
    "    metadata = entry['metadata']\n",
    "    event = metadata['time_event']\n",
    "\n",
    "    # Create a DataFrame for the current entry\n",
    "    df = pd.DataFrame(d['data'], columns=d['columns'])\n",
    "\n",
    "    # Add the IPE column\n",
    "    df['IPE'] = np.abs(df['IPLA'] - df['IPref'])\n",
    "\n",
    "    # Perform feature engineering on each column\n",
    "    new_cols = {}\n",
    "    for col in columns:\n",
    "        for op_name, op_func in operations.items():\n",
    "            new_cols[col + '_' + op_name] = op_func(df[col])\n",
    "\n",
    "    # Create a new DataFrame with the new columns\n",
    "    df_new = pd.DataFrame(new_cols)\n",
    "\n",
    "    # Concatenate the original DataFrame with the new one\n",
    "    df = pd.concat([df, df_new], axis=1)\n",
    "    \n",
    "    # Add the time column\n",
    "    df['Time'] = d['time']\n",
    "\n",
    "    # Add the Frame, Event, Label, Shot and Window columns\n",
    "    df['Frame'] = range(0, 20)\n",
    "    df['Event'] = event if event else 0\n",
    "\n",
    "    if event:\n",
    "        # Find closest points to time_event\n",
    "        differences = np.abs(df['Time'] - event)\n",
    "        closest_indices = np.argsort(differences)[:20]\n",
    "\n",
    "        # Assign labels to closest points\n",
    "        df['Label'] = 0\n",
    "        df.loc[closest_indices, 'Label'] = label\n",
    "    else:\n",
    "        df['Label'] = label\n",
    "\n",
    "    df['Shot'] = metadata['shot']\n",
    "    df['Window'] = i  # Add the window number\n",
    "\n",
    "    contains_nan = df.isna().any().any()\n",
    "\n",
    "    if not contains_nan:\n",
    "        # Append the current DataFrame to the main DataFrame\n",
    "        df_data = pd.concat([df_data, df], ignore_index=True)\n",
    "\n",
    "df_data = df_data.dropna()\n",
    "display(df_data)\n",
    "print(\"Labels count:\")\n",
    "print(f\"{df_data['Label'].value_counts()}\")\n",
    "\n",
    "base_col = df_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a specific shot\n",
    "shot = df_data[df_data['Label'] == 2]['Shot'].unique()[6]\n",
    "\n",
    "print(f\"Shot: {shot}\")\n",
    "\n",
    "# Filter the DataFrame to only include a specific shot\n",
    "df_shot = df_data[df_data['Shot'] == shot]\n",
    "\n",
    "# Filter the DataFrame to only include rows with labels clustered\n",
    "df_label_2 = df_shot[df_shot['Label'] == 2]\n",
    "df_label_1 = df_shot[df_shot['Label'] == 1]\n",
    "df_label_0 = df_shot[df_shot['Label'] == 0]\n",
    "\n",
    "# Select a specific window for each label\n",
    "window_number_2 = df_label_2['Window'].unique()[0] \n",
    "df_window_2 = df_label_2[df_label_2['Window'] == window_number_2]\n",
    "\n",
    "window_number_1 = df_label_1['Window'].unique()[0] \n",
    "df_window_1 = df_label_1[df_label_1['Window'] == window_number_1]\n",
    "\n",
    "window_number_0 = df_label_0['Window'].unique()[0]\n",
    "df_window_0 = df_label_0[df_label_0['Window'] == window_number_0]\n",
    "\n",
    "# Plot each feature across time\n",
    "features = df_data.columns.drop(['Label', 'Window', 'Shot', 'Frame', 'Time', 'Event'])  # Exclude non-feature columns\n",
    "\n",
    "# Print the time of the event\n",
    "print(\"Time of the event for each label is :\")\n",
    "print(f\"Label 2: {df_window_2['Event'].unique()[0]}\")\n",
    "print(f\"Label 1: {df_window_1['Event'].unique()[0]}\")\n",
    "print(f\"Label 0: {df_window_0['Event'].unique()[0]}\")\n",
    "\n",
    "# Create a subplot for each feature\n",
    "fig, axs = plt.subplots(len(features), 3, figsize=(20, 6*len(features)))\n",
    "\n",
    "for i, feature in enumerate(features):\n",
    "    axs[i, 0].plot(df_window_2['Time'], df_window_2[feature], label=f'Label 2')\n",
    "    axs[i, 0].set_title(f'Feature: {feature} over Time for Window: {window_number_2}')\n",
    "    axs[i, 0].set_xlabel('Time')\n",
    "    axs[i, 0].set_ylabel(feature)\n",
    "    axs[i, 0].legend()\n",
    "\n",
    "    axs[i, 1].plot(df_window_1['Time'], df_window_1[feature], label=f'Label 1')\n",
    "    axs[i, 1].set_title(f'Feature: {feature} over Time for Window: {window_number_1}')\n",
    "    axs[i, 1].set_xlabel('Time')\n",
    "    axs[i, 1].set_ylabel(feature)\n",
    "    axs[i, 1].legend()\n",
    "\n",
    "    axs[i, 2].plot(df_window_0['Time'], df_window_0[feature], label=f'Label 0')\n",
    "    axs[i, 2].set_title(f'Feature: {feature} over Time for Window: {window_number_0}')\n",
    "    axs[i, 2].set_xlabel('Time')\n",
    "    axs[i, 2].set_ylabel(feature)\n",
    "    axs[i, 2].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Save the plot in an image file\n",
    "fig.savefig('../data/feature_time.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Label           1.000\n",
       "Vloop_max       0.749\n",
       "Vloop_std       0.716\n",
       "Vloop_kurt      0.675\n",
       "Vloop_skew      0.673\n",
       "                ...  \n",
       "Q95_mean       -0.269\n",
       "Q95_max        -0.275\n",
       "ECEcore_min    -0.295\n",
       "SSXcore_skew   -0.397\n",
       "ECEcore_skew   -0.454\n",
       "Name: Label, Length: 127, dtype: float64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_disr = df_data[df_data['Label'] != 0].drop(columns=['Window', 'Shot', 'Frame', 'Time', 'Event'])\n",
    "df_disr.corr()['Label'].round(3).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dGguf_6tsM9S",
    "outputId": "52fcd99e-e6f2-43b8-db2f-9eac43f6d709"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['IPLA', 'IPref', 'ECEcore', 'SSXcore', 'LI', 'Q95', 'ZMAG', 'Vloop',\n",
       "       'IPE', 'IPLA_mean',\n",
       "       ...\n",
       "       'Vloop_der', 'Vloop_der2', 'Vloop_acf', 'Vloop_pacf', 'Time', 'Frame',\n",
       "       'Event', 'Label', 'Shot', 'Window'],\n",
       "      dtype='object', length=132)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y6qCEtg82u00"
   },
   "source": [
    "We **normalize and split** into training and test sets before feeding it into our **Neural Network**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g_qkjUMio62W",
    "outputId": "d02726ec-3769-4059-c375-a6cec7dad4ab"
   },
   "outputs": [],
   "source": [
    "# Split 'Shot' values into training and test sets and create DataFrames\n",
    "shot_train, shot_test = train_test_split(df_data['Shot'].unique(), test_size=0.2, random_state=42)\n",
    "train_df = df_data[df_data['Shot'].isin(shot_train)]\n",
    "test_df = df_data[df_data['Shot'].isin(shot_test)]\n",
    "\n",
    "# Group by 'Window' and 'Shot', and reshape the data\n",
    "train_df_grouped = train_df.sort_values(['Shot', 'Window', 'Time']).groupby(['Shot', 'Window'])\n",
    "test_df_grouped = test_df.sort_values(['Shot', 'Window', 'Time']).groupby(['Shot', 'Window'])\n",
    "\n",
    "# Prepare lists to hold sequences\n",
    "X_train_grouped, y_train_grouped = [], []\n",
    "X_test_grouped, y_test_grouped = [], []\n",
    "\n",
    "# Generate sequences for training data\n",
    "for _, group in train_df_grouped:\n",
    "    X_train_grouped.append(group.drop(columns=['Frame', 'Event', 'Label', 'Shot', 'Window']).values)\n",
    "    y_train_grouped.append(group['Label'].values[0])  # Assuming all labels in a group are the same\n",
    "\n",
    "# Generate sequences for testing data\n",
    "for _, group in test_df_grouped:\n",
    "    X_test_grouped.append(group.drop(columns=['Frame', 'Event', 'Label', 'Shot', 'Window']).values)\n",
    "    y_test_grouped.append(group['Label'].values[0])  # Assuming all labels in a group are the same\n",
    "\n",
    "# Convert lists to numpy arrays\n",
    "X_train_grouped = np.array(X_train_grouped)\n",
    "y_train_grouped = np.array(y_train_grouped)\n",
    "X_test_grouped = np.array(X_test_grouped)\n",
    "y_test_grouped = np.array(y_test_grouped)\n",
    "\n",
    "# Normalize the features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train_grouped.reshape(-1, X_train_grouped.shape[-1])).reshape(X_train_grouped.shape)\n",
    "X_test = scaler.transform(X_test_grouped.reshape(-1, X_test_grouped.shape[-1])).reshape(X_test_grouped.shape)\n",
    "\n",
    "# Convert labels to categorical\n",
    "y_train = to_categorical(y_train_grouped)\n",
    "y_test = to_categorical(y_test_grouped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(737, 20, 127)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_Z-zSjmr3ABP"
   },
   "source": [
    "#**II - Model tuning**\n",
    "\n",
    "Here we use the hyperparamter tuner from keras to find the best model architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HngMK-Dgv6VR",
    "outputId": "cf3f47ac-938f-4711-8629-a6266d63c465"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_4 (InputLayer)        [(None, 20, 127)]            0         []                            \n",
      "                                                                                                  \n",
      " conv1d_37 (Conv1D)          (None, 20, 64)               65088     ['input_4[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_27 (Ba  (None, 20, 64)               256       ['conv1d_37[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_27 (Activation)  (None, 20, 64)               0         ['batch_normalization_27[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv1d_38 (Conv1D)          (None, 20, 64)               32832     ['activation_27[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_28 (Ba  (None, 20, 64)               256       ['conv1d_38[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_28 (Activation)  (None, 20, 64)               0         ['batch_normalization_28[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv1d_39 (Conv1D)          (None, 20, 64)               32832     ['activation_28[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_29 (Ba  (None, 20, 64)               256       ['conv1d_39[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_29 (Activation)  (None, 20, 64)               0         ['batch_normalization_29[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv1d_36 (Conv1D)          (None, 20, 64)               8192      ['input_4[0][0]']             \n",
      "                                                                                                  \n",
      " add_9 (Add)                 (None, 20, 64)               0         ['activation_29[0][0]',       \n",
      "                                                                     'conv1d_36[0][0]']           \n",
      "                                                                                                  \n",
      " conv1d_41 (Conv1D)          (None, 20, 64)               20544     ['add_9[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_30 (Ba  (None, 20, 64)               256       ['conv1d_41[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_30 (Activation)  (None, 20, 64)               0         ['batch_normalization_30[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv1d_42 (Conv1D)          (None, 20, 64)               20544     ['activation_30[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_31 (Ba  (None, 20, 64)               256       ['conv1d_42[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_31 (Activation)  (None, 20, 64)               0         ['batch_normalization_31[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv1d_43 (Conv1D)          (None, 20, 64)               20544     ['activation_31[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_32 (Ba  (None, 20, 64)               256       ['conv1d_43[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_32 (Activation)  (None, 20, 64)               0         ['batch_normalization_32[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv1d_40 (Conv1D)          (None, 20, 64)               4160      ['add_9[0][0]']               \n",
      "                                                                                                  \n",
      " add_10 (Add)                (None, 20, 64)               0         ['activation_32[0][0]',       \n",
      "                                                                     'conv1d_40[0][0]']           \n",
      "                                                                                                  \n",
      " conv1d_45 (Conv1D)          (None, 20, 64)               12352     ['add_10[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_33 (Ba  (None, 20, 64)               256       ['conv1d_45[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_33 (Activation)  (None, 20, 64)               0         ['batch_normalization_33[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv1d_46 (Conv1D)          (None, 20, 64)               12352     ['activation_33[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_34 (Ba  (None, 20, 64)               256       ['conv1d_46[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_34 (Activation)  (None, 20, 64)               0         ['batch_normalization_34[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv1d_47 (Conv1D)          (None, 20, 64)               12352     ['activation_34[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_35 (Ba  (None, 20, 64)               256       ['conv1d_47[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_35 (Activation)  (None, 20, 64)               0         ['batch_normalization_35[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv1d_44 (Conv1D)          (None, 20, 64)               4160      ['add_10[0][0]']              \n",
      "                                                                                                  \n",
      " add_11 (Add)                (None, 20, 64)               0         ['activation_35[0][0]',       \n",
      "                                                                     'conv1d_44[0][0]']           \n",
      "                                                                                                  \n",
      " global_average_pooling1d_3  (None, 64)                   0         ['add_11[0][0]']              \n",
      "  (GlobalAveragePooling1D)                                                                        \n",
      "                                                                                                  \n",
      " dense_3 (Dense)             (None, 3)                    195       ['global_average_pooling1d_3[0\n",
      "                                                                    ][0]']                        \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 248451 (970.51 KB)\n",
      "Trainable params: 247299 (966.01 KB)\n",
      "Non-trainable params: 1152 (4.50 KB)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv1D, BatchNormalization, Activation, Add, GlobalAveragePooling1D, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Function for creating a residual block\n",
    "def residual_block(x, filters, kernel_size):\n",
    "    # Save the input value. Apply a 1x1 convolution to match the number of channels.\n",
    "    residual = Conv1D(filters, 1, padding='same')(x)\n",
    "\n",
    "    # Convolution, batch normalization, and ReLU activation (repeated three times)\n",
    "    for _ in range(3):\n",
    "        x = Conv1D(filters, kernel_size, padding='same')(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Activation('relu')(x)\n",
    "\n",
    "    # Add the residual (input) to the output\n",
    "    x = Add()([x, residual])\n",
    "\n",
    "    return x\n",
    "\n",
    "# Input shape: (timesteps, features)\n",
    "input_shape = (20, 127)\n",
    "\n",
    "# Input layer\n",
    "input_layer = Input(shape=input_shape)\n",
    "\n",
    "# Create three residual blocks with varying kernel sizes\n",
    "x = residual_block(input_layer, 64, 8)\n",
    "x = residual_block(x, 64, 5)\n",
    "x = residual_block(x, 64, 3)\n",
    "\n",
    "# Global Average Pooling layer\n",
    "x = GlobalAveragePooling1D()(x)\n",
    "\n",
    "# Final softmax classifier\n",
    "output_layer = Dense(3, activation='softmax')(x)\n",
    "\n",
    "# Create the model and compile it\n",
    "model = Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "# Create the optimizer\n",
    "optimizer = Adam(learning_rate=1e-7)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy', tfa.metrics.F1Score(num_classes=3, average=None)])\n",
    "\n",
    "# Print the model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10000\n",
      "24/24 [==============================] - 6s 52ms/step - loss: 2.1367 - accuracy: 0.2646 - f1_score: 0.2609 - val_loss: 1.9465 - val_accuracy: 0.2901 - val_f1_score: 0.2861\n",
      "Epoch 2/10000\n",
      "24/24 [==============================] - 1s 21ms/step - loss: 2.0896 - accuracy: 0.2727 - f1_score: 0.2642 - val_loss: 1.8109 - val_accuracy: 0.3395 - val_f1_score: 0.3115\n",
      "Epoch 3/10000\n",
      "24/24 [==============================] - 1s 28ms/step - loss: 2.0986 - accuracy: 0.2673 - f1_score: 0.2630 - val_loss: 1.7509 - val_accuracy: 0.4012 - val_f1_score: 0.3340\n",
      "Epoch 4/10000\n",
      "24/24 [==============================] - 1s 27ms/step - loss: 2.1321 - accuracy: 0.2700 - f1_score: 0.2626 - val_loss: 1.7217 - val_accuracy: 0.3889 - val_f1_score: 0.3216\n",
      "Epoch 5/10000\n",
      "24/24 [==============================] - 1s 27ms/step - loss: 2.1331 - accuracy: 0.2659 - f1_score: 0.2591 - val_loss: 1.7329 - val_accuracy: 0.3704 - val_f1_score: 0.3112\n",
      "Epoch 6/10000\n",
      "24/24 [==============================] - 1s 23ms/step - loss: 2.1136 - accuracy: 0.2592 - f1_score: 0.2588 - val_loss: 1.7496 - val_accuracy: 0.3457 - val_f1_score: 0.2956\n",
      "Epoch 7/10000\n",
      "24/24 [==============================] - 1s 21ms/step - loss: 2.0874 - accuracy: 0.2564 - f1_score: 0.2547 - val_loss: 1.7677 - val_accuracy: 0.3272 - val_f1_score: 0.2887\n",
      "Epoch 8/10000\n",
      "24/24 [==============================] - 1s 32ms/step - loss: 2.1375 - accuracy: 0.2700 - f1_score: 0.2676 - val_loss: 1.7911 - val_accuracy: 0.3086 - val_f1_score: 0.2756\n",
      "Epoch 9/10000\n",
      "24/24 [==============================] - 0s 20ms/step - loss: 2.0926 - accuracy: 0.2619 - f1_score: 0.2560 - val_loss: 1.8155 - val_accuracy: 0.3086 - val_f1_score: 0.2814\n",
      "Epoch 10/10000\n",
      "24/24 [==============================] - 1s 25ms/step - loss: 2.0932 - accuracy: 0.2605 - f1_score: 0.2557 - val_loss: 1.8360 - val_accuracy: 0.3025 - val_f1_score: 0.2803\n",
      "Epoch 11/10000\n",
      "24/24 [==============================] - 1s 24ms/step - loss: 2.0704 - accuracy: 0.2836 - f1_score: 0.2727 - val_loss: 1.8520 - val_accuracy: 0.3025 - val_f1_score: 0.2802\n",
      "Epoch 12/10000\n",
      "24/24 [==============================] - 1s 24ms/step - loss: 2.0787 - accuracy: 0.2578 - f1_score: 0.2536 - val_loss: 1.8666 - val_accuracy: 0.2963 - val_f1_score: 0.2769\n",
      "Epoch 13/10000\n",
      "24/24 [==============================] - 1s 21ms/step - loss: 2.0481 - accuracy: 0.2768 - f1_score: 0.2713 - val_loss: 1.8770 - val_accuracy: 0.3025 - val_f1_score: 0.2802\n",
      "Epoch 14/10000\n",
      "24/24 [==============================] - 1s 31ms/step - loss: 2.0777 - accuracy: 0.2727 - f1_score: 0.2662 - val_loss: 1.8881 - val_accuracy: 0.3025 - val_f1_score: 0.2802\n",
      "Epoch 15/10000\n",
      "24/24 [==============================] - 1s 22ms/step - loss: 2.0496 - accuracy: 0.2659 - f1_score: 0.2583 - val_loss: 1.8981 - val_accuracy: 0.3025 - val_f1_score: 0.2802\n",
      "Epoch 16/10000\n",
      "24/24 [==============================] - 0s 19ms/step - loss: 2.0659 - accuracy: 0.2836 - f1_score: 0.2789 - val_loss: 1.9054 - val_accuracy: 0.3025 - val_f1_score: 0.2802\n",
      "Epoch 17/10000\n",
      "24/24 [==============================] - 0s 20ms/step - loss: 2.0665 - accuracy: 0.2659 - f1_score: 0.2622 - val_loss: 1.9152 - val_accuracy: 0.3086 - val_f1_score: 0.2854\n",
      "Epoch 18/10000\n",
      "24/24 [==============================] - 0s 20ms/step - loss: 2.0628 - accuracy: 0.2578 - f1_score: 0.2563 - val_loss: 1.9150 - val_accuracy: 0.3272 - val_f1_score: 0.2970\n",
      "Epoch 19/10000\n",
      "24/24 [==============================] - 0s 19ms/step - loss: 2.0690 - accuracy: 0.2578 - f1_score: 0.2512 - val_loss: 1.9200 - val_accuracy: 0.3272 - val_f1_score: 0.2970\n",
      "Epoch 20/10000\n",
      "24/24 [==============================] - 0s 20ms/step - loss: 2.0486 - accuracy: 0.2632 - f1_score: 0.2524 - val_loss: 1.9190 - val_accuracy: 0.3333 - val_f1_score: 0.3022\n",
      "Epoch 21/10000\n",
      "24/24 [==============================] - 0s 19ms/step - loss: 2.0455 - accuracy: 0.2741 - f1_score: 0.2666 - val_loss: 1.9169 - val_accuracy: 0.3333 - val_f1_score: 0.3022\n",
      "Epoch 22/10000\n",
      "24/24 [==============================] - 1s 21ms/step - loss: 2.0647 - accuracy: 0.2714 - f1_score: 0.2631 - val_loss: 1.9177 - val_accuracy: 0.3395 - val_f1_score: 0.3053\n",
      "Epoch 23/10000\n",
      "24/24 [==============================] - 0s 19ms/step - loss: 2.0559 - accuracy: 0.2809 - f1_score: 0.2754 - val_loss: 1.9184 - val_accuracy: 0.3395 - val_f1_score: 0.3053\n",
      "Epoch 24/10000\n",
      "24/24 [==============================] - 0s 20ms/step - loss: 2.0369 - accuracy: 0.2809 - f1_score: 0.2684 - val_loss: 1.9095 - val_accuracy: 0.3333 - val_f1_score: 0.3022\n",
      "Epoch 25/10000\n",
      "24/24 [==============================] - 0s 21ms/step - loss: 2.0424 - accuracy: 0.2768 - f1_score: 0.2659 - val_loss: 1.9065 - val_accuracy: 0.3395 - val_f1_score: 0.3053\n",
      "Epoch 26/10000\n",
      "24/24 [==============================] - 0s 20ms/step - loss: 2.0970 - accuracy: 0.2917 - f1_score: 0.2779 - val_loss: 1.9045 - val_accuracy: 0.3457 - val_f1_score: 0.3083\n",
      "Epoch 27/10000\n",
      "24/24 [==============================] - 0s 19ms/step - loss: 2.0156 - accuracy: 0.2754 - f1_score: 0.2684 - val_loss: 1.9068 - val_accuracy: 0.3395 - val_f1_score: 0.3053\n",
      "Epoch 28/10000\n",
      "24/24 [==============================] - 0s 19ms/step - loss: 2.0078 - accuracy: 0.2754 - f1_score: 0.2726 - val_loss: 1.9069 - val_accuracy: 0.3395 - val_f1_score: 0.3031\n",
      "Epoch 29/10000\n",
      "24/24 [==============================] - 0s 19ms/step - loss: 2.0630 - accuracy: 0.2822 - f1_score: 0.2797 - val_loss: 1.9051 - val_accuracy: 0.3395 - val_f1_score: 0.3031\n",
      "Epoch 30/10000\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 2.0319 - accuracy: 0.2714 - f1_score: 0.2684 - val_loss: 1.9060 - val_accuracy: 0.3333 - val_f1_score: 0.3001\n",
      "Epoch 31/10000\n",
      "24/24 [==============================] - 0s 21ms/step - loss: 2.0303 - accuracy: 0.2768 - f1_score: 0.2695 - val_loss: 1.9070 - val_accuracy: 0.3272 - val_f1_score: 0.2970\n",
      "Epoch 32/10000\n",
      "24/24 [==============================] - 0s 20ms/step - loss: 2.0192 - accuracy: 0.2822 - f1_score: 0.2757 - val_loss: 1.9051 - val_accuracy: 0.3272 - val_f1_score: 0.2970\n",
      "Epoch 33/10000\n",
      "24/24 [==============================] - 0s 20ms/step - loss: 2.0595 - accuracy: 0.2877 - f1_score: 0.2841 - val_loss: 1.9005 - val_accuracy: 0.3333 - val_f1_score: 0.3001\n",
      "Epoch 34/10000\n",
      "24/24 [==============================] - 1s 27ms/step - loss: 1.9902 - accuracy: 0.2849 - f1_score: 0.2769 - val_loss: 1.8944 - val_accuracy: 0.3333 - val_f1_score: 0.3001\n",
      "Epoch 35/10000\n",
      "24/24 [==============================] - 1s 28ms/step - loss: 2.0429 - accuracy: 0.2795 - f1_score: 0.2713 - val_loss: 1.8933 - val_accuracy: 0.3333 - val_f1_score: 0.3001\n",
      "Epoch 36/10000\n",
      "24/24 [==============================] - 0s 21ms/step - loss: 2.0326 - accuracy: 0.2782 - f1_score: 0.2713 - val_loss: 1.8908 - val_accuracy: 0.3457 - val_f1_score: 0.3105\n",
      "Epoch 37/10000\n",
      "24/24 [==============================] - 0s 21ms/step - loss: 2.0065 - accuracy: 0.2863 - f1_score: 0.2786 - val_loss: 1.8912 - val_accuracy: 0.3395 - val_f1_score: 0.3053\n",
      "Epoch 38/10000\n",
      "24/24 [==============================] - 0s 21ms/step - loss: 2.0124 - accuracy: 0.2958 - f1_score: 0.2886 - val_loss: 1.8865 - val_accuracy: 0.3457 - val_f1_score: 0.3105\n",
      "Epoch 39/10000\n",
      "24/24 [==============================] - 0s 19ms/step - loss: 2.0058 - accuracy: 0.2877 - f1_score: 0.2787 - val_loss: 1.8867 - val_accuracy: 0.3333 - val_f1_score: 0.3022\n",
      "Epoch 40/10000\n",
      "24/24 [==============================] - 0s 20ms/step - loss: 2.0026 - accuracy: 0.2849 - f1_score: 0.2774 - val_loss: 1.8849 - val_accuracy: 0.3272 - val_f1_score: 0.2970\n",
      "Epoch 41/10000\n",
      "24/24 [==============================] - 0s 19ms/step - loss: 2.0561 - accuracy: 0.2849 - f1_score: 0.2817 - val_loss: 1.8823 - val_accuracy: 0.3395 - val_f1_score: 0.3075\n",
      "Epoch 42/10000\n",
      "24/24 [==============================] - 0s 21ms/step - loss: 2.0009 - accuracy: 0.2795 - f1_score: 0.2759 - val_loss: 1.8799 - val_accuracy: 0.3395 - val_f1_score: 0.3075\n",
      "Epoch 43/10000\n",
      "24/24 [==============================] - 0s 21ms/step - loss: 1.9834 - accuracy: 0.2904 - f1_score: 0.2805 - val_loss: 1.8762 - val_accuracy: 0.3519 - val_f1_score: 0.3136\n",
      "Epoch 44/10000\n",
      "24/24 [==============================] - 1s 21ms/step - loss: 1.9679 - accuracy: 0.2877 - f1_score: 0.2775 - val_loss: 1.8730 - val_accuracy: 0.3457 - val_f1_score: 0.3083\n",
      "Epoch 45/10000\n",
      "24/24 [==============================] - 0s 20ms/step - loss: 1.9862 - accuracy: 0.2863 - f1_score: 0.2753 - val_loss: 1.8774 - val_accuracy: 0.3519 - val_f1_score: 0.3136\n",
      "Epoch 46/10000\n",
      "24/24 [==============================] - 0s 20ms/step - loss: 1.9943 - accuracy: 0.2809 - f1_score: 0.2698 - val_loss: 1.8732 - val_accuracy: 0.3333 - val_f1_score: 0.3001\n",
      "Epoch 47/10000\n",
      "24/24 [==============================] - 0s 20ms/step - loss: 1.9682 - accuracy: 0.2890 - f1_score: 0.2793 - val_loss: 1.8713 - val_accuracy: 0.3395 - val_f1_score: 0.3031\n",
      "Epoch 48/10000\n",
      "24/24 [==============================] - 0s 21ms/step - loss: 1.9568 - accuracy: 0.2890 - f1_score: 0.2784 - val_loss: 1.8692 - val_accuracy: 0.3457 - val_f1_score: 0.3126\n",
      "Epoch 49/10000\n",
      "24/24 [==============================] - 0s 19ms/step - loss: 1.9686 - accuracy: 0.3012 - f1_score: 0.2859 - val_loss: 1.8676 - val_accuracy: 0.3519 - val_f1_score: 0.3156\n",
      "Epoch 50/10000\n",
      "24/24 [==============================] - 0s 19ms/step - loss: 1.9449 - accuracy: 0.2944 - f1_score: 0.2797 - val_loss: 1.8713 - val_accuracy: 0.3457 - val_f1_score: 0.3062\n",
      "Epoch 51/10000\n",
      "24/24 [==============================] - 0s 20ms/step - loss: 1.9578 - accuracy: 0.2944 - f1_score: 0.2881 - val_loss: 1.8648 - val_accuracy: 0.3519 - val_f1_score: 0.3136\n",
      "Epoch 52/10000\n",
      "24/24 [==============================] - 0s 21ms/step - loss: 1.9632 - accuracy: 0.2659 - f1_score: 0.2619 - val_loss: 1.8639 - val_accuracy: 0.3457 - val_f1_score: 0.3062\n",
      "Epoch 53/10000\n",
      "24/24 [==============================] - 0s 20ms/step - loss: 1.9630 - accuracy: 0.3053 - f1_score: 0.2911 - val_loss: 1.8624 - val_accuracy: 0.3457 - val_f1_score: 0.3104\n",
      "Epoch 54/10000\n",
      "24/24 [==============================] - 0s 19ms/step - loss: 1.9682 - accuracy: 0.2768 - f1_score: 0.2727 - val_loss: 1.8608 - val_accuracy: 0.3580 - val_f1_score: 0.3186\n",
      "Epoch 55/10000\n",
      "24/24 [==============================] - 0s 19ms/step - loss: 1.9328 - accuracy: 0.2822 - f1_score: 0.2710 - val_loss: 1.8520 - val_accuracy: 0.3580 - val_f1_score: 0.3186\n",
      "Epoch 56/10000\n",
      "24/24 [==============================] - 1s 20ms/step - loss: 1.9655 - accuracy: 0.2917 - f1_score: 0.2863 - val_loss: 1.8381 - val_accuracy: 0.3704 - val_f1_score: 0.3268\n",
      "Epoch 57/10000\n",
      "24/24 [==============================] - 0s 19ms/step - loss: 1.9435 - accuracy: 0.2917 - f1_score: 0.2809 - val_loss: 1.8374 - val_accuracy: 0.3642 - val_f1_score: 0.3239\n",
      "Epoch 58/10000\n",
      "24/24 [==============================] - 0s 20ms/step - loss: 1.9510 - accuracy: 0.2985 - f1_score: 0.2879 - val_loss: 1.8381 - val_accuracy: 0.3642 - val_f1_score: 0.3239\n",
      "Epoch 59/10000\n",
      "24/24 [==============================] - 0s 19ms/step - loss: 1.9591 - accuracy: 0.3012 - f1_score: 0.2873 - val_loss: 1.8390 - val_accuracy: 0.3580 - val_f1_score: 0.3186\n",
      "Epoch 60/10000\n",
      "24/24 [==============================] - 0s 20ms/step - loss: 1.9621 - accuracy: 0.2863 - f1_score: 0.2767 - val_loss: 1.8333 - val_accuracy: 0.3704 - val_f1_score: 0.3268\n",
      "Epoch 61/10000\n",
      "24/24 [==============================] - 0s 21ms/step - loss: 1.9552 - accuracy: 0.2836 - f1_score: 0.2763 - val_loss: 1.8325 - val_accuracy: 0.3704 - val_f1_score: 0.3268\n",
      "Epoch 62/10000\n",
      "24/24 [==============================] - 1s 30ms/step - loss: 1.9480 - accuracy: 0.2999 - f1_score: 0.2915 - val_loss: 1.8342 - val_accuracy: 0.3704 - val_f1_score: 0.3268\n",
      "Epoch 63/10000\n",
      "24/24 [==============================] - 1s 25ms/step - loss: 1.9111 - accuracy: 0.3080 - f1_score: 0.3002 - val_loss: 1.8310 - val_accuracy: 0.3642 - val_f1_score: 0.3239\n",
      "Epoch 64/10000\n",
      "24/24 [==============================] - 0s 20ms/step - loss: 1.9136 - accuracy: 0.2931 - f1_score: 0.2826 - val_loss: 1.8300 - val_accuracy: 0.3704 - val_f1_score: 0.3268\n",
      "Epoch 65/10000\n",
      "24/24 [==============================] - 0s 20ms/step - loss: 1.9393 - accuracy: 0.3202 - f1_score: 0.3052 - val_loss: 1.8285 - val_accuracy: 0.3704 - val_f1_score: 0.3268\n",
      "Epoch 66/10000\n",
      "24/24 [==============================] - 0s 21ms/step - loss: 1.8882 - accuracy: 0.3161 - f1_score: 0.3015 - val_loss: 1.8290 - val_accuracy: 0.3704 - val_f1_score: 0.3268\n",
      "Epoch 67/10000\n",
      "24/24 [==============================] - 1s 32ms/step - loss: 1.9448 - accuracy: 0.2958 - f1_score: 0.2883 - val_loss: 1.8265 - val_accuracy: 0.3704 - val_f1_score: 0.3268\n",
      "Epoch 68/10000\n",
      "24/24 [==============================] - 1s 23ms/step - loss: 1.9104 - accuracy: 0.3053 - f1_score: 0.2908 - val_loss: 1.8206 - val_accuracy: 0.3642 - val_f1_score: 0.3216\n",
      "Epoch 69/10000\n",
      "24/24 [==============================] - 1s 23ms/step - loss: 1.9020 - accuracy: 0.2931 - f1_score: 0.2813 - val_loss: 1.8137 - val_accuracy: 0.3704 - val_f1_score: 0.3268\n",
      "Epoch 70/10000\n",
      "24/24 [==============================] - 0s 20ms/step - loss: 1.8736 - accuracy: 0.3297 - f1_score: 0.3153 - val_loss: 1.8108 - val_accuracy: 0.3642 - val_f1_score: 0.3216\n",
      "Epoch 71/10000\n",
      "24/24 [==============================] - 1s 30ms/step - loss: 1.9152 - accuracy: 0.3107 - f1_score: 0.2980 - val_loss: 1.8101 - val_accuracy: 0.3704 - val_f1_score: 0.3268\n",
      "Epoch 72/10000\n",
      "24/24 [==============================] - 1s 23ms/step - loss: 1.9133 - accuracy: 0.2931 - f1_score: 0.2866 - val_loss: 1.8133 - val_accuracy: 0.3704 - val_f1_score: 0.3268\n",
      "Epoch 73/10000\n",
      "24/24 [==============================] - 1s 24ms/step - loss: 1.8682 - accuracy: 0.3270 - f1_score: 0.3142 - val_loss: 1.8047 - val_accuracy: 0.3704 - val_f1_score: 0.3268\n",
      "Epoch 74/10000\n",
      "24/24 [==============================] - 0s 20ms/step - loss: 1.9036 - accuracy: 0.3121 - f1_score: 0.2991 - val_loss: 1.7929 - val_accuracy: 0.3704 - val_f1_score: 0.3268\n",
      "Epoch 75/10000\n",
      "24/24 [==============================] - 1s 25ms/step - loss: 1.8888 - accuracy: 0.3175 - f1_score: 0.3062 - val_loss: 1.7937 - val_accuracy: 0.3704 - val_f1_score: 0.3268\n",
      "Epoch 76/10000\n",
      "24/24 [==============================] - 1s 23ms/step - loss: 1.8884 - accuracy: 0.3134 - f1_score: 0.3016 - val_loss: 1.7905 - val_accuracy: 0.3704 - val_f1_score: 0.3268\n",
      "Epoch 77/10000\n",
      "24/24 [==============================] - 1s 23ms/step - loss: 1.8676 - accuracy: 0.3148 - f1_score: 0.2979 - val_loss: 1.7884 - val_accuracy: 0.3704 - val_f1_score: 0.3268\n",
      "Epoch 78/10000\n",
      "24/24 [==============================] - 0s 20ms/step - loss: 1.8876 - accuracy: 0.3107 - f1_score: 0.2984 - val_loss: 1.7903 - val_accuracy: 0.3704 - val_f1_score: 0.3268\n",
      "Epoch 79/10000\n",
      "24/24 [==============================] - 1s 23ms/step - loss: 1.8990 - accuracy: 0.3080 - f1_score: 0.2969 - val_loss: 1.7952 - val_accuracy: 0.3704 - val_f1_score: 0.3268\n",
      "Epoch 80/10000\n",
      "24/24 [==============================] - 0s 20ms/step - loss: 1.8823 - accuracy: 0.3012 - f1_score: 0.2959 - val_loss: 1.7908 - val_accuracy: 0.3704 - val_f1_score: 0.3268\n",
      "Epoch 81/10000\n",
      "24/24 [==============================] - 0s 20ms/step - loss: 1.9044 - accuracy: 0.3026 - f1_score: 0.2903 - val_loss: 1.7875 - val_accuracy: 0.3704 - val_f1_score: 0.3268\n",
      "Epoch 82/10000\n",
      "24/24 [==============================] - 0s 20ms/step - loss: 1.8909 - accuracy: 0.3066 - f1_score: 0.2950 - val_loss: 1.7812 - val_accuracy: 0.3704 - val_f1_score: 0.3268\n",
      "Epoch 83/10000\n",
      "24/24 [==============================] - 0s 20ms/step - loss: 1.8718 - accuracy: 0.2985 - f1_score: 0.2915 - val_loss: 1.7847 - val_accuracy: 0.3704 - val_f1_score: 0.3268\n",
      "Epoch 84/10000\n",
      "24/24 [==============================] - 0s 21ms/step - loss: 1.8813 - accuracy: 0.3080 - f1_score: 0.2992 - val_loss: 1.7787 - val_accuracy: 0.3765 - val_f1_score: 0.3298\n",
      "Epoch 85/10000\n",
      "24/24 [==============================] - 0s 20ms/step - loss: 1.8382 - accuracy: 0.3256 - f1_score: 0.3076 - val_loss: 1.7719 - val_accuracy: 0.3765 - val_f1_score: 0.3298\n",
      "Epoch 86/10000\n",
      "24/24 [==============================] - 0s 19ms/step - loss: 1.8802 - accuracy: 0.3161 - f1_score: 0.3021 - val_loss: 1.7762 - val_accuracy: 0.3704 - val_f1_score: 0.3268\n",
      "Epoch 87/10000\n",
      "24/24 [==============================] - 0s 19ms/step - loss: 1.8855 - accuracy: 0.3053 - f1_score: 0.2901 - val_loss: 1.7781 - val_accuracy: 0.3704 - val_f1_score: 0.3268\n",
      "Epoch 88/10000\n",
      "24/24 [==============================] - 0s 19ms/step - loss: 1.8628 - accuracy: 0.3148 - f1_score: 0.3041 - val_loss: 1.7823 - val_accuracy: 0.3704 - val_f1_score: 0.3268\n",
      "Epoch 89/10000\n",
      "24/24 [==============================] - 0s 21ms/step - loss: 1.8592 - accuracy: 0.3243 - f1_score: 0.3007 - val_loss: 1.7784 - val_accuracy: 0.3765 - val_f1_score: 0.3298\n",
      "Epoch 90/10000\n",
      "24/24 [==============================] - 0s 19ms/step - loss: 1.8702 - accuracy: 0.3256 - f1_score: 0.3151 - val_loss: 1.7753 - val_accuracy: 0.3765 - val_f1_score: 0.3298\n",
      "Epoch 91/10000\n",
      "24/24 [==============================] - 0s 20ms/step - loss: 1.8710 - accuracy: 0.3080 - f1_score: 0.2979 - val_loss: 1.7666 - val_accuracy: 0.3765 - val_f1_score: 0.3298\n",
      "Epoch 92/10000\n",
      "24/24 [==============================] - 0s 19ms/step - loss: 1.8886 - accuracy: 0.3175 - f1_score: 0.3047 - val_loss: 1.7582 - val_accuracy: 0.3765 - val_f1_score: 0.3298\n",
      "Epoch 93/10000\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 1.8430 - accuracy: 0.3175 - f1_score: 0.3036 - val_loss: 1.7631 - val_accuracy: 0.3704 - val_f1_score: 0.3268\n",
      "Epoch 94/10000\n",
      "24/24 [==============================] - 0s 20ms/step - loss: 1.8891 - accuracy: 0.3066 - f1_score: 0.2967 - val_loss: 1.7607 - val_accuracy: 0.3704 - val_f1_score: 0.3268\n",
      "Epoch 95/10000\n",
      "24/24 [==============================] - 0s 19ms/step - loss: 1.8684 - accuracy: 0.3189 - f1_score: 0.3030 - val_loss: 1.7541 - val_accuracy: 0.3704 - val_f1_score: 0.3268\n",
      "Epoch 96/10000\n",
      "24/24 [==============================] - 0s 20ms/step - loss: 1.8369 - accuracy: 0.3148 - f1_score: 0.3024 - val_loss: 1.7537 - val_accuracy: 0.3704 - val_f1_score: 0.3268\n",
      "Epoch 97/10000\n",
      "24/24 [==============================] - 0s 20ms/step - loss: 1.8269 - accuracy: 0.3243 - f1_score: 0.3091 - val_loss: 1.7515 - val_accuracy: 0.3765 - val_f1_score: 0.3321\n",
      "Epoch 98/10000\n",
      "24/24 [==============================] - 0s 19ms/step - loss: 1.8163 - accuracy: 0.3148 - f1_score: 0.3038 - val_loss: 1.7509 - val_accuracy: 0.3704 - val_f1_score: 0.3268\n",
      "Epoch 99/10000\n",
      "24/24 [==============================] - 0s 20ms/step - loss: 1.8223 - accuracy: 0.3148 - f1_score: 0.3009 - val_loss: 1.7492 - val_accuracy: 0.3704 - val_f1_score: 0.3268\n",
      "Epoch 100/10000\n",
      "24/24 [==============================] - 0s 20ms/step - loss: 1.8346 - accuracy: 0.3284 - f1_score: 0.3093 - val_loss: 1.7463 - val_accuracy: 0.3704 - val_f1_score: 0.3268\n",
      "Epoch 101/10000\n",
      "24/24 [==============================] - 0s 19ms/step - loss: 1.8273 - accuracy: 0.3134 - f1_score: 0.3033 - val_loss: 1.7486 - val_accuracy: 0.3704 - val_f1_score: 0.3268\n",
      "Epoch 102/10000\n",
      "24/24 [==============================] - 0s 19ms/step - loss: 1.7955 - accuracy: 0.3270 - f1_score: 0.3116 - val_loss: 1.7492 - val_accuracy: 0.3889 - val_f1_score: 0.3495\n",
      "Epoch 103/10000\n",
      "24/24 [==============================] - 0s 20ms/step - loss: 1.8120 - accuracy: 0.3297 - f1_score: 0.3163 - val_loss: 1.7466 - val_accuracy: 0.3889 - val_f1_score: 0.3495\n",
      "Epoch 104/10000\n",
      "24/24 [==============================] - 1s 21ms/step - loss: 1.8325 - accuracy: 0.3121 - f1_score: 0.2986 - val_loss: 1.7488 - val_accuracy: 0.3889 - val_f1_score: 0.3495\n",
      "Epoch 105/10000\n",
      "24/24 [==============================] - 0s 20ms/step - loss: 1.8200 - accuracy: 0.3284 - f1_score: 0.3156 - val_loss: 1.7416 - val_accuracy: 0.3951 - val_f1_score: 0.3549\n",
      "Epoch 106/10000\n",
      "24/24 [==============================] - 0s 20ms/step - loss: 1.8286 - accuracy: 0.3148 - f1_score: 0.3055 - val_loss: 1.7429 - val_accuracy: 0.3889 - val_f1_score: 0.3495\n",
      "Epoch 107/10000\n",
      "24/24 [==============================] - 0s 20ms/step - loss: 1.7932 - accuracy: 0.3433 - f1_score: 0.3286 - val_loss: 1.7407 - val_accuracy: 0.3951 - val_f1_score: 0.3549\n",
      "Epoch 108/10000\n",
      "24/24 [==============================] - 0s 21ms/step - loss: 1.8023 - accuracy: 0.3229 - f1_score: 0.3095 - val_loss: 1.7345 - val_accuracy: 0.3951 - val_f1_score: 0.3526\n",
      "Epoch 109/10000\n",
      "24/24 [==============================] - 0s 20ms/step - loss: 1.8117 - accuracy: 0.3229 - f1_score: 0.3061 - val_loss: 1.7312 - val_accuracy: 0.4012 - val_f1_score: 0.3579\n",
      "Epoch 110/10000\n",
      "24/24 [==============================] - 0s 20ms/step - loss: 1.8105 - accuracy: 0.3202 - f1_score: 0.3056 - val_loss: 1.7356 - val_accuracy: 0.3951 - val_f1_score: 0.3549\n",
      "Epoch 111/10000\n",
      "24/24 [==============================] - 0s 19ms/step - loss: 1.7802 - accuracy: 0.3379 - f1_score: 0.3222 - val_loss: 1.7322 - val_accuracy: 0.3951 - val_f1_score: 0.3549\n",
      "Epoch 112/10000\n",
      "24/24 [==============================] - 0s 20ms/step - loss: 1.8127 - accuracy: 0.3392 - f1_score: 0.3238 - val_loss: 1.7267 - val_accuracy: 0.3951 - val_f1_score: 0.3526\n",
      "Epoch 113/10000\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 1.8131 - accuracy: 0.3256 - f1_score: 0.3114 - val_loss: 1.7256 - val_accuracy: 0.4012 - val_f1_score: 0.3579\n",
      "Epoch 114/10000\n",
      "24/24 [==============================] - 0s 20ms/step - loss: 1.7887 - accuracy: 0.3243 - f1_score: 0.3128 - val_loss: 1.7246 - val_accuracy: 0.4012 - val_f1_score: 0.3579\n",
      "Epoch 115/10000\n",
      "24/24 [==============================] - 0s 20ms/step - loss: 1.8139 - accuracy: 0.3107 - f1_score: 0.2991 - val_loss: 1.7161 - val_accuracy: 0.4012 - val_f1_score: 0.3579\n",
      "Epoch 116/10000\n",
      "24/24 [==============================] - 0s 19ms/step - loss: 1.7932 - accuracy: 0.3324 - f1_score: 0.3181 - val_loss: 1.7177 - val_accuracy: 0.3951 - val_f1_score: 0.3549\n",
      "Epoch 117/10000\n",
      "24/24 [==============================] - 0s 20ms/step - loss: 1.7937 - accuracy: 0.3338 - f1_score: 0.3152 - val_loss: 1.7143 - val_accuracy: 0.3951 - val_f1_score: 0.3549\n",
      "Epoch 118/10000\n",
      "24/24 [==============================] - 0s 19ms/step - loss: 1.7572 - accuracy: 0.3338 - f1_score: 0.3185 - val_loss: 1.7119 - val_accuracy: 0.4074 - val_f1_score: 0.3684\n",
      "Epoch 119/10000\n",
      "24/24 [==============================] - 0s 21ms/step - loss: 1.7606 - accuracy: 0.3446 - f1_score: 0.3270 - val_loss: 1.7117 - val_accuracy: 0.3951 - val_f1_score: 0.3598\n",
      "Epoch 120/10000\n",
      "24/24 [==============================] - 0s 20ms/step - loss: 1.8298 - accuracy: 0.3202 - f1_score: 0.3111 - val_loss: 1.7044 - val_accuracy: 0.4012 - val_f1_score: 0.3579\n",
      "Epoch 121/10000\n",
      "24/24 [==============================] - 0s 20ms/step - loss: 1.7701 - accuracy: 0.3365 - f1_score: 0.3243 - val_loss: 1.7026 - val_accuracy: 0.4074 - val_f1_score: 0.3609\n",
      "Epoch 122/10000\n",
      "24/24 [==============================] - 1s 21ms/step - loss: 1.7534 - accuracy: 0.3446 - f1_score: 0.3270 - val_loss: 1.6998 - val_accuracy: 0.3951 - val_f1_score: 0.3549\n",
      "Epoch 123/10000\n",
      "24/24 [==============================] - 0s 19ms/step - loss: 1.7864 - accuracy: 0.3324 - f1_score: 0.3154 - val_loss: 1.7006 - val_accuracy: 0.3951 - val_f1_score: 0.3549\n",
      "Epoch 124/10000\n",
      "24/24 [==============================] - 1s 21ms/step - loss: 1.7406 - accuracy: 0.3379 - f1_score: 0.3176 - val_loss: 1.6921 - val_accuracy: 0.4074 - val_f1_score: 0.3634\n",
      "Epoch 125/10000\n",
      "24/24 [==============================] - 0s 19ms/step - loss: 1.7739 - accuracy: 0.3216 - f1_score: 0.3060 - val_loss: 1.6888 - val_accuracy: 0.4074 - val_f1_score: 0.3634\n",
      "Epoch 126/10000\n",
      "24/24 [==============================] - 0s 19ms/step - loss: 1.7598 - accuracy: 0.3406 - f1_score: 0.3232 - val_loss: 1.6864 - val_accuracy: 0.4012 - val_f1_score: 0.3604\n",
      "Epoch 127/10000\n",
      "24/24 [==============================] - 1s 21ms/step - loss: 1.7629 - accuracy: 0.3338 - f1_score: 0.3190 - val_loss: 1.6713 - val_accuracy: 0.4136 - val_f1_score: 0.3664\n",
      "Epoch 128/10000\n",
      "24/24 [==============================] - 1s 21ms/step - loss: 1.7472 - accuracy: 0.3528 - f1_score: 0.3358 - val_loss: 1.6688 - val_accuracy: 0.4136 - val_f1_score: 0.3664\n",
      "Epoch 129/10000\n",
      "24/24 [==============================] - 1s 24ms/step - loss: 1.7718 - accuracy: 0.3243 - f1_score: 0.3061 - val_loss: 1.6693 - val_accuracy: 0.4136 - val_f1_score: 0.3664\n",
      "Epoch 130/10000\n",
      "24/24 [==============================] - 1s 24ms/step - loss: 1.7308 - accuracy: 0.3365 - f1_score: 0.3188 - val_loss: 1.6708 - val_accuracy: 0.4198 - val_f1_score: 0.3693\n",
      "Epoch 131/10000\n",
      "24/24 [==============================] - 1s 23ms/step - loss: 1.8100 - accuracy: 0.3324 - f1_score: 0.3181 - val_loss: 1.6682 - val_accuracy: 0.4198 - val_f1_score: 0.3693\n",
      "Epoch 132/10000\n",
      "24/24 [==============================] - 1s 20ms/step - loss: 1.7403 - accuracy: 0.3243 - f1_score: 0.3114 - val_loss: 1.6483 - val_accuracy: 0.4444 - val_f1_score: 0.3887\n",
      "Epoch 133/10000\n",
      "24/24 [==============================] - 0s 19ms/step - loss: 1.7327 - accuracy: 0.3528 - f1_score: 0.3372 - val_loss: 1.6619 - val_accuracy: 0.4259 - val_f1_score: 0.3699\n",
      "Epoch 134/10000\n",
      "24/24 [==============================] - 0s 19ms/step - loss: 1.7805 - accuracy: 0.3365 - f1_score: 0.3242 - val_loss: 1.6628 - val_accuracy: 0.4383 - val_f1_score: 0.3781\n",
      "Epoch 135/10000\n",
      "24/24 [==============================] - 0s 19ms/step - loss: 1.7005 - accuracy: 0.3460 - f1_score: 0.3288 - val_loss: 1.6659 - val_accuracy: 0.4444 - val_f1_score: 0.3810\n",
      "Epoch 136/10000\n",
      "24/24 [==============================] - 0s 19ms/step - loss: 1.6962 - accuracy: 0.3433 - f1_score: 0.3281 - val_loss: 1.6609 - val_accuracy: 0.4383 - val_f1_score: 0.3781\n",
      "Epoch 137/10000\n",
      "24/24 [==============================] - 0s 20ms/step - loss: 1.7269 - accuracy: 0.3623 - f1_score: 0.3464 - val_loss: 1.6658 - val_accuracy: 0.4321 - val_f1_score: 0.3752\n",
      "Epoch 138/10000\n",
      "24/24 [==============================] - 0s 19ms/step - loss: 1.7491 - accuracy: 0.3474 - f1_score: 0.3378 - val_loss: 1.6670 - val_accuracy: 0.4259 - val_f1_score: 0.3723\n",
      "Epoch 139/10000\n",
      "24/24 [==============================] - 0s 20ms/step - loss: 1.7118 - accuracy: 0.3582 - f1_score: 0.3367 - val_loss: 1.6659 - val_accuracy: 0.4259 - val_f1_score: 0.3723\n",
      "Epoch 140/10000\n",
      "24/24 [==============================] - 1s 21ms/step - loss: 1.7171 - accuracy: 0.3474 - f1_score: 0.3282 - val_loss: 1.6614 - val_accuracy: 0.4259 - val_f1_score: 0.3723\n",
      "Epoch 141/10000\n",
      "24/24 [==============================] - 1s 21ms/step - loss: 1.7326 - accuracy: 0.3623 - f1_score: 0.3471 - val_loss: 1.6581 - val_accuracy: 0.4321 - val_f1_score: 0.3752\n",
      "Epoch 142/10000\n",
      "24/24 [==============================] - 0s 20ms/step - loss: 1.7337 - accuracy: 0.3555 - f1_score: 0.3450 - val_loss: 1.6630 - val_accuracy: 0.4259 - val_f1_score: 0.3723\n",
      "Epoch 143/10000\n",
      "24/24 [==============================] - 1s 21ms/step - loss: 1.7046 - accuracy: 0.3406 - f1_score: 0.3226 - val_loss: 1.6607 - val_accuracy: 0.4259 - val_f1_score: 0.3723\n",
      "Epoch 144/10000\n",
      "24/24 [==============================] - 0s 19ms/step - loss: 1.7122 - accuracy: 0.3555 - f1_score: 0.3362 - val_loss: 1.6630 - val_accuracy: 0.4321 - val_f1_score: 0.3829\n",
      "Epoch 145/10000\n",
      "24/24 [==============================] - 0s 21ms/step - loss: 1.7182 - accuracy: 0.3406 - f1_score: 0.3229 - val_loss: 1.6577 - val_accuracy: 0.4321 - val_f1_score: 0.3829\n",
      "Epoch 146/10000\n",
      "24/24 [==============================] - 0s 20ms/step - loss: 1.6921 - accuracy: 0.3474 - f1_score: 0.3299 - val_loss: 1.6537 - val_accuracy: 0.4321 - val_f1_score: 0.3752\n",
      "Epoch 147/10000\n",
      "24/24 [==============================] - 0s 19ms/step - loss: 1.7522 - accuracy: 0.3501 - f1_score: 0.3251 - val_loss: 1.6517 - val_accuracy: 0.4383 - val_f1_score: 0.3858\n",
      "Epoch 148/10000\n",
      "24/24 [==============================] - 0s 20ms/step - loss: 1.7663 - accuracy: 0.3311 - f1_score: 0.3111 - val_loss: 1.6529 - val_accuracy: 0.4383 - val_f1_score: 0.3858\n",
      "Epoch 149/10000\n",
      "24/24 [==============================] - 1s 23ms/step - loss: 1.6828 - accuracy: 0.3569 - f1_score: 0.3337 - val_loss: 1.6458 - val_accuracy: 0.4383 - val_f1_score: 0.3858\n",
      "Epoch 150/10000\n",
      "24/24 [==============================] - 0s 19ms/step - loss: 1.6670 - accuracy: 0.3514 - f1_score: 0.3313 - val_loss: 1.6169 - val_accuracy: 0.4506 - val_f1_score: 0.3839\n",
      "Epoch 151/10000\n",
      "24/24 [==============================] - 0s 21ms/step - loss: 1.6896 - accuracy: 0.3487 - f1_score: 0.3265 - val_loss: 1.6237 - val_accuracy: 0.4506 - val_f1_score: 0.3839\n",
      "Epoch 152/10000\n",
      "24/24 [==============================] - 1s 21ms/step - loss: 1.6893 - accuracy: 0.3419 - f1_score: 0.3252 - val_loss: 1.6228 - val_accuracy: 0.4568 - val_f1_score: 0.3945\n",
      "Epoch 153/10000\n",
      "24/24 [==============================] - 0s 20ms/step - loss: 1.6971 - accuracy: 0.3582 - f1_score: 0.3424 - val_loss: 1.6307 - val_accuracy: 0.4506 - val_f1_score: 0.3916\n",
      "Epoch 154/10000\n",
      "24/24 [==============================] - 0s 21ms/step - loss: 1.7081 - accuracy: 0.3338 - f1_score: 0.3140 - val_loss: 1.6260 - val_accuracy: 0.4444 - val_f1_score: 0.3810\n",
      "Epoch 155/10000\n",
      "24/24 [==============================] - 0s 19ms/step - loss: 1.6743 - accuracy: 0.3311 - f1_score: 0.3137 - val_loss: 1.6328 - val_accuracy: 0.4444 - val_f1_score: 0.3887\n",
      "Epoch 156/10000\n",
      "24/24 [==============================] - 0s 20ms/step - loss: 1.7249 - accuracy: 0.3460 - f1_score: 0.3316 - val_loss: 1.6333 - val_accuracy: 0.4506 - val_f1_score: 0.3916\n",
      "Epoch 157/10000\n",
      "24/24 [==============================] - 0s 19ms/step - loss: 1.6924 - accuracy: 0.3514 - f1_score: 0.3323 - val_loss: 1.6306 - val_accuracy: 0.4506 - val_f1_score: 0.3916\n",
      "Epoch 158/10000\n",
      "24/24 [==============================] - 1s 31ms/step - loss: 1.6673 - accuracy: 0.3541 - f1_score: 0.3363 - val_loss: 1.6213 - val_accuracy: 0.4506 - val_f1_score: 0.3916\n",
      "Epoch 159/10000\n",
      "24/24 [==============================] - 1s 27ms/step - loss: 1.6584 - accuracy: 0.3596 - f1_score: 0.3478 - val_loss: 1.6210 - val_accuracy: 0.4506 - val_f1_score: 0.3916\n",
      "Epoch 160/10000\n",
      "24/24 [==============================] - 1s 31ms/step - loss: 1.7099 - accuracy: 0.3297 - f1_score: 0.3159 - val_loss: 1.6313 - val_accuracy: 0.4506 - val_f1_score: 0.3916\n",
      "Epoch 161/10000\n",
      "24/24 [==============================] - 1s 27ms/step - loss: 1.7231 - accuracy: 0.3433 - f1_score: 0.3316 - val_loss: 1.6289 - val_accuracy: 0.4506 - val_f1_score: 0.3916\n",
      "Epoch 162/10000\n",
      "24/24 [==============================] - 1s 26ms/step - loss: 1.6727 - accuracy: 0.3528 - f1_score: 0.3342 - val_loss: 1.6299 - val_accuracy: 0.4444 - val_f1_score: 0.3810\n",
      "Epoch 163/10000\n",
      "24/24 [==============================] - 1s 24ms/step - loss: 1.6612 - accuracy: 0.3582 - f1_score: 0.3384 - val_loss: 1.6320 - val_accuracy: 0.4444 - val_f1_score: 0.3810\n",
      "Epoch 164/10000\n",
      "24/24 [==============================] - 1s 24ms/step - loss: 1.6718 - accuracy: 0.3636 - f1_score: 0.3375 - val_loss: 1.6340 - val_accuracy: 0.4383 - val_f1_score: 0.3781\n",
      "Epoch 165/10000\n",
      "24/24 [==============================] - 1s 21ms/step - loss: 1.6772 - accuracy: 0.3474 - f1_score: 0.3322 - val_loss: 1.6291 - val_accuracy: 0.4444 - val_f1_score: 0.3887\n",
      "Epoch 166/10000\n",
      " 8/24 [=========>....................] - ETA: 0s - loss: 1.7162 - accuracy: 0.3711 - f1_score: 0.3591"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "history = model.fit(X_train, y_train, epochs=10000, validation_data=(X_test, y_test))\n",
    "\n",
    "# Plot the losses\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Print the F1-score on the validation set\n",
    "_, _, f1_score = model.evaluate(X_test, y_test)\n",
    "print('F1-score on validation set:', f1_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#**III - Hyper-parameter tuning**\n",
    "\n",
    "We use keras tuner to find the best hyper-parameters for our Residual Network.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 10 Complete [00h 00m 39s]\n",
      "val_loss: 0.1676895171403885\n",
      "\n",
      "Best val_loss So Far: 0.11806707084178925\n",
      "Total elapsed time: 00h 12m 46s\n",
      "Best Hyperparameters:\n",
      "{'filters_0': 64, 'kernel_size_0': 5, 'filters_1': 32, 'kernel_size_1': 13, 'filters_2': 32, 'kernel_size_2': 21}\n"
     ]
    }
   ],
   "source": [
    "import keras_tuner as kt\n",
    "\n",
    "# Define the function to build the model with hyperparameters\n",
    "def build_model(hp):\n",
    "    input_layer = Input(shape=input_shape)\n",
    "    x = input_layer\n",
    "\n",
    "    for i in range(3):\n",
    "        # Define hyperparameters for the number of filters and kernel size\n",
    "        filters = hp.Int('filters_' + str(i), min_value=32, max_value=128, step=32)\n",
    "        kernel_size = hp.Choice('kernel_size_' + str(i), values=[3, 5, 8, 13, 21])\n",
    "\n",
    "        x = residual_block(x, filters, kernel_size)\n",
    "\n",
    "    x = GlobalAveragePooling1D()(x)\n",
    "    # Final softmax classifier\n",
    "    output_layer = Dense(3, activation='softmax')(x)\n",
    "\n",
    "    model = Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "    # Define hyperparameters for the learning rate\n",
    "    learning_rate = 1e-4\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=learning_rate),\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy', tfa.metrics.F1Score(num_classes=3, average=None)]\n",
    "    )\n",
    "\n",
    "    return model\n",
    "\n",
    "# Create the tuner\n",
    "tuner = kt.RandomSearch(\n",
    "    build_model,\n",
    "    objective='val_loss',\n",
    "    max_trials=10,  # Number of hyperparameter combinations to try\n",
    "    executions_per_trial=1,  # Number of models to train for each trial\n",
    "    directory='my_dir',  # Directory where the hyperparameters will be saved\n",
    "    project_name='resnet_hyperparam_tuning'\n",
    ")\n",
    "\n",
    "# Perform the hyperparameter search\n",
    "tuner.search(X_train, y_train, epochs=100, validation_data=(X_test, y_test))\n",
    "\n",
    "# Get the best hyperparameters\n",
    "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "# Print the best hyperparameters\n",
    "print(\"Best Hyperparameters:\")\n",
    "print(best_hps.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_9\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_10 (InputLayer)       [(None, 20, 37)]             0         []                            \n",
      "                                                                                                  \n",
      " conv1d_109 (Conv1D)         (None, 20, 128)              14336     ['input_10[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_81 (Ba  (None, 20, 128)              512       ['conv1d_109[0][0]']          \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_81 (Activation)  (None, 20, 128)              0         ['batch_normalization_81[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv1d_110 (Conv1D)         (None, 20, 128)              49280     ['activation_81[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_82 (Ba  (None, 20, 128)              512       ['conv1d_110[0][0]']          \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_82 (Activation)  (None, 20, 128)              0         ['batch_normalization_82[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv1d_111 (Conv1D)         (None, 20, 128)              49280     ['activation_82[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_83 (Ba  (None, 20, 128)              512       ['conv1d_111[0][0]']          \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_83 (Activation)  (None, 20, 128)              0         ['batch_normalization_83[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv1d_108 (Conv1D)         (None, 20, 128)              4864      ['input_10[0][0]']            \n",
      "                                                                                                  \n",
      " add_27 (Add)                (None, 20, 128)              0         ['activation_83[0][0]',       \n",
      "                                                                     'conv1d_108[0][0]']          \n",
      "                                                                                                  \n",
      " conv1d_113 (Conv1D)         (None, 20, 96)               98400     ['add_27[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_84 (Ba  (None, 20, 96)               384       ['conv1d_113[0][0]']          \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_84 (Activation)  (None, 20, 96)               0         ['batch_normalization_84[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv1d_114 (Conv1D)         (None, 20, 96)               73824     ['activation_84[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_85 (Ba  (None, 20, 96)               384       ['conv1d_114[0][0]']          \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_85 (Activation)  (None, 20, 96)               0         ['batch_normalization_85[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv1d_115 (Conv1D)         (None, 20, 96)               73824     ['activation_85[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_86 (Ba  (None, 20, 96)               384       ['conv1d_115[0][0]']          \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_86 (Activation)  (None, 20, 96)               0         ['batch_normalization_86[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv1d_112 (Conv1D)         (None, 20, 96)               12384     ['add_27[0][0]']              \n",
      "                                                                                                  \n",
      " add_28 (Add)                (None, 20, 96)               0         ['activation_86[0][0]',       \n",
      "                                                                     'conv1d_112[0][0]']          \n",
      "                                                                                                  \n",
      " conv1d_117 (Conv1D)         (None, 20, 32)               64544     ['add_28[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_87 (Ba  (None, 20, 32)               128       ['conv1d_117[0][0]']          \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_87 (Activation)  (None, 20, 32)               0         ['batch_normalization_87[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv1d_118 (Conv1D)         (None, 20, 32)               21536     ['activation_87[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_88 (Ba  (None, 20, 32)               128       ['conv1d_118[0][0]']          \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_88 (Activation)  (None, 20, 32)               0         ['batch_normalization_88[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv1d_119 (Conv1D)         (None, 20, 32)               21536     ['activation_88[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_89 (Ba  (None, 20, 32)               128       ['conv1d_119[0][0]']          \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_89 (Activation)  (None, 20, 32)               0         ['batch_normalization_89[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv1d_116 (Conv1D)         (None, 20, 32)               3104      ['add_28[0][0]']              \n",
      "                                                                                                  \n",
      " add_29 (Add)                (None, 20, 32)               0         ['activation_89[0][0]',       \n",
      "                                                                     'conv1d_116[0][0]']          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_9  (None, 32)                   0         ['add_29[0][0]']              \n",
      "  (GlobalAveragePooling1D)                                                                        \n",
      "                                                                                                  \n",
      " dense_9 (Dense)             (None, 3)                    99        ['global_average_pooling1d_9[0\n",
      "                                                                    ][0]']                        \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 490083 (1.87 MB)\n",
      "Trainable params: 488547 (1.86 MB)\n",
      "Non-trainable params: 1536 (6.00 KB)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Input shape: (timesteps, features)\n",
    "input_shape = (20, 37)\n",
    "\n",
    "# Input layer\n",
    "input_layer = Input(shape=input_shape)\n",
    "\n",
    "# Create three residual blocks with varying kernel sizes\n",
    "x = residual_block(input_layer, 128, 3)\n",
    "x = residual_block(x, 96, 8)\n",
    "x = residual_block(x, 32, 21)\n",
    "\n",
    "# Global Average Pooling layer\n",
    "x = GlobalAveragePooling1D()(x)\n",
    "\n",
    "# Final softmax classifier\n",
    "output_layer = Dense(3, activation='softmax')(x)\n",
    "\n",
    "# Create the model and compile it\n",
    "model_best = Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "# Create the optimizer\n",
    "optimizer = Adam(learning_rate=1e-6)\n",
    "\n",
    "# Compile the model\n",
    "model_best.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy', tfa.metrics.F1Score(num_classes=3, average=None)])\n",
    "\n",
    "# Print the model summary\n",
    "model_best.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10000\n",
      "24/24 [==============================] - 5s 48ms/step - loss: 2.3650 - accuracy: 0.2198 - f1_score: 0.1711 - val_loss: 1.5612 - val_accuracy: 0.1296 - val_f1_score: 0.1336\n",
      "Epoch 2/10000\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 2.2986 - accuracy: 0.2157 - f1_score: 0.1623 - val_loss: 1.6050 - val_accuracy: 0.1296 - val_f1_score: 0.1319\n",
      "Epoch 3/10000\n",
      "24/24 [==============================] - 1s 32ms/step - loss: 2.2580 - accuracy: 0.2171 - f1_score: 0.1629 - val_loss: 1.6654 - val_accuracy: 0.1296 - val_f1_score: 0.1295\n",
      "Epoch 4/10000\n",
      "24/24 [==============================] - 1s 31ms/step - loss: 2.1959 - accuracy: 0.2293 - f1_score: 0.1780 - val_loss: 1.7241 - val_accuracy: 0.1111 - val_f1_score: 0.1026\n",
      "Epoch 5/10000\n",
      "24/24 [==============================] - 1s 32ms/step - loss: 2.1068 - accuracy: 0.2307 - f1_score: 0.1746 - val_loss: 1.7730 - val_accuracy: 0.1111 - val_f1_score: 0.1000\n",
      "Epoch 6/10000\n",
      "24/24 [==============================] - 1s 31ms/step - loss: 2.0715 - accuracy: 0.2239 - f1_score: 0.1742 - val_loss: 1.8162 - val_accuracy: 0.1111 - val_f1_score: 0.0945\n",
      "Epoch 7/10000\n",
      "24/24 [==============================] - 1s 30ms/step - loss: 2.0137 - accuracy: 0.2347 - f1_score: 0.1787 - val_loss: 1.8552 - val_accuracy: 0.1173 - val_f1_score: 0.0938\n",
      "Epoch 8/10000\n",
      "24/24 [==============================] - 1s 30ms/step - loss: 1.9951 - accuracy: 0.2266 - f1_score: 0.1778 - val_loss: 1.8888 - val_accuracy: 0.1173 - val_f1_score: 0.0905\n",
      "Epoch 9/10000\n",
      "24/24 [==============================] - 1s 30ms/step - loss: 1.9283 - accuracy: 0.2388 - f1_score: 0.1963 - val_loss: 1.9108 - val_accuracy: 0.1235 - val_f1_score: 0.0939\n",
      "Epoch 10/10000\n",
      "24/24 [==============================] - 1s 31ms/step - loss: 1.8847 - accuracy: 0.2374 - f1_score: 0.1899 - val_loss: 1.9264 - val_accuracy: 0.1235 - val_f1_score: 0.0920\n",
      "Epoch 11/10000\n",
      "24/24 [==============================] - 1s 31ms/step - loss: 1.7870 - accuracy: 0.2537 - f1_score: 0.2009 - val_loss: 1.9271 - val_accuracy: 0.1235 - val_f1_score: 0.0907\n",
      "Epoch 12/10000\n",
      "24/24 [==============================] - 1s 30ms/step - loss: 1.7825 - accuracy: 0.2578 - f1_score: 0.2119 - val_loss: 1.9281 - val_accuracy: 0.1235 - val_f1_score: 0.0895\n",
      "Epoch 13/10000\n",
      "24/24 [==============================] - 1s 31ms/step - loss: 1.7220 - accuracy: 0.2510 - f1_score: 0.2038 - val_loss: 1.9207 - val_accuracy: 0.1235 - val_f1_score: 0.0889\n",
      "Epoch 14/10000\n",
      "24/24 [==============================] - 1s 32ms/step - loss: 1.7529 - accuracy: 0.2768 - f1_score: 0.2361 - val_loss: 1.9012 - val_accuracy: 0.1358 - val_f1_score: 0.0990\n",
      "Epoch 15/10000\n",
      "24/24 [==============================] - 1s 32ms/step - loss: 1.6867 - accuracy: 0.2890 - f1_score: 0.2472 - val_loss: 1.8819 - val_accuracy: 0.1481 - val_f1_score: 0.1090\n",
      "Epoch 16/10000\n",
      "24/24 [==============================] - 1s 32ms/step - loss: 1.6576 - accuracy: 0.3148 - f1_score: 0.2830 - val_loss: 1.8583 - val_accuracy: 0.1728 - val_f1_score: 0.1287\n",
      "Epoch 17/10000\n",
      "24/24 [==============================] - 1s 31ms/step - loss: 1.5794 - accuracy: 0.3351 - f1_score: 0.3040 - val_loss: 1.7978 - val_accuracy: 0.1975 - val_f1_score: 0.1453\n",
      "Epoch 18/10000\n",
      "24/24 [==============================] - 1s 31ms/step - loss: 1.5485 - accuracy: 0.3324 - f1_score: 0.3032 - val_loss: 1.7740 - val_accuracy: 0.2160 - val_f1_score: 0.1588\n",
      "Epoch 19/10000\n",
      "24/24 [==============================] - 1s 32ms/step - loss: 1.5064 - accuracy: 0.3813 - f1_score: 0.3330 - val_loss: 1.7404 - val_accuracy: 0.2716 - val_f1_score: 0.1988\n",
      "Epoch 20/10000\n",
      "24/24 [==============================] - 1s 30ms/step - loss: 1.4800 - accuracy: 0.3908 - f1_score: 0.3557 - val_loss: 1.7089 - val_accuracy: 0.3025 - val_f1_score: 0.2181\n",
      "Epoch 21/10000\n",
      "24/24 [==============================] - 1s 31ms/step - loss: 1.4432 - accuracy: 0.4084 - f1_score: 0.3785 - val_loss: 1.6716 - val_accuracy: 0.3210 - val_f1_score: 0.2313\n",
      "Epoch 22/10000\n",
      "24/24 [==============================] - 1s 31ms/step - loss: 1.4216 - accuracy: 0.4288 - f1_score: 0.3786 - val_loss: 1.6436 - val_accuracy: 0.3457 - val_f1_score: 0.2477\n",
      "Epoch 23/10000\n",
      "24/24 [==============================] - 1s 31ms/step - loss: 1.4066 - accuracy: 0.4328 - f1_score: 0.4053 - val_loss: 1.6069 - val_accuracy: 0.3642 - val_f1_score: 0.2597\n",
      "Epoch 24/10000\n",
      "24/24 [==============================] - 1s 32ms/step - loss: 1.3795 - accuracy: 0.4478 - f1_score: 0.4017 - val_loss: 1.5702 - val_accuracy: 0.3827 - val_f1_score: 0.2705\n",
      "Epoch 25/10000\n",
      "24/24 [==============================] - 1s 31ms/step - loss: 1.2959 - accuracy: 0.4654 - f1_score: 0.4312 - val_loss: 1.5282 - val_accuracy: 0.4198 - val_f1_score: 0.3372\n",
      "Epoch 26/10000\n",
      "24/24 [==============================] - 1s 31ms/step - loss: 1.2798 - accuracy: 0.4912 - f1_score: 0.4725 - val_loss: 1.4990 - val_accuracy: 0.4259 - val_f1_score: 0.3393\n",
      "Epoch 27/10000\n",
      "24/24 [==============================] - 1s 30ms/step - loss: 1.2610 - accuracy: 0.5034 - f1_score: 0.4549 - val_loss: 1.4491 - val_accuracy: 0.4568 - val_f1_score: 0.3598\n",
      "Epoch 28/10000\n",
      "24/24 [==============================] - 1s 32ms/step - loss: 1.1989 - accuracy: 0.5088 - f1_score: 0.4532 - val_loss: 1.4136 - val_accuracy: 0.4691 - val_f1_score: 0.3683\n",
      "Epoch 29/10000\n",
      "24/24 [==============================] - 1s 31ms/step - loss: 1.1824 - accuracy: 0.5455 - f1_score: 0.4925 - val_loss: 1.3849 - val_accuracy: 0.4938 - val_f1_score: 0.3840\n",
      "Epoch 30/10000\n",
      "24/24 [==============================] - 1s 31ms/step - loss: 1.1931 - accuracy: 0.5631 - f1_score: 0.5191 - val_loss: 1.3502 - val_accuracy: 0.5679 - val_f1_score: 0.4296\n",
      "Epoch 31/10000\n",
      "24/24 [==============================] - 1s 31ms/step - loss: 1.0963 - accuracy: 0.5767 - f1_score: 0.5011 - val_loss: 1.3320 - val_accuracy: 0.5864 - val_f1_score: 0.4420\n",
      "Epoch 32/10000\n",
      "24/24 [==============================] - 1s 31ms/step - loss: 1.0878 - accuracy: 0.6214 - f1_score: 0.5503 - val_loss: 1.3011 - val_accuracy: 0.6296 - val_f1_score: 0.4687\n",
      "Epoch 33/10000\n",
      "24/24 [==============================] - 1s 31ms/step - loss: 1.0989 - accuracy: 0.6187 - f1_score: 0.5614 - val_loss: 1.2684 - val_accuracy: 0.6605 - val_f1_score: 0.5358\n",
      "Epoch 34/10000\n",
      "24/24 [==============================] - 1s 30ms/step - loss: 1.0670 - accuracy: 0.6336 - f1_score: 0.5755 - val_loss: 1.2450 - val_accuracy: 0.6975 - val_f1_score: 0.5667\n",
      "Epoch 35/10000\n",
      "24/24 [==============================] - 1s 31ms/step - loss: 1.0544 - accuracy: 0.6567 - f1_score: 0.6047 - val_loss: 1.2188 - val_accuracy: 0.7284 - val_f1_score: 0.5952\n",
      "Epoch 36/10000\n",
      "24/24 [==============================] - 1s 32ms/step - loss: 1.0500 - accuracy: 0.6649 - f1_score: 0.6011 - val_loss: 1.1604 - val_accuracy: 0.7593 - val_f1_score: 0.6273\n",
      "Epoch 37/10000\n",
      "24/24 [==============================] - 1s 31ms/step - loss: 1.0021 - accuracy: 0.6839 - f1_score: 0.6049 - val_loss: 1.1293 - val_accuracy: 0.7778 - val_f1_score: 0.6470\n",
      "Epoch 38/10000\n",
      "24/24 [==============================] - 1s 31ms/step - loss: 0.9749 - accuracy: 0.7164 - f1_score: 0.6379 - val_loss: 1.0993 - val_accuracy: 0.7840 - val_f1_score: 0.6597\n",
      "Epoch 39/10000\n",
      "24/24 [==============================] - 1s 31ms/step - loss: 0.9646 - accuracy: 0.7110 - f1_score: 0.6532 - val_loss: 1.0916 - val_accuracy: 0.7901 - val_f1_score: 0.6555\n",
      "Epoch 40/10000\n",
      "24/24 [==============================] - 1s 32ms/step - loss: 0.9237 - accuracy: 0.7408 - f1_score: 0.6572 - val_loss: 1.0733 - val_accuracy: 0.8148 - val_f1_score: 0.6813\n",
      "Epoch 41/10000\n",
      "24/24 [==============================] - 1s 31ms/step - loss: 0.9568 - accuracy: 0.7205 - f1_score: 0.6324 - val_loss: 1.0566 - val_accuracy: 0.8148 - val_f1_score: 0.6731\n",
      "Epoch 42/10000\n",
      "24/24 [==============================] - 1s 31ms/step - loss: 0.9172 - accuracy: 0.7449 - f1_score: 0.6703 - val_loss: 1.0419 - val_accuracy: 0.8333 - val_f1_score: 0.6950\n",
      "Epoch 43/10000\n",
      "24/24 [==============================] - 1s 31ms/step - loss: 0.9024 - accuracy: 0.7422 - f1_score: 0.6630 - val_loss: 1.0231 - val_accuracy: 0.8395 - val_f1_score: 0.6997\n",
      "Epoch 44/10000\n",
      "24/24 [==============================] - 1s 30ms/step - loss: 0.8488 - accuracy: 0.7612 - f1_score: 0.6762 - val_loss: 1.0112 - val_accuracy: 0.8519 - val_f1_score: 0.7187\n",
      "Epoch 45/10000\n",
      "24/24 [==============================] - 1s 32ms/step - loss: 0.8448 - accuracy: 0.7938 - f1_score: 0.7091 - val_loss: 0.9939 - val_accuracy: 0.8519 - val_f1_score: 0.7187\n",
      "Epoch 46/10000\n",
      "24/24 [==============================] - 1s 31ms/step - loss: 0.8168 - accuracy: 0.7815 - f1_score: 0.6885 - val_loss: 0.9733 - val_accuracy: 0.8519 - val_f1_score: 0.7187\n",
      "Epoch 47/10000\n",
      "24/24 [==============================] - 1s 31ms/step - loss: 0.8384 - accuracy: 0.7775 - f1_score: 0.7005 - val_loss: 0.9564 - val_accuracy: 0.8580 - val_f1_score: 0.7144\n",
      "Epoch 48/10000\n",
      "24/24 [==============================] - 1s 31ms/step - loss: 0.7983 - accuracy: 0.8046 - f1_score: 0.7047 - val_loss: 0.9296 - val_accuracy: 0.8642 - val_f1_score: 0.7286\n",
      "Epoch 49/10000\n",
      "24/24 [==============================] - 1s 32ms/step - loss: 0.7843 - accuracy: 0.8304 - f1_score: 0.7352 - val_loss: 0.9139 - val_accuracy: 0.8642 - val_f1_score: 0.7286\n",
      "Epoch 50/10000\n",
      "24/24 [==============================] - 1s 31ms/step - loss: 0.7582 - accuracy: 0.8128 - f1_score: 0.7337 - val_loss: 0.8640 - val_accuracy: 0.8642 - val_f1_score: 0.7286\n",
      "Epoch 51/10000\n",
      "24/24 [==============================] - 1s 30ms/step - loss: 0.7470 - accuracy: 0.8277 - f1_score: 0.7367 - val_loss: 0.8627 - val_accuracy: 0.8642 - val_f1_score: 0.7286\n",
      "Epoch 52/10000\n",
      "24/24 [==============================] - 1s 31ms/step - loss: 0.7475 - accuracy: 0.8304 - f1_score: 0.7524 - val_loss: 0.8552 - val_accuracy: 0.8642 - val_f1_score: 0.7286\n",
      "Epoch 53/10000\n",
      "24/24 [==============================] - 1s 32ms/step - loss: 0.7369 - accuracy: 0.8318 - f1_score: 0.7637 - val_loss: 0.8477 - val_accuracy: 0.8704 - val_f1_score: 0.7337\n",
      "Epoch 54/10000\n",
      "24/24 [==============================] - 1s 31ms/step - loss: 0.7252 - accuracy: 0.8453 - f1_score: 0.7455 - val_loss: 0.8341 - val_accuracy: 0.8765 - val_f1_score: 0.7389\n",
      "Epoch 55/10000\n",
      "24/24 [==============================] - 1s 31ms/step - loss: 0.7147 - accuracy: 0.8358 - f1_score: 0.7371 - val_loss: 0.8201 - val_accuracy: 0.8765 - val_f1_score: 0.7389\n",
      "Epoch 56/10000\n",
      "24/24 [==============================] - 1s 31ms/step - loss: 0.7635 - accuracy: 0.8114 - f1_score: 0.7227 - val_loss: 0.8114 - val_accuracy: 0.8765 - val_f1_score: 0.7389\n",
      "Epoch 57/10000\n",
      "24/24 [==============================] - 1s 32ms/step - loss: 0.6692 - accuracy: 0.8589 - f1_score: 0.7797 - val_loss: 0.8053 - val_accuracy: 0.8765 - val_f1_score: 0.7389\n",
      "Epoch 58/10000\n",
      "24/24 [==============================] - 1s 31ms/step - loss: 0.6799 - accuracy: 0.8535 - f1_score: 0.7574 - val_loss: 0.7974 - val_accuracy: 0.8765 - val_f1_score: 0.7389\n",
      "Epoch 59/10000\n",
      "24/24 [==============================] - 1s 30ms/step - loss: 0.7109 - accuracy: 0.8385 - f1_score: 0.7591 - val_loss: 0.7896 - val_accuracy: 0.8765 - val_f1_score: 0.7389\n",
      "Epoch 60/10000\n",
      "24/24 [==============================] - 1s 31ms/step - loss: 0.6482 - accuracy: 0.8684 - f1_score: 0.7801 - val_loss: 0.7782 - val_accuracy: 0.8765 - val_f1_score: 0.7389\n",
      "Epoch 61/10000\n",
      "24/24 [==============================] - 1s 32ms/step - loss: 0.6716 - accuracy: 0.8535 - f1_score: 0.7698 - val_loss: 0.7696 - val_accuracy: 0.8765 - val_f1_score: 0.7389\n",
      "Epoch 62/10000\n",
      "24/24 [==============================] - 1s 31ms/step - loss: 0.6600 - accuracy: 0.8562 - f1_score: 0.7736 - val_loss: 0.7627 - val_accuracy: 0.8765 - val_f1_score: 0.7389\n",
      "Epoch 63/10000\n",
      "24/24 [==============================] - 1s 31ms/step - loss: 0.6408 - accuracy: 0.8494 - f1_score: 0.7485 - val_loss: 0.7556 - val_accuracy: 0.8765 - val_f1_score: 0.7389\n",
      "Epoch 64/10000\n",
      "24/24 [==============================] - 1s 31ms/step - loss: 0.6066 - accuracy: 0.8562 - f1_score: 0.7685 - val_loss: 0.7459 - val_accuracy: 0.8827 - val_f1_score: 0.7442\n",
      "Epoch 65/10000\n",
      "24/24 [==============================] - 1s 32ms/step - loss: 0.6038 - accuracy: 0.8752 - f1_score: 0.7711 - val_loss: 0.7351 - val_accuracy: 0.8889 - val_f1_score: 0.7496\n",
      "Epoch 66/10000\n",
      "24/24 [==============================] - 1s 31ms/step - loss: 0.6039 - accuracy: 0.8901 - f1_score: 0.8238 - val_loss: 0.7193 - val_accuracy: 0.8827 - val_f1_score: 0.7412\n",
      "Epoch 67/10000\n",
      "24/24 [==============================] - 1s 31ms/step - loss: 0.6045 - accuracy: 0.8738 - f1_score: 0.8038 - val_loss: 0.7112 - val_accuracy: 0.8827 - val_f1_score: 0.7412\n",
      "Epoch 68/10000\n",
      "24/24 [==============================] - 1s 31ms/step - loss: 0.6028 - accuracy: 0.8657 - f1_score: 0.7775 - val_loss: 0.6921 - val_accuracy: 0.8827 - val_f1_score: 0.7412\n",
      "Epoch 69/10000\n",
      "24/24 [==============================] - 1s 32ms/step - loss: 0.5880 - accuracy: 0.8684 - f1_score: 0.7935 - val_loss: 0.6884 - val_accuracy: 0.8827 - val_f1_score: 0.7412\n",
      "Epoch 70/10000\n",
      "24/24 [==============================] - 1s 32ms/step - loss: 0.5720 - accuracy: 0.8806 - f1_score: 0.8087 - val_loss: 0.6828 - val_accuracy: 0.8827 - val_f1_score: 0.7412\n",
      "Epoch 71/10000\n",
      "24/24 [==============================] - 1s 31ms/step - loss: 0.5885 - accuracy: 0.8711 - f1_score: 0.7975 - val_loss: 0.6759 - val_accuracy: 0.8827 - val_f1_score: 0.7412\n",
      "Epoch 72/10000\n",
      "24/24 [==============================] - 1s 30ms/step - loss: 0.5368 - accuracy: 0.8928 - f1_score: 0.8162 - val_loss: 0.6725 - val_accuracy: 0.8827 - val_f1_score: 0.7412\n",
      "Epoch 73/10000\n",
      "24/24 [==============================] - 1s 32ms/step - loss: 0.5530 - accuracy: 0.8996 - f1_score: 0.8262 - val_loss: 0.6659 - val_accuracy: 0.8889 - val_f1_score: 0.7467\n",
      "Epoch 74/10000\n",
      "24/24 [==============================] - 1s 31ms/step - loss: 0.5417 - accuracy: 0.8860 - f1_score: 0.8149 - val_loss: 0.6586 - val_accuracy: 0.8889 - val_f1_score: 0.7467\n",
      "Epoch 75/10000\n",
      "24/24 [==============================] - 1s 31ms/step - loss: 0.5314 - accuracy: 0.8792 - f1_score: 0.8049 - val_loss: 0.6488 - val_accuracy: 0.8889 - val_f1_score: 0.7467\n",
      "Epoch 76/10000\n",
      "24/24 [==============================] - 1s 32ms/step - loss: 0.5674 - accuracy: 0.8847 - f1_score: 0.8165 - val_loss: 0.6413 - val_accuracy: 0.8889 - val_f1_score: 0.7467\n",
      "Epoch 77/10000\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.5003 - accuracy: 0.8874 - f1_score: 0.8238 - val_loss: 0.6378 - val_accuracy: 0.8889 - val_f1_score: 0.7467\n",
      "Epoch 78/10000\n",
      "24/24 [==============================] - 1s 31ms/step - loss: 0.5122 - accuracy: 0.8928 - f1_score: 0.8383 - val_loss: 0.6313 - val_accuracy: 0.8889 - val_f1_score: 0.7467\n",
      "Epoch 79/10000\n",
      "24/24 [==============================] - 1s 30ms/step - loss: 0.4818 - accuracy: 0.8833 - f1_score: 0.8031 - val_loss: 0.6189 - val_accuracy: 0.8951 - val_f1_score: 0.7523\n",
      "Epoch 80/10000\n",
      "24/24 [==============================] - 1s 31ms/step - loss: 0.4777 - accuracy: 0.9077 - f1_score: 0.8331 - val_loss: 0.6084 - val_accuracy: 0.8951 - val_f1_score: 0.7523\n",
      "Epoch 81/10000\n",
      "24/24 [==============================] - 1s 32ms/step - loss: 0.4781 - accuracy: 0.8942 - f1_score: 0.8189 - val_loss: 0.6038 - val_accuracy: 0.8951 - val_f1_score: 0.7523\n",
      "Epoch 82/10000\n",
      "24/24 [==============================] - 1s 31ms/step - loss: 0.4754 - accuracy: 0.9172 - f1_score: 0.8616 - val_loss: 0.5939 - val_accuracy: 0.9012 - val_f1_score: 0.7581\n",
      "Epoch 83/10000\n",
      "24/24 [==============================] - 1s 32ms/step - loss: 0.4712 - accuracy: 0.9064 - f1_score: 0.8537 - val_loss: 0.5947 - val_accuracy: 0.9074 - val_f1_score: 0.7800\n",
      "Epoch 84/10000\n",
      "24/24 [==============================] - 1s 32ms/step - loss: 0.4565 - accuracy: 0.8928 - f1_score: 0.8330 - val_loss: 0.5923 - val_accuracy: 0.9074 - val_f1_score: 0.7800\n",
      "Epoch 85/10000\n",
      "24/24 [==============================] - 1s 31ms/step - loss: 0.4748 - accuracy: 0.9118 - f1_score: 0.8498 - val_loss: 0.5857 - val_accuracy: 0.9074 - val_f1_score: 0.7800\n",
      "Epoch 86/10000\n",
      "24/24 [==============================] - 1s 31ms/step - loss: 0.4715 - accuracy: 0.9064 - f1_score: 0.8437 - val_loss: 0.5730 - val_accuracy: 0.9074 - val_f1_score: 0.7800\n",
      "Epoch 87/10000\n",
      "24/24 [==============================] - 1s 31ms/step - loss: 0.4748 - accuracy: 0.8982 - f1_score: 0.8345 - val_loss: 0.5687 - val_accuracy: 0.9074 - val_f1_score: 0.7800\n",
      "Epoch 88/10000\n",
      "24/24 [==============================] - 1s 32ms/step - loss: 0.4413 - accuracy: 0.9050 - f1_score: 0.8449 - val_loss: 0.5651 - val_accuracy: 0.9074 - val_f1_score: 0.7800\n",
      "Epoch 89/10000\n",
      "24/24 [==============================] - 1s 31ms/step - loss: 0.4490 - accuracy: 0.8969 - f1_score: 0.8153 - val_loss: 0.5604 - val_accuracy: 0.9074 - val_f1_score: 0.7800\n",
      "Epoch 90/10000\n",
      "24/24 [==============================] - 1s 31ms/step - loss: 0.4607 - accuracy: 0.9091 - f1_score: 0.8491 - val_loss: 0.5480 - val_accuracy: 0.9074 - val_f1_score: 0.7800\n",
      "Epoch 91/10000\n",
      "24/24 [==============================] - 1s 32ms/step - loss: 0.4449 - accuracy: 0.9064 - f1_score: 0.8519 - val_loss: 0.5444 - val_accuracy: 0.9074 - val_f1_score: 0.7800\n",
      "Epoch 92/10000\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.4451 - accuracy: 0.9023 - f1_score: 0.8466 - val_loss: 0.5431 - val_accuracy: 0.9074 - val_f1_score: 0.7800\n",
      "Epoch 93/10000\n",
      "24/24 [==============================] - 1s 31ms/step - loss: 0.4256 - accuracy: 0.9050 - f1_score: 0.8471 - val_loss: 0.5395 - val_accuracy: 0.9074 - val_f1_score: 0.7800\n",
      "Epoch 94/10000\n",
      "24/24 [==============================] - 1s 31ms/step - loss: 0.4536 - accuracy: 0.9091 - f1_score: 0.8716 - val_loss: 0.5362 - val_accuracy: 0.9074 - val_f1_score: 0.7800\n",
      "Epoch 95/10000\n",
      "24/24 [==============================] - 1s 31ms/step - loss: 0.4412 - accuracy: 0.9037 - f1_score: 0.8557 - val_loss: 0.5309 - val_accuracy: 0.9074 - val_f1_score: 0.7800\n",
      "Epoch 96/10000\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.4303 - accuracy: 0.9104 - f1_score: 0.8688 - val_loss: 0.4992 - val_accuracy: 0.9074 - val_f1_score: 0.7800\n",
      "Epoch 97/10000\n",
      "24/24 [==============================] - 1s 32ms/step - loss: 0.4158 - accuracy: 0.9104 - f1_score: 0.8484 - val_loss: 0.5035 - val_accuracy: 0.9074 - val_f1_score: 0.7800\n",
      "Epoch 98/10000\n",
      "24/24 [==============================] - 1s 31ms/step - loss: 0.4051 - accuracy: 0.9091 - f1_score: 0.8499 - val_loss: 0.4986 - val_accuracy: 0.9074 - val_f1_score: 0.7800\n",
      "Epoch 99/10000\n",
      "24/24 [==============================] - 1s 31ms/step - loss: 0.4314 - accuracy: 0.9050 - f1_score: 0.8387 - val_loss: 0.4999 - val_accuracy: 0.9074 - val_f1_score: 0.7800\n",
      "Epoch 100/10000\n",
      "24/24 [==============================] - 1s 31ms/step - loss: 0.3883 - accuracy: 0.9213 - f1_score: 0.8558 - val_loss: 0.4984 - val_accuracy: 0.9074 - val_f1_score: 0.7800\n",
      "Epoch 101/10000\n",
      "24/24 [==============================] - 1s 31ms/step - loss: 0.4004 - accuracy: 0.9064 - f1_score: 0.8633 - val_loss: 0.4965 - val_accuracy: 0.9074 - val_f1_score: 0.7800\n",
      "Epoch 102/10000\n",
      "24/24 [==============================] - 1s 31ms/step - loss: 0.4281 - accuracy: 0.9091 - f1_score: 0.8546 - val_loss: 0.4935 - val_accuracy: 0.9074 - val_f1_score: 0.7800\n",
      "Epoch 103/10000\n",
      "24/24 [==============================] - 1s 32ms/step - loss: 0.4232 - accuracy: 0.8847 - f1_score: 0.8224 - val_loss: 0.4898 - val_accuracy: 0.9074 - val_f1_score: 0.7800\n",
      "Epoch 104/10000\n",
      "24/24 [==============================] - 1s 32ms/step - loss: 0.3679 - accuracy: 0.9199 - f1_score: 0.8539 - val_loss: 0.4881 - val_accuracy: 0.9074 - val_f1_score: 0.7800\n",
      "Epoch 105/10000\n",
      "24/24 [==============================] - 1s 32ms/step - loss: 0.3783 - accuracy: 0.9186 - f1_score: 0.8661 - val_loss: 0.4854 - val_accuracy: 0.9074 - val_f1_score: 0.7800\n",
      "Epoch 106/10000\n",
      "24/24 [==============================] - 1s 35ms/step - loss: 0.3897 - accuracy: 0.9077 - f1_score: 0.8536 - val_loss: 0.4829 - val_accuracy: 0.9136 - val_f1_score: 0.7985\n",
      "Epoch 107/10000\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.3775 - accuracy: 0.9240 - f1_score: 0.8866 - val_loss: 0.4767 - val_accuracy: 0.9136 - val_f1_score: 0.7985\n",
      "Epoch 108/10000\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.4160 - accuracy: 0.8955 - f1_score: 0.8336 - val_loss: 0.4726 - val_accuracy: 0.9136 - val_f1_score: 0.7985\n",
      "Epoch 109/10000\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.4011 - accuracy: 0.9172 - f1_score: 0.8441 - val_loss: 0.4209 - val_accuracy: 0.9074 - val_f1_score: 0.7899\n",
      "Epoch 110/10000\n",
      "24/24 [==============================] - 1s 35ms/step - loss: 0.3661 - accuracy: 0.9227 - f1_score: 0.8722 - val_loss: 0.4237 - val_accuracy: 0.9074 - val_f1_score: 0.7899\n",
      "Epoch 111/10000\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.3900 - accuracy: 0.9050 - f1_score: 0.8421 - val_loss: 0.4277 - val_accuracy: 0.9074 - val_f1_score: 0.8027\n",
      "Epoch 112/10000\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.3585 - accuracy: 0.9118 - f1_score: 0.8547 - val_loss: 0.4280 - val_accuracy: 0.9074 - val_f1_score: 0.7899\n",
      "Epoch 113/10000\n",
      "24/24 [==============================] - 1s 34ms/step - loss: 0.3564 - accuracy: 0.9254 - f1_score: 0.8737 - val_loss: 0.4310 - val_accuracy: 0.9136 - val_f1_score: 0.7985\n",
      "Epoch 114/10000\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.3612 - accuracy: 0.9240 - f1_score: 0.8789 - val_loss: 0.4342 - val_accuracy: 0.9136 - val_f1_score: 0.8116\n",
      "Epoch 115/10000\n",
      "24/24 [==============================] - 1s 32ms/step - loss: 0.3516 - accuracy: 0.9145 - f1_score: 0.8684 - val_loss: 0.4370 - val_accuracy: 0.9136 - val_f1_score: 0.8116\n",
      "Epoch 116/10000\n",
      "24/24 [==============================] - 1s 32ms/step - loss: 0.3626 - accuracy: 0.9132 - f1_score: 0.8578 - val_loss: 0.4291 - val_accuracy: 0.9136 - val_f1_score: 0.8116\n",
      "Epoch 117/10000\n",
      "24/24 [==============================] - 1s 34ms/step - loss: 0.3730 - accuracy: 0.9104 - f1_score: 0.8578 - val_loss: 0.4292 - val_accuracy: 0.9136 - val_f1_score: 0.8116\n",
      "Epoch 118/10000\n",
      "24/24 [==============================] - 1s 32ms/step - loss: 0.3284 - accuracy: 0.9172 - f1_score: 0.8578 - val_loss: 0.4254 - val_accuracy: 0.9136 - val_f1_score: 0.8116\n",
      "Epoch 119/10000\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.3506 - accuracy: 0.9294 - f1_score: 0.8890 - val_loss: 0.4249 - val_accuracy: 0.9136 - val_f1_score: 0.8116\n",
      "Epoch 120/10000\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.3246 - accuracy: 0.9213 - f1_score: 0.8729 - val_loss: 0.4192 - val_accuracy: 0.9136 - val_f1_score: 0.8116\n",
      "Epoch 121/10000\n",
      "24/24 [==============================] - 1s 32ms/step - loss: 0.3227 - accuracy: 0.9240 - f1_score: 0.8678 - val_loss: 0.4170 - val_accuracy: 0.9136 - val_f1_score: 0.8116\n",
      "Epoch 122/10000\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.3354 - accuracy: 0.9281 - f1_score: 0.8949 - val_loss: 0.4157 - val_accuracy: 0.9136 - val_f1_score: 0.8116\n",
      "Epoch 123/10000\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.3095 - accuracy: 0.9294 - f1_score: 0.8629 - val_loss: 0.4123 - val_accuracy: 0.9136 - val_f1_score: 0.8116\n",
      "Epoch 124/10000\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.3153 - accuracy: 0.9281 - f1_score: 0.8634 - val_loss: 0.4105 - val_accuracy: 0.9136 - val_f1_score: 0.8116\n",
      "Epoch 125/10000\n",
      "24/24 [==============================] - 1s 32ms/step - loss: 0.3092 - accuracy: 0.9308 - f1_score: 0.8850 - val_loss: 0.4008 - val_accuracy: 0.9136 - val_f1_score: 0.8116\n",
      "Epoch 126/10000\n",
      "24/24 [==============================] - 1s 32ms/step - loss: 0.3196 - accuracy: 0.9227 - f1_score: 0.8738 - val_loss: 0.4027 - val_accuracy: 0.9136 - val_f1_score: 0.8116\n",
      "Epoch 127/10000\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.3138 - accuracy: 0.9281 - f1_score: 0.8775 - val_loss: 0.3986 - val_accuracy: 0.9136 - val_f1_score: 0.8116\n",
      "Epoch 128/10000\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.3300 - accuracy: 0.9294 - f1_score: 0.8793 - val_loss: 0.3945 - val_accuracy: 0.9136 - val_f1_score: 0.8116\n",
      "Epoch 129/10000\n",
      "24/24 [==============================] - 1s 32ms/step - loss: 0.2937 - accuracy: 0.9281 - f1_score: 0.8677 - val_loss: 0.3927 - val_accuracy: 0.9136 - val_f1_score: 0.8116\n",
      "Epoch 130/10000\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.2986 - accuracy: 0.9227 - f1_score: 0.8733 - val_loss: 0.3911 - val_accuracy: 0.9136 - val_f1_score: 0.8116\n",
      "Epoch 131/10000\n",
      "24/24 [==============================] - 1s 32ms/step - loss: 0.3022 - accuracy: 0.9281 - f1_score: 0.8757 - val_loss: 0.3822 - val_accuracy: 0.9136 - val_f1_score: 0.8116\n",
      "Epoch 132/10000\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.3162 - accuracy: 0.9159 - f1_score: 0.8463 - val_loss: 0.3798 - val_accuracy: 0.9136 - val_f1_score: 0.8116\n",
      "Epoch 133/10000\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.2768 - accuracy: 0.9471 - f1_score: 0.9011 - val_loss: 0.3734 - val_accuracy: 0.9074 - val_f1_score: 0.8027\n",
      "Epoch 134/10000\n",
      "24/24 [==============================] - 1s 32ms/step - loss: 0.2958 - accuracy: 0.9213 - f1_score: 0.8542 - val_loss: 0.3740 - val_accuracy: 0.9136 - val_f1_score: 0.8116\n",
      "Epoch 135/10000\n",
      "24/24 [==============================] - 1s 32ms/step - loss: 0.3252 - accuracy: 0.9077 - f1_score: 0.8641 - val_loss: 0.3742 - val_accuracy: 0.9136 - val_f1_score: 0.8116\n",
      "Epoch 136/10000\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.2697 - accuracy: 0.9322 - f1_score: 0.8806 - val_loss: 0.3728 - val_accuracy: 0.9136 - val_f1_score: 0.8116\n",
      "Epoch 137/10000\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.2686 - accuracy: 0.9281 - f1_score: 0.8813 - val_loss: 0.3702 - val_accuracy: 0.9136 - val_f1_score: 0.8116\n",
      "Epoch 138/10000\n",
      "24/24 [==============================] - 1s 32ms/step - loss: 0.2584 - accuracy: 0.9308 - f1_score: 0.8744 - val_loss: 0.3683 - val_accuracy: 0.9136 - val_f1_score: 0.8116\n",
      "Epoch 139/10000\n",
      "24/24 [==============================] - 1s 32ms/step - loss: 0.2751 - accuracy: 0.9417 - f1_score: 0.8915 - val_loss: 0.3672 - val_accuracy: 0.9136 - val_f1_score: 0.8116\n",
      "Epoch 140/10000\n",
      "24/24 [==============================] - 1s 34ms/step - loss: 0.2637 - accuracy: 0.9403 - f1_score: 0.9009 - val_loss: 0.3630 - val_accuracy: 0.9136 - val_f1_score: 0.8116\n",
      "Epoch 141/10000\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.2544 - accuracy: 0.9389 - f1_score: 0.8826 - val_loss: 0.3566 - val_accuracy: 0.9136 - val_f1_score: 0.8116\n",
      "Epoch 142/10000\n",
      "24/24 [==============================] - 1s 32ms/step - loss: 0.2951 - accuracy: 0.9335 - f1_score: 0.8803 - val_loss: 0.3560 - val_accuracy: 0.9136 - val_f1_score: 0.8116\n",
      "Epoch 143/10000\n",
      "24/24 [==============================] - 1s 34ms/step - loss: 0.2833 - accuracy: 0.9199 - f1_score: 0.8707 - val_loss: 0.3553 - val_accuracy: 0.9136 - val_f1_score: 0.8116\n",
      "Epoch 144/10000\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.2610 - accuracy: 0.9362 - f1_score: 0.8877 - val_loss: 0.3341 - val_accuracy: 0.9074 - val_f1_score: 0.8027\n",
      "Epoch 145/10000\n",
      "24/24 [==============================] - 1s 32ms/step - loss: 0.2736 - accuracy: 0.9349 - f1_score: 0.8867 - val_loss: 0.3365 - val_accuracy: 0.9074 - val_f1_score: 0.8027\n",
      "Epoch 146/10000\n",
      "24/24 [==============================] - 1s 34ms/step - loss: 0.2726 - accuracy: 0.9335 - f1_score: 0.8944 - val_loss: 0.3403 - val_accuracy: 0.9074 - val_f1_score: 0.8027\n",
      "Epoch 147/10000\n",
      "24/24 [==============================] - 1s 32ms/step - loss: 0.2471 - accuracy: 0.9362 - f1_score: 0.8853 - val_loss: 0.3426 - val_accuracy: 0.9074 - val_f1_score: 0.8027\n",
      "Epoch 148/10000\n",
      "24/24 [==============================] - 1s 32ms/step - loss: 0.2485 - accuracy: 0.9417 - f1_score: 0.9024 - val_loss: 0.3418 - val_accuracy: 0.9074 - val_f1_score: 0.8027\n",
      "Epoch 149/10000\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.2563 - accuracy: 0.9199 - f1_score: 0.8735 - val_loss: 0.3397 - val_accuracy: 0.9074 - val_f1_score: 0.8027\n",
      "Epoch 150/10000\n",
      "24/24 [==============================] - 1s 32ms/step - loss: 0.2457 - accuracy: 0.9349 - f1_score: 0.8903 - val_loss: 0.3357 - val_accuracy: 0.9074 - val_f1_score: 0.8027\n",
      "Epoch 151/10000\n",
      "24/24 [==============================] - 1s 32ms/step - loss: 0.2327 - accuracy: 0.9417 - f1_score: 0.8871 - val_loss: 0.3351 - val_accuracy: 0.9074 - val_f1_score: 0.8027\n",
      "Epoch 152/10000\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.2530 - accuracy: 0.9376 - f1_score: 0.9055 - val_loss: 0.3315 - val_accuracy: 0.9074 - val_f1_score: 0.8027\n",
      "Epoch 153/10000\n",
      "24/24 [==============================] - 1s 32ms/step - loss: 0.2646 - accuracy: 0.9362 - f1_score: 0.9029 - val_loss: 0.3307 - val_accuracy: 0.9074 - val_f1_score: 0.8027\n",
      "Epoch 154/10000\n",
      "24/24 [==============================] - 1s 32ms/step - loss: 0.2561 - accuracy: 0.9322 - f1_score: 0.8936 - val_loss: 0.3310 - val_accuracy: 0.9074 - val_f1_score: 0.8027\n",
      "Epoch 155/10000\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.2366 - accuracy: 0.9498 - f1_score: 0.8947 - val_loss: 0.3262 - val_accuracy: 0.9074 - val_f1_score: 0.8027\n",
      "Epoch 156/10000\n",
      "24/24 [==============================] - 1s 32ms/step - loss: 0.2455 - accuracy: 0.9430 - f1_score: 0.8930 - val_loss: 0.3251 - val_accuracy: 0.9074 - val_f1_score: 0.8027\n",
      "Epoch 157/10000\n",
      "24/24 [==============================] - 1s 31ms/step - loss: 0.2352 - accuracy: 0.9444 - f1_score: 0.8999 - val_loss: 0.3209 - val_accuracy: 0.9136 - val_f1_score: 0.8087\n",
      "Epoch 158/10000\n",
      "24/24 [==============================] - 1s 31ms/step - loss: 0.2243 - accuracy: 0.9457 - f1_score: 0.9159 - val_loss: 0.3208 - val_accuracy: 0.9074 - val_f1_score: 0.8027\n",
      "Epoch 159/10000\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.2490 - accuracy: 0.9376 - f1_score: 0.8893 - val_loss: 0.3189 - val_accuracy: 0.9136 - val_f1_score: 0.8087\n",
      "Epoch 160/10000\n",
      "24/24 [==============================] - 1s 31ms/step - loss: 0.2451 - accuracy: 0.9281 - f1_score: 0.8760 - val_loss: 0.3191 - val_accuracy: 0.9136 - val_f1_score: 0.8087\n",
      "Epoch 161/10000\n",
      "24/24 [==============================] - 1s 32ms/step - loss: 0.2389 - accuracy: 0.9322 - f1_score: 0.8701 - val_loss: 0.3185 - val_accuracy: 0.9136 - val_f1_score: 0.8087\n",
      "Epoch 162/10000\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.2264 - accuracy: 0.9444 - f1_score: 0.9005 - val_loss: 0.3200 - val_accuracy: 0.9136 - val_f1_score: 0.8087\n",
      "Epoch 163/10000\n",
      "24/24 [==============================] - 1s 32ms/step - loss: 0.2385 - accuracy: 0.9471 - f1_score: 0.8888 - val_loss: 0.3178 - val_accuracy: 0.9136 - val_f1_score: 0.8116\n",
      "Epoch 164/10000\n",
      "24/24 [==============================] - 1s 31ms/step - loss: 0.2200 - accuracy: 0.9376 - f1_score: 0.8698 - val_loss: 0.3149 - val_accuracy: 0.9136 - val_f1_score: 0.8087\n",
      "Epoch 165/10000\n",
      "24/24 [==============================] - 1s 32ms/step - loss: 0.2165 - accuracy: 0.9430 - f1_score: 0.8904 - val_loss: 0.3105 - val_accuracy: 0.9136 - val_f1_score: 0.8087\n",
      "Epoch 166/10000\n",
      "24/24 [==============================] - 1s 31ms/step - loss: 0.2414 - accuracy: 0.9254 - f1_score: 0.8623 - val_loss: 0.3093 - val_accuracy: 0.9136 - val_f1_score: 0.8087\n",
      "Epoch 167/10000\n",
      "24/24 [==============================] - 1s 31ms/step - loss: 0.2265 - accuracy: 0.9403 - f1_score: 0.8886 - val_loss: 0.3044 - val_accuracy: 0.9198 - val_f1_score: 0.8284\n",
      "Epoch 168/10000\n",
      "24/24 [==============================] - 1s 32ms/step - loss: 0.2365 - accuracy: 0.9362 - f1_score: 0.8887 - val_loss: 0.3028 - val_accuracy: 0.9198 - val_f1_score: 0.8284\n",
      "Epoch 169/10000\n",
      "24/24 [==============================] - 1s 31ms/step - loss: 0.2149 - accuracy: 0.9471 - f1_score: 0.9128 - val_loss: 0.3027 - val_accuracy: 0.9198 - val_f1_score: 0.8284\n",
      "Epoch 170/10000\n",
      "24/24 [==============================] - 1s 31ms/step - loss: 0.2182 - accuracy: 0.9471 - f1_score: 0.9109 - val_loss: 0.3016 - val_accuracy: 0.9198 - val_f1_score: 0.8284\n",
      "Epoch 171/10000\n",
      "24/24 [==============================] - 1s 34ms/step - loss: 0.2200 - accuracy: 0.9281 - f1_score: 0.8789 - val_loss: 0.2996 - val_accuracy: 0.9198 - val_f1_score: 0.8284\n",
      "Epoch 172/10000\n",
      "24/24 [==============================] - 1s 31ms/step - loss: 0.2293 - accuracy: 0.9552 - f1_score: 0.9326 - val_loss: 0.2986 - val_accuracy: 0.9198 - val_f1_score: 0.8284\n",
      "Epoch 173/10000\n",
      "24/24 [==============================] - 1s 32ms/step - loss: 0.2011 - accuracy: 0.9457 - f1_score: 0.8994 - val_loss: 0.2847 - val_accuracy: 0.9259 - val_f1_score: 0.8346\n",
      "Epoch 174/10000\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.2055 - accuracy: 0.9512 - f1_score: 0.9099 - val_loss: 0.2851 - val_accuracy: 0.9259 - val_f1_score: 0.8346\n",
      "Epoch 175/10000\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.2024 - accuracy: 0.9525 - f1_score: 0.9165 - val_loss: 0.2869 - val_accuracy: 0.9198 - val_f1_score: 0.8284\n",
      "Epoch 176/10000\n",
      "24/24 [==============================] - 1s 32ms/step - loss: 0.2318 - accuracy: 0.9430 - f1_score: 0.9112 - val_loss: 0.2868 - val_accuracy: 0.9198 - val_f1_score: 0.8284\n",
      "Epoch 177/10000\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.2064 - accuracy: 0.9417 - f1_score: 0.8883 - val_loss: 0.2851 - val_accuracy: 0.9259 - val_f1_score: 0.8346\n",
      "Epoch 178/10000\n",
      "24/24 [==============================] - 1s 31ms/step - loss: 0.2013 - accuracy: 0.9525 - f1_score: 0.9134 - val_loss: 0.2857 - val_accuracy: 0.9198 - val_f1_score: 0.8284\n",
      "Epoch 179/10000\n",
      "24/24 [==============================] - 1s 31ms/step - loss: 0.2090 - accuracy: 0.9444 - f1_score: 0.9055 - val_loss: 0.2856 - val_accuracy: 0.9198 - val_f1_score: 0.8284\n",
      "Epoch 180/10000\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.1934 - accuracy: 0.9566 - f1_score: 0.9132 - val_loss: 0.2839 - val_accuracy: 0.9198 - val_f1_score: 0.8284\n",
      "Epoch 181/10000\n",
      "24/24 [==============================] - 1s 31ms/step - loss: 0.2729 - accuracy: 0.9376 - f1_score: 0.9028 - val_loss: 0.2831 - val_accuracy: 0.9259 - val_f1_score: 0.8346\n",
      "Epoch 182/10000\n",
      "24/24 [==============================] - 1s 31ms/step - loss: 0.2420 - accuracy: 0.9322 - f1_score: 0.8862 - val_loss: 0.2802 - val_accuracy: 0.9259 - val_f1_score: 0.8346\n",
      "Epoch 183/10000\n",
      "24/24 [==============================] - 1s 32ms/step - loss: 0.2014 - accuracy: 0.9579 - f1_score: 0.9110 - val_loss: 0.2770 - val_accuracy: 0.9259 - val_f1_score: 0.8346\n",
      "Epoch 184/10000\n",
      "24/24 [==============================] - 1s 31ms/step - loss: 0.2027 - accuracy: 0.9539 - f1_score: 0.9177 - val_loss: 0.2767 - val_accuracy: 0.9259 - val_f1_score: 0.8346\n",
      "Epoch 185/10000\n",
      "24/24 [==============================] - 1s 32ms/step - loss: 0.1971 - accuracy: 0.9593 - f1_score: 0.9327 - val_loss: 0.2764 - val_accuracy: 0.9259 - val_f1_score: 0.8346\n",
      "Epoch 186/10000\n",
      "24/24 [==============================] - 1s 31ms/step - loss: 0.2207 - accuracy: 0.9471 - f1_score: 0.9205 - val_loss: 0.2757 - val_accuracy: 0.9259 - val_f1_score: 0.8346\n",
      "Epoch 187/10000\n",
      "24/24 [==============================] - 1s 31ms/step - loss: 0.2074 - accuracy: 0.9430 - f1_score: 0.9055 - val_loss: 0.2753 - val_accuracy: 0.9259 - val_f1_score: 0.8346\n",
      "Epoch 188/10000\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.2311 - accuracy: 0.9403 - f1_score: 0.9057 - val_loss: 0.2751 - val_accuracy: 0.9259 - val_f1_score: 0.8346\n",
      "Epoch 189/10000\n",
      "24/24 [==============================] - 1s 32ms/step - loss: 0.2164 - accuracy: 0.9349 - f1_score: 0.8771 - val_loss: 0.2763 - val_accuracy: 0.9259 - val_f1_score: 0.8346\n",
      "Epoch 190/10000\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.2120 - accuracy: 0.9417 - f1_score: 0.8974 - val_loss: 0.2734 - val_accuracy: 0.9259 - val_f1_score: 0.8346\n",
      "Epoch 191/10000\n",
      "24/24 [==============================] - 1s 31ms/step - loss: 0.1781 - accuracy: 0.9579 - f1_score: 0.9293 - val_loss: 0.2720 - val_accuracy: 0.9259 - val_f1_score: 0.8346\n",
      "Epoch 192/10000\n",
      "24/24 [==============================] - 1s 32ms/step - loss: 0.1958 - accuracy: 0.9539 - f1_score: 0.9140 - val_loss: 0.2696 - val_accuracy: 0.9321 - val_f1_score: 0.8409\n",
      "Epoch 193/10000\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.2217 - accuracy: 0.9389 - f1_score: 0.8854 - val_loss: 0.2690 - val_accuracy: 0.9321 - val_f1_score: 0.8409\n",
      "Epoch 194/10000\n",
      "24/24 [==============================] - 1s 31ms/step - loss: 0.1968 - accuracy: 0.9552 - f1_score: 0.9251 - val_loss: 0.2565 - val_accuracy: 0.9321 - val_f1_score: 0.8409\n",
      "Epoch 195/10000\n",
      "24/24 [==============================] - 1s 31ms/step - loss: 0.1877 - accuracy: 0.9593 - f1_score: 0.9230 - val_loss: 0.2585 - val_accuracy: 0.9321 - val_f1_score: 0.8409\n",
      "Epoch 196/10000\n",
      "24/24 [==============================] - 1s 32ms/step - loss: 0.1905 - accuracy: 0.9471 - f1_score: 0.9048 - val_loss: 0.2568 - val_accuracy: 0.9383 - val_f1_score: 0.8475\n",
      "Epoch 197/10000\n",
      "24/24 [==============================] - 1s 31ms/step - loss: 0.1899 - accuracy: 0.9498 - f1_score: 0.9168 - val_loss: 0.2577 - val_accuracy: 0.9383 - val_f1_score: 0.8475\n",
      "Epoch 198/10000\n",
      "24/24 [==============================] - 1s 31ms/step - loss: 0.1839 - accuracy: 0.9512 - f1_score: 0.9066 - val_loss: 0.2569 - val_accuracy: 0.9383 - val_f1_score: 0.8475\n",
      "Epoch 199/10000\n",
      "24/24 [==============================] - 1s 32ms/step - loss: 0.1795 - accuracy: 0.9552 - f1_score: 0.9262 - val_loss: 0.2581 - val_accuracy: 0.9383 - val_f1_score: 0.8475\n",
      "Epoch 200/10000\n",
      "24/24 [==============================] - 1s 31ms/step - loss: 0.2019 - accuracy: 0.9498 - f1_score: 0.9050 - val_loss: 0.2583 - val_accuracy: 0.9383 - val_f1_score: 0.8475\n",
      "Epoch 201/10000\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.1830 - accuracy: 0.9525 - f1_score: 0.9190 - val_loss: 0.2572 - val_accuracy: 0.9383 - val_f1_score: 0.8475\n",
      "Epoch 202/10000\n",
      "24/24 [==============================] - 1s 31ms/step - loss: 0.1530 - accuracy: 0.9607 - f1_score: 0.9280 - val_loss: 0.2573 - val_accuracy: 0.9383 - val_f1_score: 0.8475\n",
      "Epoch 203/10000\n",
      "24/24 [==============================] - 1s 31ms/step - loss: 0.2125 - accuracy: 0.9457 - f1_score: 0.9169 - val_loss: 0.2568 - val_accuracy: 0.9383 - val_f1_score: 0.8475\n",
      "Epoch 204/10000\n",
      "24/24 [==============================] - 1s 32ms/step - loss: 0.1698 - accuracy: 0.9620 - f1_score: 0.9266 - val_loss: 0.2565 - val_accuracy: 0.9383 - val_f1_score: 0.8475\n",
      "Epoch 205/10000\n",
      "24/24 [==============================] - 1s 31ms/step - loss: 0.1743 - accuracy: 0.9593 - f1_score: 0.9176 - val_loss: 0.2551 - val_accuracy: 0.9383 - val_f1_score: 0.8475\n",
      "Epoch 206/10000\n",
      "24/24 [==============================] - 1s 31ms/step - loss: 0.1938 - accuracy: 0.9484 - f1_score: 0.9116 - val_loss: 0.2564 - val_accuracy: 0.9383 - val_f1_score: 0.8475\n",
      "Epoch 207/10000\n",
      "24/24 [==============================] - 1s 32ms/step - loss: 0.1769 - accuracy: 0.9607 - f1_score: 0.9232 - val_loss: 0.2555 - val_accuracy: 0.9383 - val_f1_score: 0.8475\n",
      "Epoch 208/10000\n",
      "24/24 [==============================] - 1s 30ms/step - loss: 0.1692 - accuracy: 0.9607 - f1_score: 0.9316 - val_loss: 0.2527 - val_accuracy: 0.9383 - val_f1_score: 0.8475\n",
      "Epoch 209/10000\n",
      "24/24 [==============================] - 1s 30ms/step - loss: 0.1446 - accuracy: 0.9729 - f1_score: 0.9502 - val_loss: 0.2522 - val_accuracy: 0.9383 - val_f1_score: 0.8475\n",
      "Epoch 210/10000\n",
      "24/24 [==============================] - 1s 31ms/step - loss: 0.1975 - accuracy: 0.9484 - f1_score: 0.9177 - val_loss: 0.2535 - val_accuracy: 0.9383 - val_f1_score: 0.8475\n",
      "Epoch 211/10000\n",
      "24/24 [==============================] - 1s 31ms/step - loss: 0.1737 - accuracy: 0.9512 - f1_score: 0.9069 - val_loss: 0.2519 - val_accuracy: 0.9383 - val_f1_score: 0.8475\n",
      "Epoch 212/10000\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.1771 - accuracy: 0.9444 - f1_score: 0.8974 - val_loss: 0.2522 - val_accuracy: 0.9383 - val_f1_score: 0.8475\n",
      "Epoch 213/10000\n",
      "24/24 [==============================] - 1s 31ms/step - loss: 0.1947 - accuracy: 0.9552 - f1_score: 0.9159 - val_loss: 0.2463 - val_accuracy: 0.9383 - val_f1_score: 0.8475\n",
      "Epoch 214/10000\n",
      "24/24 [==============================] - 1s 31ms/step - loss: 0.1654 - accuracy: 0.9634 - f1_score: 0.9304 - val_loss: 0.2479 - val_accuracy: 0.9383 - val_f1_score: 0.8346\n",
      "Epoch 215/10000\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.1606 - accuracy: 0.9552 - f1_score: 0.9202 - val_loss: 0.2482 - val_accuracy: 0.9383 - val_f1_score: 0.8346\n",
      "Epoch 216/10000\n",
      "24/24 [==============================] - 1s 31ms/step - loss: 0.1853 - accuracy: 0.9471 - f1_score: 0.9082 - val_loss: 0.2480 - val_accuracy: 0.9383 - val_f1_score: 0.8346\n",
      "Epoch 217/10000\n",
      "24/24 [==============================] - 1s 32ms/step - loss: 0.1749 - accuracy: 0.9539 - f1_score: 0.9178 - val_loss: 0.2476 - val_accuracy: 0.9383 - val_f1_score: 0.8346\n",
      "Epoch 218/10000\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.1551 - accuracy: 0.9498 - f1_score: 0.9065 - val_loss: 0.2465 - val_accuracy: 0.9383 - val_f1_score: 0.8346\n",
      "Epoch 219/10000\n",
      "24/24 [==============================] - 1s 31ms/step - loss: 0.1678 - accuracy: 0.9539 - f1_score: 0.9270 - val_loss: 0.2450 - val_accuracy: 0.9383 - val_f1_score: 0.8346\n",
      "Epoch 220/10000\n",
      "24/24 [==============================] - 1s 32ms/step - loss: 0.1725 - accuracy: 0.9579 - f1_score: 0.9137 - val_loss: 0.2375 - val_accuracy: 0.9383 - val_f1_score: 0.8346\n",
      "Epoch 221/10000\n",
      "24/24 [==============================] - 1s 31ms/step - loss: 0.1916 - accuracy: 0.9498 - f1_score: 0.9072 - val_loss: 0.2372 - val_accuracy: 0.9383 - val_f1_score: 0.8346\n",
      "Epoch 222/10000\n",
      "24/24 [==============================] - 1s 31ms/step - loss: 0.1458 - accuracy: 0.9634 - f1_score: 0.9262 - val_loss: 0.2391 - val_accuracy: 0.9383 - val_f1_score: 0.8346\n",
      "Epoch 223/10000\n",
      "24/24 [==============================] - 1s 32ms/step - loss: 0.1780 - accuracy: 0.9566 - f1_score: 0.9177 - val_loss: 0.2396 - val_accuracy: 0.9383 - val_f1_score: 0.8346\n",
      "Epoch 224/10000\n",
      "24/24 [==============================] - 1s 31ms/step - loss: 0.1601 - accuracy: 0.9620 - f1_score: 0.9162 - val_loss: 0.2400 - val_accuracy: 0.9383 - val_f1_score: 0.8346\n",
      "Epoch 225/10000\n",
      "24/24 [==============================] - 1s 31ms/step - loss: 0.1637 - accuracy: 0.9471 - f1_score: 0.9104 - val_loss: 0.2400 - val_accuracy: 0.9383 - val_f1_score: 0.8346\n",
      "Epoch 226/10000\n",
      "24/24 [==============================] - 1s 32ms/step - loss: 0.1683 - accuracy: 0.9607 - f1_score: 0.9175 - val_loss: 0.2391 - val_accuracy: 0.9383 - val_f1_score: 0.8475\n",
      "Epoch 227/10000\n",
      "24/24 [==============================] - 1s 31ms/step - loss: 0.1659 - accuracy: 0.9484 - f1_score: 0.9103 - val_loss: 0.2382 - val_accuracy: 0.9383 - val_f1_score: 0.8346\n",
      "Epoch 228/10000\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.1560 - accuracy: 0.9674 - f1_score: 0.9300 - val_loss: 0.2387 - val_accuracy: 0.9383 - val_f1_score: 0.8346\n",
      "Epoch 229/10000\n",
      "24/24 [==============================] - 1s 31ms/step - loss: 0.1457 - accuracy: 0.9607 - f1_score: 0.9220 - val_loss: 0.2381 - val_accuracy: 0.9383 - val_f1_score: 0.8346\n",
      "Epoch 230/10000\n",
      "24/24 [==============================] - 1s 31ms/step - loss: 0.1524 - accuracy: 0.9647 - f1_score: 0.9322 - val_loss: 0.2328 - val_accuracy: 0.9444 - val_f1_score: 0.8542\n",
      "Epoch 231/10000\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.1538 - accuracy: 0.9539 - f1_score: 0.9132 - val_loss: 0.2345 - val_accuracy: 0.9444 - val_f1_score: 0.8542\n",
      "Epoch 232/10000\n",
      "24/24 [==============================] - 1s 31ms/step - loss: 0.1520 - accuracy: 0.9539 - f1_score: 0.9292 - val_loss: 0.2334 - val_accuracy: 0.9444 - val_f1_score: 0.8542\n",
      "Epoch 233/10000\n",
      "24/24 [==============================] - 1s 32ms/step - loss: 0.1638 - accuracy: 0.9620 - f1_score: 0.9293 - val_loss: 0.2334 - val_accuracy: 0.9444 - val_f1_score: 0.8542\n",
      "Epoch 234/10000\n",
      "24/24 [==============================] - 1s 31ms/step - loss: 0.1410 - accuracy: 0.9579 - f1_score: 0.9221 - val_loss: 0.2333 - val_accuracy: 0.9444 - val_f1_score: 0.8542\n",
      "Epoch 235/10000\n",
      "24/24 [==============================] - 1s 31ms/step - loss: 0.1386 - accuracy: 0.9634 - f1_score: 0.9356 - val_loss: 0.2346 - val_accuracy: 0.9444 - val_f1_score: 0.8542\n",
      "Epoch 236/10000\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.1453 - accuracy: 0.9647 - f1_score: 0.9469 - val_loss: 0.2344 - val_accuracy: 0.9444 - val_f1_score: 0.8542\n",
      "Epoch 237/10000\n",
      "24/24 [==============================] - 1s 32ms/step - loss: 0.1330 - accuracy: 0.9634 - f1_score: 0.9356 - val_loss: 0.2338 - val_accuracy: 0.9444 - val_f1_score: 0.8542\n",
      "Epoch 238/10000\n",
      "24/24 [==============================] - 1s 31ms/step - loss: 0.1470 - accuracy: 0.9620 - f1_score: 0.9288 - val_loss: 0.2331 - val_accuracy: 0.9444 - val_f1_score: 0.8542\n",
      "Epoch 239/10000\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.1523 - accuracy: 0.9607 - f1_score: 0.9301 - val_loss: 0.2311 - val_accuracy: 0.9444 - val_f1_score: 0.8542\n",
      "Epoch 240/10000\n",
      "24/24 [==============================] - 1s 32ms/step - loss: 0.1415 - accuracy: 0.9634 - f1_score: 0.9349 - val_loss: 0.2318 - val_accuracy: 0.9444 - val_f1_score: 0.8542\n",
      "Epoch 241/10000\n",
      "24/24 [==============================] - 1s 32ms/step - loss: 0.1483 - accuracy: 0.9552 - f1_score: 0.9185 - val_loss: 0.2330 - val_accuracy: 0.9444 - val_f1_score: 0.8542\n",
      "Epoch 242/10000\n",
      "24/24 [==============================] - 1s 31ms/step - loss: 0.1842 - accuracy: 0.9457 - f1_score: 0.9209 - val_loss: 0.2327 - val_accuracy: 0.9444 - val_f1_score: 0.8542\n",
      "Epoch 243/10000\n",
      "24/24 [==============================] - 1s 31ms/step - loss: 0.1639 - accuracy: 0.9498 - f1_score: 0.9067 - val_loss: 0.2330 - val_accuracy: 0.9383 - val_f1_score: 0.8448\n",
      "Epoch 244/10000\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.1390 - accuracy: 0.9579 - f1_score: 0.9262 - val_loss: 0.2322 - val_accuracy: 0.9383 - val_f1_score: 0.8448\n",
      "Epoch 245/10000\n",
      "24/24 [==============================] - 1s 31ms/step - loss: 0.1408 - accuracy: 0.9620 - f1_score: 0.9326 - val_loss: 0.2320 - val_accuracy: 0.9383 - val_f1_score: 0.8448\n",
      "Epoch 246/10000\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.1434 - accuracy: 0.9607 - f1_score: 0.9250 - val_loss: 0.2320 - val_accuracy: 0.9383 - val_f1_score: 0.8448\n",
      "Epoch 247/10000\n",
      "24/24 [==============================] - 1s 31ms/step - loss: 0.1478 - accuracy: 0.9634 - f1_score: 0.9241 - val_loss: 0.2337 - val_accuracy: 0.9444 - val_f1_score: 0.8542\n",
      "Epoch 248/10000\n",
      "24/24 [==============================] - 1s 31ms/step - loss: 0.1323 - accuracy: 0.9620 - f1_score: 0.9305 - val_loss: 0.2330 - val_accuracy: 0.9444 - val_f1_score: 0.8542\n",
      "Epoch 249/10000\n",
      "24/24 [==============================] - 1s 32ms/step - loss: 0.1413 - accuracy: 0.9579 - f1_score: 0.9151 - val_loss: 0.2320 - val_accuracy: 0.9444 - val_f1_score: 0.8542\n",
      "Epoch 250/10000\n",
      "24/24 [==============================] - 1s 32ms/step - loss: 0.1358 - accuracy: 0.9620 - f1_score: 0.9409 - val_loss: 0.2302 - val_accuracy: 0.9383 - val_f1_score: 0.8448\n",
      "Epoch 251/10000\n",
      "24/24 [==============================] - 1s 32ms/step - loss: 0.1397 - accuracy: 0.9566 - f1_score: 0.9128 - val_loss: 0.2292 - val_accuracy: 0.9383 - val_f1_score: 0.8448\n",
      "Epoch 252/10000\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.1207 - accuracy: 0.9674 - f1_score: 0.9278 - val_loss: 0.2296 - val_accuracy: 0.9383 - val_f1_score: 0.8448\n",
      "Epoch 253/10000\n",
      "24/24 [==============================] - 1s 32ms/step - loss: 0.1328 - accuracy: 0.9674 - f1_score: 0.9334 - val_loss: 0.2309 - val_accuracy: 0.9444 - val_f1_score: 0.8542\n",
      "Epoch 254/10000\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.1404 - accuracy: 0.9579 - f1_score: 0.9136 - val_loss: 0.2316 - val_accuracy: 0.9444 - val_f1_score: 0.8542\n",
      "Epoch 255/10000\n",
      "24/24 [==============================] - 1s 32ms/step - loss: 0.1330 - accuracy: 0.9756 - f1_score: 0.9460 - val_loss: 0.2317 - val_accuracy: 0.9444 - val_f1_score: 0.8542\n",
      "Epoch 256/10000\n",
      "24/24 [==============================] - 1s 31ms/step - loss: 0.1381 - accuracy: 0.9579 - f1_score: 0.9223 - val_loss: 0.2314 - val_accuracy: 0.9444 - val_f1_score: 0.8542\n",
      "Epoch 257/10000\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.1255 - accuracy: 0.9607 - f1_score: 0.9256 - val_loss: 0.2321 - val_accuracy: 0.9444 - val_f1_score: 0.8542\n",
      "Epoch 258/10000\n",
      "24/24 [==============================] - 1s 31ms/step - loss: 0.1304 - accuracy: 0.9620 - f1_score: 0.9071 - val_loss: 0.2298 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 259/10000\n",
      "24/24 [==============================] - 1s 32ms/step - loss: 0.1453 - accuracy: 0.9607 - f1_score: 0.9221 - val_loss: 0.2278 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 260/10000\n",
      "24/24 [==============================] - 1s 31ms/step - loss: 0.1758 - accuracy: 0.9444 - f1_score: 0.8908 - val_loss: 0.2286 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 261/10000\n",
      "24/24 [==============================] - 1s 31ms/step - loss: 0.1201 - accuracy: 0.9674 - f1_score: 0.9344 - val_loss: 0.2278 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 262/10000\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.1360 - accuracy: 0.9661 - f1_score: 0.9343 - val_loss: 0.2207 - val_accuracy: 0.9444 - val_f1_score: 0.8542\n",
      "Epoch 263/10000\n",
      "24/24 [==============================] - 1s 31ms/step - loss: 0.1266 - accuracy: 0.9674 - f1_score: 0.9406 - val_loss: 0.2227 - val_accuracy: 0.9444 - val_f1_score: 0.8542\n",
      "Epoch 264/10000\n",
      "24/24 [==============================] - 1s 32ms/step - loss: 0.1524 - accuracy: 0.9539 - f1_score: 0.9155 - val_loss: 0.2229 - val_accuracy: 0.9444 - val_f1_score: 0.8542\n",
      "Epoch 265/10000\n",
      "24/24 [==============================] - 1s 31ms/step - loss: 0.1492 - accuracy: 0.9512 - f1_score: 0.9068 - val_loss: 0.2234 - val_accuracy: 0.9444 - val_f1_score: 0.8542\n",
      "Epoch 266/10000\n",
      "24/24 [==============================] - 1s 32ms/step - loss: 0.1262 - accuracy: 0.9634 - f1_score: 0.9352 - val_loss: 0.2240 - val_accuracy: 0.9444 - val_f1_score: 0.8542\n",
      "Epoch 267/10000\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.1252 - accuracy: 0.9674 - f1_score: 0.9467 - val_loss: 0.2250 - val_accuracy: 0.9444 - val_f1_score: 0.8542\n",
      "Epoch 268/10000\n",
      "24/24 [==============================] - 1s 32ms/step - loss: 0.1114 - accuracy: 0.9674 - f1_score: 0.9315 - val_loss: 0.2247 - val_accuracy: 0.9444 - val_f1_score: 0.8542\n",
      "Epoch 269/10000\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.1164 - accuracy: 0.9701 - f1_score: 0.9340 - val_loss: 0.2190 - val_accuracy: 0.9444 - val_f1_score: 0.8542\n",
      "Epoch 270/10000\n",
      "24/24 [==============================] - 1s 31ms/step - loss: 0.1573 - accuracy: 0.9566 - f1_score: 0.9168 - val_loss: 0.2206 - val_accuracy: 0.9444 - val_f1_score: 0.8542\n",
      "Epoch 271/10000\n",
      "24/24 [==============================] - 1s 32ms/step - loss: 0.1243 - accuracy: 0.9566 - f1_score: 0.8990 - val_loss: 0.2207 - val_accuracy: 0.9444 - val_f1_score: 0.8542\n",
      "Epoch 272/10000\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.1418 - accuracy: 0.9566 - f1_score: 0.9232 - val_loss: 0.2212 - val_accuracy: 0.9444 - val_f1_score: 0.8542\n",
      "Epoch 273/10000\n",
      "24/24 [==============================] - 1s 32ms/step - loss: 0.1145 - accuracy: 0.9729 - f1_score: 0.9454 - val_loss: 0.2182 - val_accuracy: 0.9383 - val_f1_score: 0.8448\n",
      "Epoch 274/10000\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.1015 - accuracy: 0.9756 - f1_score: 0.9351 - val_loss: 0.2174 - val_accuracy: 0.9444 - val_f1_score: 0.8542\n",
      "Epoch 275/10000\n",
      "24/24 [==============================] - 1s 31ms/step - loss: 0.1406 - accuracy: 0.9579 - f1_score: 0.9295 - val_loss: 0.2184 - val_accuracy: 0.9444 - val_f1_score: 0.8542\n",
      "Epoch 276/10000\n",
      "24/24 [==============================] - 1s 31ms/step - loss: 0.1107 - accuracy: 0.9742 - f1_score: 0.9448 - val_loss: 0.2190 - val_accuracy: 0.9444 - val_f1_score: 0.8542\n",
      "Epoch 277/10000\n",
      "24/24 [==============================] - 1s 34ms/step - loss: 0.1204 - accuracy: 0.9607 - f1_score: 0.9251 - val_loss: 0.2194 - val_accuracy: 0.9444 - val_f1_score: 0.8542\n",
      "Epoch 278/10000\n",
      "24/24 [==============================] - 1s 31ms/step - loss: 0.1199 - accuracy: 0.9715 - f1_score: 0.9385 - val_loss: 0.2192 - val_accuracy: 0.9444 - val_f1_score: 0.8542\n",
      "Epoch 279/10000\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.1436 - accuracy: 0.9566 - f1_score: 0.9219 - val_loss: 0.2209 - val_accuracy: 0.9444 - val_f1_score: 0.8542\n",
      "Epoch 280/10000\n",
      "24/24 [==============================] - 1s 31ms/step - loss: 0.1395 - accuracy: 0.9674 - f1_score: 0.9389 - val_loss: 0.2209 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 281/10000\n",
      "24/24 [==============================] - 1s 31ms/step - loss: 0.1188 - accuracy: 0.9620 - f1_score: 0.9268 - val_loss: 0.2204 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 282/10000\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.1266 - accuracy: 0.9647 - f1_score: 0.9358 - val_loss: 0.2180 - val_accuracy: 0.9383 - val_f1_score: 0.8448\n",
      "Epoch 283/10000\n",
      "24/24 [==============================] - 1s 31ms/step - loss: 0.1102 - accuracy: 0.9701 - f1_score: 0.9439 - val_loss: 0.2204 - val_accuracy: 0.9383 - val_f1_score: 0.8448\n",
      "Epoch 284/10000\n",
      "24/24 [==============================] - 1s 34ms/step - loss: 0.1113 - accuracy: 0.9661 - f1_score: 0.9327 - val_loss: 0.2201 - val_accuracy: 0.9383 - val_f1_score: 0.8448\n",
      "Epoch 285/10000\n",
      "24/24 [==============================] - 1s 31ms/step - loss: 0.1335 - accuracy: 0.9552 - f1_score: 0.9081 - val_loss: 0.2215 - val_accuracy: 0.9444 - val_f1_score: 0.8542\n",
      "Epoch 286/10000\n",
      "24/24 [==============================] - 1s 32ms/step - loss: 0.1110 - accuracy: 0.9742 - f1_score: 0.9488 - val_loss: 0.2222 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 287/10000\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.1100 - accuracy: 0.9674 - f1_score: 0.9282 - val_loss: 0.2222 - val_accuracy: 0.9383 - val_f1_score: 0.8448\n",
      "Epoch 288/10000\n",
      "24/24 [==============================] - 1s 31ms/step - loss: 0.1145 - accuracy: 0.9701 - f1_score: 0.9338 - val_loss: 0.2220 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 289/10000\n",
      "24/24 [==============================] - 1s 34ms/step - loss: 0.1283 - accuracy: 0.9674 - f1_score: 0.9418 - val_loss: 0.2215 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 290/10000\n",
      "24/24 [==============================] - 1s 31ms/step - loss: 0.1198 - accuracy: 0.9661 - f1_score: 0.9253 - val_loss: 0.2208 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 291/10000\n",
      "24/24 [==============================] - 1s 32ms/step - loss: 0.1246 - accuracy: 0.9579 - f1_score: 0.9299 - val_loss: 0.2182 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 292/10000\n",
      "24/24 [==============================] - 1s 32ms/step - loss: 0.1069 - accuracy: 0.9701 - f1_score: 0.9328 - val_loss: 0.2178 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 293/10000\n",
      "24/24 [==============================] - 1s 31ms/step - loss: 0.1159 - accuracy: 0.9688 - f1_score: 0.9248 - val_loss: 0.2188 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 294/10000\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.1040 - accuracy: 0.9661 - f1_score: 0.9297 - val_loss: 0.2182 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 295/10000\n",
      "24/24 [==============================] - 1s 31ms/step - loss: 0.1172 - accuracy: 0.9701 - f1_score: 0.9442 - val_loss: 0.2188 - val_accuracy: 0.9383 - val_f1_score: 0.8448\n",
      "Epoch 296/10000\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.1064 - accuracy: 0.9661 - f1_score: 0.9234 - val_loss: 0.2187 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 297/10000\n",
      "24/24 [==============================] - 1s 32ms/step - loss: 0.1080 - accuracy: 0.9674 - f1_score: 0.9459 - val_loss: 0.2195 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 298/10000\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.1107 - accuracy: 0.9634 - f1_score: 0.9232 - val_loss: 0.2197 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 299/10000\n",
      "24/24 [==============================] - 1s 32ms/step - loss: 0.1176 - accuracy: 0.9647 - f1_score: 0.9282 - val_loss: 0.2199 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 300/10000\n",
      "24/24 [==============================] - 1s 31ms/step - loss: 0.1088 - accuracy: 0.9796 - f1_score: 0.9567 - val_loss: 0.2196 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 301/10000\n",
      "24/24 [==============================] - 1s 34ms/step - loss: 0.1115 - accuracy: 0.9715 - f1_score: 0.9384 - val_loss: 0.2192 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 302/10000\n",
      "24/24 [==============================] - 1s 32ms/step - loss: 0.0998 - accuracy: 0.9688 - f1_score: 0.9357 - val_loss: 0.2180 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 303/10000\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.1158 - accuracy: 0.9674 - f1_score: 0.9413 - val_loss: 0.2177 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 304/10000\n",
      "24/24 [==============================] - 1s 31ms/step - loss: 0.1172 - accuracy: 0.9661 - f1_score: 0.9381 - val_loss: 0.2180 - val_accuracy: 0.9383 - val_f1_score: 0.8448\n",
      "Epoch 305/10000\n",
      "24/24 [==============================] - 1s 32ms/step - loss: 0.1470 - accuracy: 0.9593 - f1_score: 0.9338 - val_loss: 0.2195 - val_accuracy: 0.9383 - val_f1_score: 0.8448\n",
      "Epoch 306/10000\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.1070 - accuracy: 0.9661 - f1_score: 0.9372 - val_loss: 0.2186 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 307/10000\n",
      "24/24 [==============================] - 1s 32ms/step - loss: 0.1215 - accuracy: 0.9647 - f1_score: 0.9243 - val_loss: 0.2182 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 308/10000\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.1148 - accuracy: 0.9661 - f1_score: 0.9338 - val_loss: 0.2172 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 309/10000\n",
      "24/24 [==============================] - 1s 32ms/step - loss: 0.1080 - accuracy: 0.9769 - f1_score: 0.9576 - val_loss: 0.2170 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 310/10000\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.1178 - accuracy: 0.9715 - f1_score: 0.9431 - val_loss: 0.2169 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 311/10000\n",
      "24/24 [==============================] - 1s 32ms/step - loss: 0.1405 - accuracy: 0.9552 - f1_score: 0.9254 - val_loss: 0.2169 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 312/10000\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.1010 - accuracy: 0.9715 - f1_score: 0.9375 - val_loss: 0.2172 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 313/10000\n",
      "24/24 [==============================] - 1s 31ms/step - loss: 0.1050 - accuracy: 0.9729 - f1_score: 0.9489 - val_loss: 0.2168 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 314/10000\n",
      "24/24 [==============================] - 1s 32ms/step - loss: 0.0972 - accuracy: 0.9701 - f1_score: 0.9395 - val_loss: 0.2162 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 315/10000\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.1140 - accuracy: 0.9688 - f1_score: 0.9382 - val_loss: 0.2157 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 316/10000\n",
      "24/24 [==============================] - 1s 31ms/step - loss: 0.1020 - accuracy: 0.9729 - f1_score: 0.9440 - val_loss: 0.2158 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 317/10000\n",
      "24/24 [==============================] - 1s 34ms/step - loss: 0.1150 - accuracy: 0.9647 - f1_score: 0.9400 - val_loss: 0.2159 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 318/10000\n",
      "24/24 [==============================] - 1s 32ms/step - loss: 0.0867 - accuracy: 0.9742 - f1_score: 0.9446 - val_loss: 0.2162 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 319/10000\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.1316 - accuracy: 0.9661 - f1_score: 0.9421 - val_loss: 0.2153 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 320/10000\n",
      "24/24 [==============================] - 1s 32ms/step - loss: 0.0994 - accuracy: 0.9715 - f1_score: 0.9458 - val_loss: 0.2154 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 321/10000\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.1017 - accuracy: 0.9756 - f1_score: 0.9494 - val_loss: 0.2154 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 322/10000\n",
      "24/24 [==============================] - 1s 31ms/step - loss: 0.0933 - accuracy: 0.9729 - f1_score: 0.9461 - val_loss: 0.2156 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 323/10000\n",
      "24/24 [==============================] - 1s 32ms/step - loss: 0.0914 - accuracy: 0.9783 - f1_score: 0.9549 - val_loss: 0.2156 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 324/10000\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.1250 - accuracy: 0.9647 - f1_score: 0.9358 - val_loss: 0.2154 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 325/10000\n",
      "24/24 [==============================] - 1s 32ms/step - loss: 0.0998 - accuracy: 0.9756 - f1_score: 0.9461 - val_loss: 0.2162 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 326/10000\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.1011 - accuracy: 0.9661 - f1_score: 0.9264 - val_loss: 0.2161 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 327/10000\n",
      "24/24 [==============================] - 1s 32ms/step - loss: 0.1000 - accuracy: 0.9742 - f1_score: 0.9448 - val_loss: 0.2154 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 328/10000\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.1080 - accuracy: 0.9688 - f1_score: 0.9317 - val_loss: 0.2155 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 329/10000\n",
      "24/24 [==============================] - 1s 32ms/step - loss: 0.1027 - accuracy: 0.9756 - f1_score: 0.9412 - val_loss: 0.2151 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 330/10000\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.1277 - accuracy: 0.9566 - f1_score: 0.9131 - val_loss: 0.2146 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 331/10000\n",
      "24/24 [==============================] - 1s 32ms/step - loss: 0.1081 - accuracy: 0.9688 - f1_score: 0.9361 - val_loss: 0.2142 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 332/10000\n",
      "24/24 [==============================] - 1s 31ms/step - loss: 0.1007 - accuracy: 0.9661 - f1_score: 0.9329 - val_loss: 0.2148 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 333/10000\n",
      "24/24 [==============================] - 1s 32ms/step - loss: 0.0943 - accuracy: 0.9688 - f1_score: 0.9387 - val_loss: 0.2147 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 334/10000\n",
      "24/24 [==============================] - 1s 31ms/step - loss: 0.1180 - accuracy: 0.9688 - f1_score: 0.9255 - val_loss: 0.2148 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 335/10000\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0977 - accuracy: 0.9729 - f1_score: 0.9462 - val_loss: 0.2145 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 336/10000\n",
      "24/24 [==============================] - 1s 30ms/step - loss: 0.1044 - accuracy: 0.9674 - f1_score: 0.9392 - val_loss: 0.2148 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 337/10000\n",
      "24/24 [==============================] - 1s 32ms/step - loss: 0.1006 - accuracy: 0.9729 - f1_score: 0.9505 - val_loss: 0.2138 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 338/10000\n",
      "24/24 [==============================] - 1s 31ms/step - loss: 0.0965 - accuracy: 0.9756 - f1_score: 0.9525 - val_loss: 0.2136 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 339/10000\n",
      "24/24 [==============================] - 1s 32ms/step - loss: 0.1196 - accuracy: 0.9661 - f1_score: 0.9330 - val_loss: 0.2123 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 340/10000\n",
      "24/24 [==============================] - 1s 31ms/step - loss: 0.0956 - accuracy: 0.9688 - f1_score: 0.9367 - val_loss: 0.2124 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 341/10000\n",
      "24/24 [==============================] - 1s 32ms/step - loss: 0.0969 - accuracy: 0.9729 - f1_score: 0.9325 - val_loss: 0.2119 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 342/10000\n",
      "24/24 [==============================] - 1s 31ms/step - loss: 0.0926 - accuracy: 0.9729 - f1_score: 0.9452 - val_loss: 0.2119 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 343/10000\n",
      "24/24 [==============================] - 1s 32ms/step - loss: 0.1007 - accuracy: 0.9634 - f1_score: 0.9343 - val_loss: 0.2118 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 344/10000\n",
      "24/24 [==============================] - 1s 32ms/step - loss: 0.0988 - accuracy: 0.9729 - f1_score: 0.9378 - val_loss: 0.2118 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 345/10000\n",
      "24/24 [==============================] - 1s 32ms/step - loss: 0.0953 - accuracy: 0.9783 - f1_score: 0.9628 - val_loss: 0.2129 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 346/10000\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.1135 - accuracy: 0.9620 - f1_score: 0.9263 - val_loss: 0.2131 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 347/10000\n",
      "24/24 [==============================] - 1s 32ms/step - loss: 0.0900 - accuracy: 0.9810 - f1_score: 0.9585 - val_loss: 0.2128 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 348/10000\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.1012 - accuracy: 0.9674 - f1_score: 0.9384 - val_loss: 0.2160 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 349/10000\n",
      "24/24 [==============================] - 1s 32ms/step - loss: 0.0903 - accuracy: 0.9715 - f1_score: 0.9392 - val_loss: 0.2150 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 350/10000\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0923 - accuracy: 0.9796 - f1_score: 0.9638 - val_loss: 0.2142 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 351/10000\n",
      "24/24 [==============================] - 1s 32ms/step - loss: 0.0862 - accuracy: 0.9769 - f1_score: 0.9480 - val_loss: 0.2135 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 352/10000\n",
      "24/24 [==============================] - 1s 34ms/step - loss: 0.1061 - accuracy: 0.9756 - f1_score: 0.9601 - val_loss: 0.2134 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 353/10000\n",
      "24/24 [==============================] - 1s 32ms/step - loss: 0.0917 - accuracy: 0.9729 - f1_score: 0.9388 - val_loss: 0.2132 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 354/10000\n",
      "24/24 [==============================] - 1s 32ms/step - loss: 0.1015 - accuracy: 0.9715 - f1_score: 0.9530 - val_loss: 0.2125 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 355/10000\n",
      "24/24 [==============================] - 1s 30ms/step - loss: 0.0833 - accuracy: 0.9729 - f1_score: 0.9436 - val_loss: 0.2113 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 356/10000\n",
      "24/24 [==============================] - 1s 32ms/step - loss: 0.1191 - accuracy: 0.9607 - f1_score: 0.9263 - val_loss: 0.2112 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 357/10000\n",
      "24/24 [==============================] - 1s 31ms/step - loss: 0.0924 - accuracy: 0.9742 - f1_score: 0.9505 - val_loss: 0.2111 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 358/10000\n",
      "24/24 [==============================] - 1s 31ms/step - loss: 0.1177 - accuracy: 0.9634 - f1_score: 0.9378 - val_loss: 0.2107 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 359/10000\n",
      "24/24 [==============================] - 1s 32ms/step - loss: 0.0932 - accuracy: 0.9688 - f1_score: 0.9323 - val_loss: 0.2101 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 360/10000\n",
      "24/24 [==============================] - 1s 31ms/step - loss: 0.0880 - accuracy: 0.9742 - f1_score: 0.9255 - val_loss: 0.2105 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 361/10000\n",
      "24/24 [==============================] - 1s 32ms/step - loss: 0.1018 - accuracy: 0.9715 - f1_score: 0.9416 - val_loss: 0.2111 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 362/10000\n",
      "24/24 [==============================] - 1s 30ms/step - loss: 0.1030 - accuracy: 0.9647 - f1_score: 0.9262 - val_loss: 0.2111 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 363/10000\n",
      "24/24 [==============================] - 1s 31ms/step - loss: 0.0840 - accuracy: 0.9769 - f1_score: 0.9538 - val_loss: 0.2112 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 364/10000\n",
      "24/24 [==============================] - 1s 31ms/step - loss: 0.0881 - accuracy: 0.9756 - f1_score: 0.9460 - val_loss: 0.2107 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 365/10000\n",
      "24/24 [==============================] - 1s 32ms/step - loss: 0.0819 - accuracy: 0.9742 - f1_score: 0.9383 - val_loss: 0.2096 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 366/10000\n",
      "24/24 [==============================] - 1s 32ms/step - loss: 0.0920 - accuracy: 0.9701 - f1_score: 0.9417 - val_loss: 0.2087 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 367/10000\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.1042 - accuracy: 0.9729 - f1_score: 0.9510 - val_loss: 0.2089 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 368/10000\n",
      "24/24 [==============================] - 1s 32ms/step - loss: 0.0900 - accuracy: 0.9756 - f1_score: 0.9486 - val_loss: 0.2089 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 369/10000\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0958 - accuracy: 0.9769 - f1_score: 0.9544 - val_loss: 0.2090 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 370/10000\n",
      "24/24 [==============================] - 1s 31ms/step - loss: 0.0917 - accuracy: 0.9688 - f1_score: 0.9373 - val_loss: 0.2091 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 371/10000\n",
      "24/24 [==============================] - 1s 32ms/step - loss: 0.0911 - accuracy: 0.9742 - f1_score: 0.9448 - val_loss: 0.2093 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 372/10000\n",
      "24/24 [==============================] - 1s 31ms/step - loss: 0.1037 - accuracy: 0.9634 - f1_score: 0.9227 - val_loss: 0.2094 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 373/10000\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0841 - accuracy: 0.9769 - f1_score: 0.9512 - val_loss: 0.2087 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 374/10000\n",
      "24/24 [==============================] - 1s 32ms/step - loss: 0.0908 - accuracy: 0.9715 - f1_score: 0.9490 - val_loss: 0.2091 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 375/10000\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0952 - accuracy: 0.9769 - f1_score: 0.9576 - val_loss: 0.2093 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 376/10000\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0806 - accuracy: 0.9742 - f1_score: 0.9358 - val_loss: 0.2089 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 377/10000\n",
      "24/24 [==============================] - 1s 34ms/step - loss: 0.0785 - accuracy: 0.9742 - f1_score: 0.9423 - val_loss: 0.2089 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 378/10000\n",
      "24/24 [==============================] - 1s 34ms/step - loss: 0.0886 - accuracy: 0.9742 - f1_score: 0.9485 - val_loss: 0.2084 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 379/10000\n",
      "24/24 [==============================] - 1s 34ms/step - loss: 0.0782 - accuracy: 0.9729 - f1_score: 0.9374 - val_loss: 0.2087 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 380/10000\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0741 - accuracy: 0.9783 - f1_score: 0.9484 - val_loss: 0.2085 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 381/10000\n",
      "24/24 [==============================] - 1s 34ms/step - loss: 0.0842 - accuracy: 0.9769 - f1_score: 0.9511 - val_loss: 0.2088 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 382/10000\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0897 - accuracy: 0.9715 - f1_score: 0.9393 - val_loss: 0.2094 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 383/10000\n",
      "24/24 [==============================] - 1s 34ms/step - loss: 0.0776 - accuracy: 0.9810 - f1_score: 0.9642 - val_loss: 0.2092 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 384/10000\n",
      "24/24 [==============================] - 1s 32ms/step - loss: 0.0755 - accuracy: 0.9796 - f1_score: 0.9568 - val_loss: 0.2096 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 385/10000\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0798 - accuracy: 0.9742 - f1_score: 0.9358 - val_loss: 0.2091 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 386/10000\n",
      "24/24 [==============================] - 1s 32ms/step - loss: 0.0892 - accuracy: 0.9742 - f1_score: 0.9441 - val_loss: 0.2089 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 387/10000\n",
      "24/24 [==============================] - 1s 34ms/step - loss: 0.1090 - accuracy: 0.9661 - f1_score: 0.9434 - val_loss: 0.2084 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 388/10000\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0944 - accuracy: 0.9701 - f1_score: 0.9443 - val_loss: 0.2092 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 389/10000\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0795 - accuracy: 0.9783 - f1_score: 0.9522 - val_loss: 0.2083 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 390/10000\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0848 - accuracy: 0.9701 - f1_score: 0.9331 - val_loss: 0.2084 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 391/10000\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0840 - accuracy: 0.9742 - f1_score: 0.9479 - val_loss: 0.2082 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 392/10000\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0877 - accuracy: 0.9769 - f1_score: 0.9510 - val_loss: 0.2080 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 393/10000\n",
      "24/24 [==============================] - 1s 34ms/step - loss: 0.0875 - accuracy: 0.9742 - f1_score: 0.9556 - val_loss: 0.2079 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 394/10000\n",
      "24/24 [==============================] - 1s 34ms/step - loss: 0.0705 - accuracy: 0.9796 - f1_score: 0.9536 - val_loss: 0.2085 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 395/10000\n",
      "24/24 [==============================] - 1s 35ms/step - loss: 0.0955 - accuracy: 0.9701 - f1_score: 0.9323 - val_loss: 0.2089 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 396/10000\n",
      "24/24 [==============================] - 1s 34ms/step - loss: 0.0915 - accuracy: 0.9742 - f1_score: 0.9548 - val_loss: 0.2087 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 397/10000\n",
      "24/24 [==============================] - 1s 34ms/step - loss: 0.0946 - accuracy: 0.9715 - f1_score: 0.9493 - val_loss: 0.2084 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 398/10000\n",
      "24/24 [==============================] - 1s 34ms/step - loss: 0.0790 - accuracy: 0.9729 - f1_score: 0.9480 - val_loss: 0.2091 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 399/10000\n",
      "24/24 [==============================] - 1s 34ms/step - loss: 0.0707 - accuracy: 0.9783 - f1_score: 0.9492 - val_loss: 0.2084 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 400/10000\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0914 - accuracy: 0.9701 - f1_score: 0.9409 - val_loss: 0.2085 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 401/10000\n",
      "24/24 [==============================] - 1s 34ms/step - loss: 0.0678 - accuracy: 0.9837 - f1_score: 0.9559 - val_loss: 0.2088 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 402/10000\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0887 - accuracy: 0.9742 - f1_score: 0.9485 - val_loss: 0.2082 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 403/10000\n",
      "24/24 [==============================] - 1s 34ms/step - loss: 0.0801 - accuracy: 0.9769 - f1_score: 0.9503 - val_loss: 0.2097 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 404/10000\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0854 - accuracy: 0.9769 - f1_score: 0.9576 - val_loss: 0.2087 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 405/10000\n",
      "24/24 [==============================] - 1s 34ms/step - loss: 0.0977 - accuracy: 0.9674 - f1_score: 0.9362 - val_loss: 0.2081 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 406/10000\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0700 - accuracy: 0.9851 - f1_score: 0.9688 - val_loss: 0.2080 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 407/10000\n",
      "24/24 [==============================] - 1s 34ms/step - loss: 0.0742 - accuracy: 0.9796 - f1_score: 0.9573 - val_loss: 0.2079 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 408/10000\n",
      "24/24 [==============================] - 1s 34ms/step - loss: 0.0732 - accuracy: 0.9796 - f1_score: 0.9567 - val_loss: 0.2074 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 409/10000\n",
      "24/24 [==============================] - 1s 32ms/step - loss: 0.0832 - accuracy: 0.9769 - f1_score: 0.9537 - val_loss: 0.2069 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 410/10000\n",
      "24/24 [==============================] - 1s 34ms/step - loss: 0.0704 - accuracy: 0.9851 - f1_score: 0.9688 - val_loss: 0.2069 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 411/10000\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0947 - accuracy: 0.9769 - f1_score: 0.9538 - val_loss: 0.2074 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 412/10000\n",
      "24/24 [==============================] - 1s 34ms/step - loss: 0.0799 - accuracy: 0.9796 - f1_score: 0.9573 - val_loss: 0.2073 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 413/10000\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0762 - accuracy: 0.9769 - f1_score: 0.9490 - val_loss: 0.2070 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 414/10000\n",
      "24/24 [==============================] - 1s 34ms/step - loss: 0.0734 - accuracy: 0.9796 - f1_score: 0.9464 - val_loss: 0.2075 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 415/10000\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0852 - accuracy: 0.9783 - f1_score: 0.9593 - val_loss: 0.2064 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 416/10000\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0715 - accuracy: 0.9810 - f1_score: 0.9585 - val_loss: 0.2063 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 417/10000\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0647 - accuracy: 0.9824 - f1_score: 0.9483 - val_loss: 0.2060 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 418/10000\n",
      "24/24 [==============================] - 1s 34ms/step - loss: 0.0703 - accuracy: 0.9810 - f1_score: 0.9618 - val_loss: 0.2061 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 419/10000\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0779 - accuracy: 0.9783 - f1_score: 0.9523 - val_loss: 0.2067 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 420/10000\n",
      "24/24 [==============================] - 1s 34ms/step - loss: 0.0710 - accuracy: 0.9783 - f1_score: 0.9517 - val_loss: 0.2064 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 421/10000\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0808 - accuracy: 0.9729 - f1_score: 0.9437 - val_loss: 0.2071 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 422/10000\n",
      "24/24 [==============================] - 1s 34ms/step - loss: 0.0719 - accuracy: 0.9837 - f1_score: 0.9643 - val_loss: 0.2076 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 423/10000\n",
      "24/24 [==============================] - 1s 34ms/step - loss: 0.0785 - accuracy: 0.9742 - f1_score: 0.9412 - val_loss: 0.2077 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 424/10000\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0784 - accuracy: 0.9742 - f1_score: 0.9445 - val_loss: 0.2078 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 425/10000\n",
      "24/24 [==============================] - 1s 35ms/step - loss: 0.0814 - accuracy: 0.9783 - f1_score: 0.9554 - val_loss: 0.2040 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 426/10000\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0733 - accuracy: 0.9769 - f1_score: 0.9434 - val_loss: 0.2049 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 427/10000\n",
      "24/24 [==============================] - 1s 45ms/step - loss: 0.0727 - accuracy: 0.9756 - f1_score: 0.9559 - val_loss: 0.2060 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 428/10000\n",
      "24/24 [==============================] - 1s 32ms/step - loss: 0.0763 - accuracy: 0.9769 - f1_score: 0.9472 - val_loss: 0.2067 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 429/10000\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0623 - accuracy: 0.9851 - f1_score: 0.9585 - val_loss: 0.2068 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 430/10000\n",
      "24/24 [==============================] - 1s 32ms/step - loss: 0.0786 - accuracy: 0.9783 - f1_score: 0.9593 - val_loss: 0.2070 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 431/10000\n",
      "24/24 [==============================] - 1s 32ms/step - loss: 0.0651 - accuracy: 0.9796 - f1_score: 0.9529 - val_loss: 0.2076 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 432/10000\n",
      "24/24 [==============================] - 1s 30ms/step - loss: 0.0843 - accuracy: 0.9661 - f1_score: 0.9338 - val_loss: 0.2069 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 433/10000\n",
      "24/24 [==============================] - 1s 32ms/step - loss: 0.0901 - accuracy: 0.9688 - f1_score: 0.9326 - val_loss: 0.2047 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 434/10000\n",
      "24/24 [==============================] - 1s 29ms/step - loss: 0.0748 - accuracy: 0.9742 - f1_score: 0.9505 - val_loss: 0.2045 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 435/10000\n",
      "24/24 [==============================] - 1s 30ms/step - loss: 0.0803 - accuracy: 0.9729 - f1_score: 0.9366 - val_loss: 0.2048 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 436/10000\n",
      "24/24 [==============================] - 1s 32ms/step - loss: 0.0883 - accuracy: 0.9715 - f1_score: 0.9566 - val_loss: 0.2044 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 437/10000\n",
      "24/24 [==============================] - 1s 30ms/step - loss: 0.0774 - accuracy: 0.9783 - f1_score: 0.9485 - val_loss: 0.2042 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 438/10000\n",
      "24/24 [==============================] - 1s 31ms/step - loss: 0.0796 - accuracy: 0.9769 - f1_score: 0.9536 - val_loss: 0.2036 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 439/10000\n",
      "24/24 [==============================] - 1s 31ms/step - loss: 0.0659 - accuracy: 0.9796 - f1_score: 0.9529 - val_loss: 0.2037 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 440/10000\n",
      "24/24 [==============================] - 1s 31ms/step - loss: 0.0749 - accuracy: 0.9769 - f1_score: 0.9512 - val_loss: 0.2036 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 441/10000\n",
      "24/24 [==============================] - 1s 30ms/step - loss: 0.0643 - accuracy: 0.9824 - f1_score: 0.9567 - val_loss: 0.2056 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 442/10000\n",
      "24/24 [==============================] - 1s 31ms/step - loss: 0.0651 - accuracy: 0.9783 - f1_score: 0.9517 - val_loss: 0.2052 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 443/10000\n",
      "24/24 [==============================] - 1s 30ms/step - loss: 0.0813 - accuracy: 0.9715 - f1_score: 0.9353 - val_loss: 0.2059 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 444/10000\n",
      "24/24 [==============================] - 1s 31ms/step - loss: 0.0720 - accuracy: 0.9824 - f1_score: 0.9567 - val_loss: 0.2034 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 445/10000\n",
      "24/24 [==============================] - 1s 30ms/step - loss: 0.0676 - accuracy: 0.9769 - f1_score: 0.9512 - val_loss: 0.2047 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 446/10000\n",
      "24/24 [==============================] - 1s 31ms/step - loss: 0.0692 - accuracy: 0.9796 - f1_score: 0.9529 - val_loss: 0.2042 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 447/10000\n",
      "24/24 [==============================] - 1s 30ms/step - loss: 0.0786 - accuracy: 0.9742 - f1_score: 0.9401 - val_loss: 0.2045 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 448/10000\n",
      "24/24 [==============================] - 1s 31ms/step - loss: 0.0670 - accuracy: 0.9769 - f1_score: 0.9472 - val_loss: 0.2037 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 449/10000\n",
      "24/24 [==============================] - 1s 30ms/step - loss: 0.0724 - accuracy: 0.9742 - f1_score: 0.9418 - val_loss: 0.2039 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 450/10000\n",
      "24/24 [==============================] - 1s 31ms/step - loss: 0.0878 - accuracy: 0.9701 - f1_score: 0.9372 - val_loss: 0.2040 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 451/10000\n",
      "24/24 [==============================] - 1s 31ms/step - loss: 0.0732 - accuracy: 0.9769 - f1_score: 0.9408 - val_loss: 0.2043 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 452/10000\n",
      "24/24 [==============================] - 1s 30ms/step - loss: 0.0747 - accuracy: 0.9769 - f1_score: 0.9546 - val_loss: 0.2046 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 453/10000\n",
      "24/24 [==============================] - 1s 31ms/step - loss: 0.0728 - accuracy: 0.9756 - f1_score: 0.9505 - val_loss: 0.2058 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 454/10000\n",
      "24/24 [==============================] - 1s 35ms/step - loss: 0.0576 - accuracy: 0.9824 - f1_score: 0.9554 - val_loss: 0.2055 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 455/10000\n",
      "24/24 [==============================] - 1s 31ms/step - loss: 0.0654 - accuracy: 0.9810 - f1_score: 0.9478 - val_loss: 0.2055 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 456/10000\n",
      "24/24 [==============================] - 1s 30ms/step - loss: 0.0847 - accuracy: 0.9756 - f1_score: 0.9573 - val_loss: 0.2059 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 457/10000\n",
      "24/24 [==============================] - 1s 31ms/step - loss: 0.0688 - accuracy: 0.9796 - f1_score: 0.9483 - val_loss: 0.2053 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 458/10000\n",
      "24/24 [==============================] - 1s 32ms/step - loss: 0.0775 - accuracy: 0.9742 - f1_score: 0.9410 - val_loss: 0.2048 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 459/10000\n",
      "24/24 [==============================] - 1s 31ms/step - loss: 0.0649 - accuracy: 0.9810 - f1_score: 0.9576 - val_loss: 0.2045 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 460/10000\n",
      "24/24 [==============================] - 1s 31ms/step - loss: 0.0579 - accuracy: 0.9878 - f1_score: 0.9604 - val_loss: 0.2048 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 461/10000\n",
      "24/24 [==============================] - 1s 51ms/step - loss: 0.0667 - accuracy: 0.9769 - f1_score: 0.9547 - val_loss: 0.2069 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 462/10000\n",
      "24/24 [==============================] - 1s 36ms/step - loss: 0.0702 - accuracy: 0.9756 - f1_score: 0.9466 - val_loss: 0.2059 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 463/10000\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0626 - accuracy: 0.9810 - f1_score: 0.9523 - val_loss: 0.2059 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 464/10000\n",
      "24/24 [==============================] - 1s 31ms/step - loss: 0.0664 - accuracy: 0.9783 - f1_score: 0.9491 - val_loss: 0.2053 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 465/10000\n",
      "24/24 [==============================] - 1s 31ms/step - loss: 0.0615 - accuracy: 0.9783 - f1_score: 0.9491 - val_loss: 0.2054 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 466/10000\n",
      "24/24 [==============================] - 1s 35ms/step - loss: 0.0777 - accuracy: 0.9756 - f1_score: 0.9500 - val_loss: 0.2058 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 467/10000\n",
      "24/24 [==============================] - 1s 39ms/step - loss: 0.0580 - accuracy: 0.9810 - f1_score: 0.9581 - val_loss: 0.2061 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 468/10000\n",
      "24/24 [==============================] - 1s 43ms/step - loss: 0.0728 - accuracy: 0.9769 - f1_score: 0.9474 - val_loss: 0.2053 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 469/10000\n",
      "24/24 [==============================] - 1s 37ms/step - loss: 0.0828 - accuracy: 0.9701 - f1_score: 0.9443 - val_loss: 0.2058 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 470/10000\n",
      "24/24 [==============================] - 1s 35ms/step - loss: 0.0783 - accuracy: 0.9769 - f1_score: 0.9510 - val_loss: 0.2037 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 471/10000\n",
      "24/24 [==============================] - 1s 36ms/step - loss: 0.0832 - accuracy: 0.9756 - f1_score: 0.9422 - val_loss: 0.2035 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 472/10000\n",
      "24/24 [==============================] - 1s 34ms/step - loss: 0.0713 - accuracy: 0.9756 - f1_score: 0.9458 - val_loss: 0.2030 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 473/10000\n",
      "24/24 [==============================] - 1s 34ms/step - loss: 0.0726 - accuracy: 0.9756 - f1_score: 0.9461 - val_loss: 0.2021 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 474/10000\n",
      "24/24 [==============================] - 1s 52ms/step - loss: 0.0763 - accuracy: 0.9756 - f1_score: 0.9450 - val_loss: 0.2021 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 475/10000\n",
      "24/24 [==============================] - 1s 35ms/step - loss: 0.0762 - accuracy: 0.9688 - f1_score: 0.9329 - val_loss: 0.2016 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 476/10000\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0583 - accuracy: 0.9851 - f1_score: 0.9755 - val_loss: 0.2015 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 477/10000\n",
      "24/24 [==============================] - 1s 32ms/step - loss: 0.0757 - accuracy: 0.9796 - f1_score: 0.9504 - val_loss: 0.2019 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 478/10000\n",
      "24/24 [==============================] - 1s 32ms/step - loss: 0.0574 - accuracy: 0.9851 - f1_score: 0.9617 - val_loss: 0.2016 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 479/10000\n",
      "24/24 [==============================] - 1s 31ms/step - loss: 0.0694 - accuracy: 0.9756 - f1_score: 0.9500 - val_loss: 0.2016 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 480/10000\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0787 - accuracy: 0.9701 - f1_score: 0.9368 - val_loss: 0.2023 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 481/10000\n",
      "24/24 [==============================] - 1s 31ms/step - loss: 0.0636 - accuracy: 0.9851 - f1_score: 0.9683 - val_loss: 0.2027 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 482/10000\n",
      "24/24 [==============================] - 1s 31ms/step - loss: 0.0635 - accuracy: 0.9796 - f1_score: 0.9458 - val_loss: 0.2024 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 483/10000\n",
      "24/24 [==============================] - 1s 32ms/step - loss: 0.0783 - accuracy: 0.9742 - f1_score: 0.9478 - val_loss: 0.2020 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 484/10000\n",
      "24/24 [==============================] - 1s 30ms/step - loss: 0.0685 - accuracy: 0.9715 - f1_score: 0.9358 - val_loss: 0.2021 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 485/10000\n",
      "24/24 [==============================] - 1s 31ms/step - loss: 0.0648 - accuracy: 0.9742 - f1_score: 0.9361 - val_loss: 0.2022 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 486/10000\n",
      "24/24 [==============================] - 1s 31ms/step - loss: 0.0532 - accuracy: 0.9878 - f1_score: 0.9712 - val_loss: 0.2016 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 487/10000\n",
      "24/24 [==============================] - 1s 30ms/step - loss: 0.0655 - accuracy: 0.9796 - f1_score: 0.9611 - val_loss: 0.2012 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 488/10000\n",
      "24/24 [==============================] - 1s 31ms/step - loss: 0.0589 - accuracy: 0.9837 - f1_score: 0.9617 - val_loss: 0.2013 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 489/10000\n",
      "24/24 [==============================] - 1s 30ms/step - loss: 0.0556 - accuracy: 0.9824 - f1_score: 0.9631 - val_loss: 0.2015 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 490/10000\n",
      "24/24 [==============================] - 1s 30ms/step - loss: 0.0660 - accuracy: 0.9769 - f1_score: 0.9465 - val_loss: 0.2008 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 491/10000\n",
      "24/24 [==============================] - 1s 30ms/step - loss: 0.0706 - accuracy: 0.9769 - f1_score: 0.9473 - val_loss: 0.2005 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 492/10000\n",
      "24/24 [==============================] - 1s 32ms/step - loss: 0.0722 - accuracy: 0.9756 - f1_score: 0.9492 - val_loss: 0.2007 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 493/10000\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0634 - accuracy: 0.9824 - f1_score: 0.9555 - val_loss: 0.2010 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 494/10000\n",
      "24/24 [==============================] - 1s 30ms/step - loss: 0.0720 - accuracy: 0.9783 - f1_score: 0.9455 - val_loss: 0.1995 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 495/10000\n",
      "24/24 [==============================] - 1s 31ms/step - loss: 0.0676 - accuracy: 0.9729 - f1_score: 0.9397 - val_loss: 0.2003 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 496/10000\n",
      "24/24 [==============================] - 1s 30ms/step - loss: 0.0614 - accuracy: 0.9796 - f1_score: 0.9572 - val_loss: 0.2005 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 497/10000\n",
      "24/24 [==============================] - 1s 31ms/step - loss: 0.0641 - accuracy: 0.9796 - f1_score: 0.9536 - val_loss: 0.2016 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 498/10000\n",
      "24/24 [==============================] - 1s 31ms/step - loss: 0.0571 - accuracy: 0.9796 - f1_score: 0.9573 - val_loss: 0.2035 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 499/10000\n",
      "24/24 [==============================] - 1s 30ms/step - loss: 0.0665 - accuracy: 0.9796 - f1_score: 0.9572 - val_loss: 0.2026 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 500/10000\n",
      "24/24 [==============================] - 1s 30ms/step - loss: 0.0646 - accuracy: 0.9783 - f1_score: 0.9491 - val_loss: 0.2014 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 501/10000\n",
      "24/24 [==============================] - 1s 30ms/step - loss: 0.0686 - accuracy: 0.9769 - f1_score: 0.9589 - val_loss: 0.2012 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 502/10000\n",
      "24/24 [==============================] - 1s 31ms/step - loss: 0.0844 - accuracy: 0.9701 - f1_score: 0.9372 - val_loss: 0.2008 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 503/10000\n",
      "24/24 [==============================] - 1s 31ms/step - loss: 0.0794 - accuracy: 0.9715 - f1_score: 0.9454 - val_loss: 0.2009 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 504/10000\n",
      "24/24 [==============================] - 1s 30ms/step - loss: 0.0714 - accuracy: 0.9783 - f1_score: 0.9625 - val_loss: 0.1998 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 505/10000\n",
      "24/24 [==============================] - 1s 31ms/step - loss: 0.0512 - accuracy: 0.9864 - f1_score: 0.9696 - val_loss: 0.1993 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 506/10000\n",
      "24/24 [==============================] - 1s 30ms/step - loss: 0.0674 - accuracy: 0.9783 - f1_score: 0.9523 - val_loss: 0.1987 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 507/10000\n",
      "24/24 [==============================] - 1s 31ms/step - loss: 0.0700 - accuracy: 0.9783 - f1_score: 0.9566 - val_loss: 0.1987 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 508/10000\n",
      "24/24 [==============================] - 1s 29ms/step - loss: 0.0560 - accuracy: 0.9824 - f1_score: 0.9529 - val_loss: 0.1990 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 509/10000\n",
      "24/24 [==============================] - 1s 30ms/step - loss: 0.0682 - accuracy: 0.9783 - f1_score: 0.9517 - val_loss: 0.1995 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 510/10000\n",
      "24/24 [==============================] - 1s 30ms/step - loss: 0.0554 - accuracy: 0.9837 - f1_score: 0.9679 - val_loss: 0.1991 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 511/10000\n",
      "24/24 [==============================] - 1s 29ms/step - loss: 0.0711 - accuracy: 0.9742 - f1_score: 0.9487 - val_loss: 0.1990 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 512/10000\n",
      "24/24 [==============================] - 1s 30ms/step - loss: 0.0722 - accuracy: 0.9769 - f1_score: 0.9504 - val_loss: 0.1986 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 513/10000\n",
      "24/24 [==============================] - 1s 29ms/step - loss: 0.0646 - accuracy: 0.9810 - f1_score: 0.9511 - val_loss: 0.1992 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 514/10000\n",
      "24/24 [==============================] - 1s 30ms/step - loss: 0.0631 - accuracy: 0.9837 - f1_score: 0.9605 - val_loss: 0.1992 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 515/10000\n",
      "24/24 [==============================] - 1s 29ms/step - loss: 0.0651 - accuracy: 0.9810 - f1_score: 0.9652 - val_loss: 0.1996 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 516/10000\n",
      "24/24 [==============================] - 1s 30ms/step - loss: 0.0658 - accuracy: 0.9851 - f1_score: 0.9645 - val_loss: 0.1949 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 517/10000\n",
      "24/24 [==============================] - 1s 29ms/step - loss: 0.0536 - accuracy: 0.9864 - f1_score: 0.9630 - val_loss: 0.1941 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 518/10000\n",
      "24/24 [==============================] - 1s 30ms/step - loss: 0.0681 - accuracy: 0.9756 - f1_score: 0.9486 - val_loss: 0.1954 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 519/10000\n",
      "24/24 [==============================] - 1s 30ms/step - loss: 0.0610 - accuracy: 0.9878 - f1_score: 0.9716 - val_loss: 0.1952 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 520/10000\n",
      "24/24 [==============================] - 1s 29ms/step - loss: 0.0539 - accuracy: 0.9783 - f1_score: 0.9437 - val_loss: 0.1958 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 521/10000\n",
      "24/24 [==============================] - 1s 30ms/step - loss: 0.0534 - accuracy: 0.9851 - f1_score: 0.9640 - val_loss: 0.1963 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 522/10000\n",
      "24/24 [==============================] - 1s 29ms/step - loss: 0.0617 - accuracy: 0.9810 - f1_score: 0.9580 - val_loss: 0.1962 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 523/10000\n",
      "24/24 [==============================] - 1s 29ms/step - loss: 0.0666 - accuracy: 0.9810 - f1_score: 0.9617 - val_loss: 0.1970 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 524/10000\n",
      "24/24 [==============================] - 1s 30ms/step - loss: 0.0540 - accuracy: 0.9824 - f1_score: 0.9634 - val_loss: 0.1975 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 525/10000\n",
      "24/24 [==============================] - 1s 29ms/step - loss: 0.0676 - accuracy: 0.9837 - f1_score: 0.9675 - val_loss: 0.1984 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 526/10000\n",
      "24/24 [==============================] - 1s 30ms/step - loss: 0.0499 - accuracy: 0.9878 - f1_score: 0.9783 - val_loss: 0.1985 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 527/10000\n",
      "24/24 [==============================] - 1s 30ms/step - loss: 0.0594 - accuracy: 0.9783 - f1_score: 0.9493 - val_loss: 0.1974 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 528/10000\n",
      "24/24 [==============================] - 1s 30ms/step - loss: 0.0578 - accuracy: 0.9824 - f1_score: 0.9522 - val_loss: 0.1983 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 529/10000\n",
      "24/24 [==============================] - 1s 31ms/step - loss: 0.0729 - accuracy: 0.9742 - f1_score: 0.9296 - val_loss: 0.1978 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 530/10000\n",
      "24/24 [==============================] - 1s 30ms/step - loss: 0.0575 - accuracy: 0.9837 - f1_score: 0.9573 - val_loss: 0.1976 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 531/10000\n",
      "24/24 [==============================] - 1s 31ms/step - loss: 0.0789 - accuracy: 0.9769 - f1_score: 0.9544 - val_loss: 0.1990 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 532/10000\n",
      "24/24 [==============================] - 1s 30ms/step - loss: 0.0637 - accuracy: 0.9810 - f1_score: 0.9580 - val_loss: 0.1990 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 533/10000\n",
      "24/24 [==============================] - 1s 31ms/step - loss: 0.0525 - accuracy: 0.9891 - f1_score: 0.9758 - val_loss: 0.1989 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 534/10000\n",
      "24/24 [==============================] - 1s 30ms/step - loss: 0.0559 - accuracy: 0.9864 - f1_score: 0.9704 - val_loss: 0.1989 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 535/10000\n",
      "24/24 [==============================] - 1s 30ms/step - loss: 0.0570 - accuracy: 0.9824 - f1_score: 0.9597 - val_loss: 0.1993 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 536/10000\n",
      "24/24 [==============================] - 1s 30ms/step - loss: 0.0679 - accuracy: 0.9769 - f1_score: 0.9552 - val_loss: 0.1980 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 537/10000\n",
      "24/24 [==============================] - 1s 30ms/step - loss: 0.0525 - accuracy: 0.9837 - f1_score: 0.9643 - val_loss: 0.1985 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 538/10000\n",
      "24/24 [==============================] - 1s 31ms/step - loss: 0.0583 - accuracy: 0.9851 - f1_score: 0.9628 - val_loss: 0.1983 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 539/10000\n",
      "24/24 [==============================] - 1s 30ms/step - loss: 0.0564 - accuracy: 0.9878 - f1_score: 0.9746 - val_loss: 0.1988 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 540/10000\n",
      "24/24 [==============================] - 1s 30ms/step - loss: 0.0581 - accuracy: 0.9796 - f1_score: 0.9496 - val_loss: 0.1981 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 541/10000\n",
      "24/24 [==============================] - 1s 31ms/step - loss: 0.0538 - accuracy: 0.9837 - f1_score: 0.9671 - val_loss: 0.1979 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 542/10000\n",
      "24/24 [==============================] - 1s 30ms/step - loss: 0.0596 - accuracy: 0.9796 - f1_score: 0.9497 - val_loss: 0.1945 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 543/10000\n",
      "24/24 [==============================] - 1s 31ms/step - loss: 0.0612 - accuracy: 0.9837 - f1_score: 0.9680 - val_loss: 0.1920 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 544/10000\n",
      "24/24 [==============================] - 1s 30ms/step - loss: 0.0564 - accuracy: 0.9783 - f1_score: 0.9521 - val_loss: 0.1925 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 545/10000\n",
      "24/24 [==============================] - 1s 30ms/step - loss: 0.0584 - accuracy: 0.9851 - f1_score: 0.9611 - val_loss: 0.1934 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 546/10000\n",
      "24/24 [==============================] - 1s 31ms/step - loss: 0.0751 - accuracy: 0.9824 - f1_score: 0.9667 - val_loss: 0.1944 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 547/10000\n",
      "24/24 [==============================] - 1s 30ms/step - loss: 0.0712 - accuracy: 0.9796 - f1_score: 0.9579 - val_loss: 0.1946 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 548/10000\n",
      "24/24 [==============================] - 1s 31ms/step - loss: 0.0719 - accuracy: 0.9756 - f1_score: 0.9570 - val_loss: 0.1963 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 549/10000\n",
      "24/24 [==============================] - 1s 30ms/step - loss: 0.0612 - accuracy: 0.9824 - f1_score: 0.9560 - val_loss: 0.1963 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 550/10000\n",
      "24/24 [==============================] - 1s 30ms/step - loss: 0.0541 - accuracy: 0.9796 - f1_score: 0.9419 - val_loss: 0.1970 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 551/10000\n",
      "24/24 [==============================] - 1s 31ms/step - loss: 0.0668 - accuracy: 0.9769 - f1_score: 0.9466 - val_loss: 0.1972 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 552/10000\n",
      "24/24 [==============================] - 1s 30ms/step - loss: 0.0588 - accuracy: 0.9783 - f1_score: 0.9523 - val_loss: 0.1973 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 553/10000\n",
      "24/24 [==============================] - 1s 31ms/step - loss: 0.0561 - accuracy: 0.9783 - f1_score: 0.9405 - val_loss: 0.1971 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 554/10000\n",
      "24/24 [==============================] - 1s 30ms/step - loss: 0.0544 - accuracy: 0.9783 - f1_score: 0.9454 - val_loss: 0.1981 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 555/10000\n",
      "24/24 [==============================] - 1s 31ms/step - loss: 0.0575 - accuracy: 0.9837 - f1_score: 0.9667 - val_loss: 0.1994 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 556/10000\n",
      "24/24 [==============================] - 1s 31ms/step - loss: 0.0600 - accuracy: 0.9715 - f1_score: 0.9313 - val_loss: 0.1983 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 557/10000\n",
      "24/24 [==============================] - 1s 30ms/step - loss: 0.0632 - accuracy: 0.9769 - f1_score: 0.9412 - val_loss: 0.1978 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 558/10000\n",
      "24/24 [==============================] - 1s 31ms/step - loss: 0.0532 - accuracy: 0.9837 - f1_score: 0.9535 - val_loss: 0.1975 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 559/10000\n",
      "24/24 [==============================] - 1s 30ms/step - loss: 0.0508 - accuracy: 0.9878 - f1_score: 0.9712 - val_loss: 0.1973 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 560/10000\n",
      "24/24 [==============================] - 1s 30ms/step - loss: 0.0620 - accuracy: 0.9783 - f1_score: 0.9584 - val_loss: 0.1980 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 561/10000\n",
      "24/24 [==============================] - 1s 32ms/step - loss: 0.0547 - accuracy: 0.9864 - f1_score: 0.9700 - val_loss: 0.1973 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 562/10000\n",
      "24/24 [==============================] - 1s 32ms/step - loss: 0.0657 - accuracy: 0.9742 - f1_score: 0.9409 - val_loss: 0.1970 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 563/10000\n",
      "24/24 [==============================] - 1s 31ms/step - loss: 0.0545 - accuracy: 0.9837 - f1_score: 0.9572 - val_loss: 0.1960 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 564/10000\n",
      "24/24 [==============================] - 1s 32ms/step - loss: 0.0528 - accuracy: 0.9824 - f1_score: 0.9521 - val_loss: 0.1967 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 565/10000\n",
      "24/24 [==============================] - 1s 31ms/step - loss: 0.0552 - accuracy: 0.9810 - f1_score: 0.9549 - val_loss: 0.1967 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 566/10000\n",
      "24/24 [==============================] - 1s 32ms/step - loss: 0.0605 - accuracy: 0.9783 - f1_score: 0.9591 - val_loss: 0.1967 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 567/10000\n",
      "24/24 [==============================] - 1s 32ms/step - loss: 0.0552 - accuracy: 0.9796 - f1_score: 0.9498 - val_loss: 0.1967 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 568/10000\n",
      "24/24 [==============================] - 1s 30ms/step - loss: 0.0700 - accuracy: 0.9729 - f1_score: 0.9363 - val_loss: 0.1964 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 569/10000\n",
      "24/24 [==============================] - 1s 32ms/step - loss: 0.0632 - accuracy: 0.9769 - f1_score: 0.9403 - val_loss: 0.1967 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 570/10000\n",
      "24/24 [==============================] - 1s 31ms/step - loss: 0.0637 - accuracy: 0.9742 - f1_score: 0.9399 - val_loss: 0.1970 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 571/10000\n",
      "24/24 [==============================] - 1s 31ms/step - loss: 0.0627 - accuracy: 0.9769 - f1_score: 0.9473 - val_loss: 0.1971 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 572/10000\n",
      "24/24 [==============================] - 1s 31ms/step - loss: 0.0533 - accuracy: 0.9810 - f1_score: 0.9549 - val_loss: 0.1974 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 573/10000\n",
      "24/24 [==============================] - 1s 31ms/step - loss: 0.0529 - accuracy: 0.9837 - f1_score: 0.9606 - val_loss: 0.1965 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 574/10000\n",
      "24/24 [==============================] - 1s 31ms/step - loss: 0.0598 - accuracy: 0.9824 - f1_score: 0.9548 - val_loss: 0.1968 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 575/10000\n",
      "24/24 [==============================] - 1s 31ms/step - loss: 0.0624 - accuracy: 0.9783 - f1_score: 0.9484 - val_loss: 0.1941 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 576/10000\n",
      "24/24 [==============================] - 1s 31ms/step - loss: 0.0563 - accuracy: 0.9824 - f1_score: 0.9555 - val_loss: 0.1945 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 577/10000\n",
      "24/24 [==============================] - 1s 32ms/step - loss: 0.0641 - accuracy: 0.9810 - f1_score: 0.9623 - val_loss: 0.1956 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 578/10000\n",
      "24/24 [==============================] - 1s 32ms/step - loss: 0.0585 - accuracy: 0.9796 - f1_score: 0.9573 - val_loss: 0.1962 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 579/10000\n",
      "24/24 [==============================] - 1s 32ms/step - loss: 0.0665 - accuracy: 0.9810 - f1_score: 0.9587 - val_loss: 0.1957 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 580/10000\n",
      "24/24 [==============================] - 1s 31ms/step - loss: 0.0543 - accuracy: 0.9837 - f1_score: 0.9611 - val_loss: 0.1954 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 581/10000\n",
      "24/24 [==============================] - 1s 32ms/step - loss: 0.0712 - accuracy: 0.9769 - f1_score: 0.9542 - val_loss: 0.1956 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 582/10000\n",
      "24/24 [==============================] - 1s 31ms/step - loss: 0.0650 - accuracy: 0.9783 - f1_score: 0.9554 - val_loss: 0.1952 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 583/10000\n",
      "24/24 [==============================] - 1s 31ms/step - loss: 0.0583 - accuracy: 0.9824 - f1_score: 0.9561 - val_loss: 0.1955 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 584/10000\n",
      "24/24 [==============================] - 1s 32ms/step - loss: 0.0596 - accuracy: 0.9796 - f1_score: 0.9561 - val_loss: 0.1957 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 585/10000\n",
      "24/24 [==============================] - 1s 30ms/step - loss: 0.0689 - accuracy: 0.9796 - f1_score: 0.9574 - val_loss: 0.1951 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 586/10000\n",
      "24/24 [==============================] - 1s 31ms/step - loss: 0.0524 - accuracy: 0.9769 - f1_score: 0.9401 - val_loss: 0.1949 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 587/10000\n",
      "24/24 [==============================] - 1s 31ms/step - loss: 0.0485 - accuracy: 0.9851 - f1_score: 0.9612 - val_loss: 0.1949 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 588/10000\n",
      "24/24 [==============================] - 1s 30ms/step - loss: 0.0553 - accuracy: 0.9824 - f1_score: 0.9562 - val_loss: 0.1957 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 589/10000\n",
      "24/24 [==============================] - 1s 30ms/step - loss: 0.0747 - accuracy: 0.9729 - f1_score: 0.9413 - val_loss: 0.1965 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 590/10000\n",
      "24/24 [==============================] - 1s 31ms/step - loss: 0.0480 - accuracy: 0.9919 - f1_score: 0.9786 - val_loss: 0.1963 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 591/10000\n",
      "24/24 [==============================] - 1s 29ms/step - loss: 0.0542 - accuracy: 0.9783 - f1_score: 0.9478 - val_loss: 0.1962 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 592/10000\n",
      "24/24 [==============================] - 1s 31ms/step - loss: 0.0555 - accuracy: 0.9837 - f1_score: 0.9643 - val_loss: 0.1960 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 593/10000\n",
      "24/24 [==============================] - 1s 31ms/step - loss: 0.0542 - accuracy: 0.9837 - f1_score: 0.9637 - val_loss: 0.1955 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 594/10000\n",
      "24/24 [==============================] - 1s 30ms/step - loss: 0.0598 - accuracy: 0.9796 - f1_score: 0.9504 - val_loss: 0.1945 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 595/10000\n",
      "24/24 [==============================] - 1s 30ms/step - loss: 0.0579 - accuracy: 0.9824 - f1_score: 0.9598 - val_loss: 0.1941 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 596/10000\n",
      "24/24 [==============================] - 1s 31ms/step - loss: 0.0594 - accuracy: 0.9824 - f1_score: 0.9593 - val_loss: 0.1940 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 597/10000\n",
      "24/24 [==============================] - 1s 30ms/step - loss: 0.0483 - accuracy: 0.9837 - f1_score: 0.9605 - val_loss: 0.1951 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 598/10000\n",
      "24/24 [==============================] - 1s 31ms/step - loss: 0.0634 - accuracy: 0.9769 - f1_score: 0.9478 - val_loss: 0.1946 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 599/10000\n",
      "24/24 [==============================] - 1s 30ms/step - loss: 0.0544 - accuracy: 0.9810 - f1_score: 0.9479 - val_loss: 0.1945 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 600/10000\n",
      "24/24 [==============================] - 1s 30ms/step - loss: 0.0465 - accuracy: 0.9796 - f1_score: 0.9529 - val_loss: 0.1955 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 601/10000\n",
      "24/24 [==============================] - 1s 31ms/step - loss: 0.0537 - accuracy: 0.9837 - f1_score: 0.9605 - val_loss: 0.1952 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 602/10000\n",
      "24/24 [==============================] - 1s 30ms/step - loss: 0.0642 - accuracy: 0.9783 - f1_score: 0.9524 - val_loss: 0.1948 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 603/10000\n",
      "24/24 [==============================] - 1s 30ms/step - loss: 0.0473 - accuracy: 0.9864 - f1_score: 0.9696 - val_loss: 0.1945 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 604/10000\n",
      "24/24 [==============================] - 1s 30ms/step - loss: 0.0560 - accuracy: 0.9837 - f1_score: 0.9573 - val_loss: 0.1944 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 605/10000\n",
      "24/24 [==============================] - 1s 30ms/step - loss: 0.0573 - accuracy: 0.9783 - f1_score: 0.9548 - val_loss: 0.1942 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 606/10000\n",
      "24/24 [==============================] - 1s 30ms/step - loss: 0.0541 - accuracy: 0.9878 - f1_score: 0.9746 - val_loss: 0.1935 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 607/10000\n",
      "24/24 [==============================] - 1s 32ms/step - loss: 0.0604 - accuracy: 0.9810 - f1_score: 0.9621 - val_loss: 0.1935 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 608/10000\n",
      "24/24 [==============================] - 1s 32ms/step - loss: 0.0494 - accuracy: 0.9824 - f1_score: 0.9522 - val_loss: 0.1939 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 609/10000\n",
      "24/24 [==============================] - 1s 31ms/step - loss: 0.0598 - accuracy: 0.9810 - f1_score: 0.9581 - val_loss: 0.1925 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 610/10000\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0512 - accuracy: 0.9837 - f1_score: 0.9605 - val_loss: 0.1929 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 611/10000\n",
      "24/24 [==============================] - 1s 31ms/step - loss: 0.0594 - accuracy: 0.9837 - f1_score: 0.9675 - val_loss: 0.1929 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 612/10000\n",
      "24/24 [==============================] - 1s 32ms/step - loss: 0.0528 - accuracy: 0.9837 - f1_score: 0.9566 - val_loss: 0.1935 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 613/10000\n",
      "24/24 [==============================] - 1s 31ms/step - loss: 0.0461 - accuracy: 0.9878 - f1_score: 0.9580 - val_loss: 0.1937 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 614/10000\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0457 - accuracy: 0.9824 - f1_score: 0.9554 - val_loss: 0.1927 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 615/10000\n",
      "24/24 [==============================] - 1s 37ms/step - loss: 0.0510 - accuracy: 0.9824 - f1_score: 0.9561 - val_loss: 0.1929 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 616/10000\n",
      "24/24 [==============================] - 1s 56ms/step - loss: 0.0460 - accuracy: 0.9878 - f1_score: 0.9675 - val_loss: 0.1927 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 617/10000\n",
      "24/24 [==============================] - 1s 46ms/step - loss: 0.0588 - accuracy: 0.9810 - f1_score: 0.9548 - val_loss: 0.1929 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 618/10000\n",
      "24/24 [==============================] - 1s 50ms/step - loss: 0.0554 - accuracy: 0.9824 - f1_score: 0.9548 - val_loss: 0.1932 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 619/10000\n",
      "24/24 [==============================] - 1s 46ms/step - loss: 0.0627 - accuracy: 0.9796 - f1_score: 0.9567 - val_loss: 0.1924 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 620/10000\n",
      "24/24 [==============================] - 1s 56ms/step - loss: 0.0444 - accuracy: 0.9878 - f1_score: 0.9642 - val_loss: 0.1920 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 621/10000\n",
      "24/24 [==============================] - 1s 48ms/step - loss: 0.0478 - accuracy: 0.9905 - f1_score: 0.9733 - val_loss: 0.1923 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 622/10000\n",
      "24/24 [==============================] - 1s 34ms/step - loss: 0.0465 - accuracy: 0.9878 - f1_score: 0.9719 - val_loss: 0.1919 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 623/10000\n",
      "24/24 [==============================] - 1s 40ms/step - loss: 0.0558 - accuracy: 0.9769 - f1_score: 0.9508 - val_loss: 0.1916 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 624/10000\n",
      "24/24 [==============================] - 1s 50ms/step - loss: 0.0466 - accuracy: 0.9810 - f1_score: 0.9477 - val_loss: 0.1883 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 625/10000\n",
      "24/24 [==============================] - 1s 47ms/step - loss: 0.0541 - accuracy: 0.9824 - f1_score: 0.9699 - val_loss: 0.1891 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 626/10000\n",
      "24/24 [==============================] - 1s 35ms/step - loss: 0.0750 - accuracy: 0.9769 - f1_score: 0.9547 - val_loss: 0.1901 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 627/10000\n",
      "24/24 [==============================] - 1s 42ms/step - loss: 0.0668 - accuracy: 0.9769 - f1_score: 0.9545 - val_loss: 0.1921 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 628/10000\n",
      "24/24 [==============================] - 1s 51ms/step - loss: 0.0653 - accuracy: 0.9796 - f1_score: 0.9609 - val_loss: 0.1928 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 629/10000\n",
      "24/24 [==============================] - 1s 39ms/step - loss: 0.0504 - accuracy: 0.9837 - f1_score: 0.9679 - val_loss: 0.1935 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 630/10000\n",
      "24/24 [==============================] - 1s 48ms/step - loss: 0.0532 - accuracy: 0.9810 - f1_score: 0.9542 - val_loss: 0.1930 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 631/10000\n",
      "24/24 [==============================] - 1s 37ms/step - loss: 0.0524 - accuracy: 0.9796 - f1_score: 0.9510 - val_loss: 0.1930 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 632/10000\n",
      "24/24 [==============================] - 1s 41ms/step - loss: 0.0495 - accuracy: 0.9851 - f1_score: 0.9656 - val_loss: 0.1920 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 633/10000\n",
      "24/24 [==============================] - 1s 41ms/step - loss: 0.0446 - accuracy: 0.9891 - f1_score: 0.9762 - val_loss: 0.1923 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 634/10000\n",
      "24/24 [==============================] - 1s 40ms/step - loss: 0.0423 - accuracy: 0.9864 - f1_score: 0.9662 - val_loss: 0.1921 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 635/10000\n",
      "24/24 [==============================] - 1s 39ms/step - loss: 0.0505 - accuracy: 0.9796 - f1_score: 0.9542 - val_loss: 0.1931 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 636/10000\n",
      "24/24 [==============================] - 1s 42ms/step - loss: 0.0518 - accuracy: 0.9824 - f1_score: 0.9553 - val_loss: 0.1924 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 637/10000\n",
      "24/24 [==============================] - 1s 42ms/step - loss: 0.0467 - accuracy: 0.9824 - f1_score: 0.9592 - val_loss: 0.1923 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 638/10000\n",
      "24/24 [==============================] - 1s 40ms/step - loss: 0.0419 - accuracy: 0.9851 - f1_score: 0.9617 - val_loss: 0.1931 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 639/10000\n",
      "24/24 [==============================] - 1s 40ms/step - loss: 0.0493 - accuracy: 0.9851 - f1_score: 0.9650 - val_loss: 0.1936 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 640/10000\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0545 - accuracy: 0.9810 - f1_score: 0.9517 - val_loss: 0.1932 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 641/10000\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0540 - accuracy: 0.9796 - f1_score: 0.9455 - val_loss: 0.1921 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 642/10000\n",
      "24/24 [==============================] - 1s 40ms/step - loss: 0.0633 - accuracy: 0.9756 - f1_score: 0.9500 - val_loss: 0.1922 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 643/10000\n",
      "24/24 [==============================] - 1s 40ms/step - loss: 0.0483 - accuracy: 0.9824 - f1_score: 0.9598 - val_loss: 0.1919 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 644/10000\n",
      "24/24 [==============================] - 1s 38ms/step - loss: 0.0507 - accuracy: 0.9837 - f1_score: 0.9573 - val_loss: 0.1911 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 645/10000\n",
      "24/24 [==============================] - 1s 39ms/step - loss: 0.0613 - accuracy: 0.9756 - f1_score: 0.9455 - val_loss: 0.1914 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 646/10000\n",
      "24/24 [==============================] - 1s 42ms/step - loss: 0.0507 - accuracy: 0.9783 - f1_score: 0.9523 - val_loss: 0.1915 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 647/10000\n",
      "24/24 [==============================] - 1s 41ms/step - loss: 0.0475 - accuracy: 0.9824 - f1_score: 0.9620 - val_loss: 0.1914 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 648/10000\n",
      "24/24 [==============================] - 1s 37ms/step - loss: 0.0546 - accuracy: 0.9796 - f1_score: 0.9497 - val_loss: 0.1916 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 649/10000\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0489 - accuracy: 0.9796 - f1_score: 0.9505 - val_loss: 0.1917 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 650/10000\n",
      "24/24 [==============================] - 1s 35ms/step - loss: 0.0466 - accuracy: 0.9824 - f1_score: 0.9523 - val_loss: 0.1914 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 651/10000\n",
      "24/24 [==============================] - 1s 40ms/step - loss: 0.0463 - accuracy: 0.9851 - f1_score: 0.9617 - val_loss: 0.1917 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 652/10000\n",
      "24/24 [==============================] - 1s 41ms/step - loss: 0.0450 - accuracy: 0.9864 - f1_score: 0.9700 - val_loss: 0.1919 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 653/10000\n",
      "24/24 [==============================] - 1s 38ms/step - loss: 0.0448 - accuracy: 0.9837 - f1_score: 0.9527 - val_loss: 0.1918 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 654/10000\n",
      "24/24 [==============================] - 1s 39ms/step - loss: 0.0397 - accuracy: 0.9891 - f1_score: 0.9687 - val_loss: 0.1907 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 655/10000\n",
      "24/24 [==============================] - 1s 45ms/step - loss: 0.0550 - accuracy: 0.9851 - f1_score: 0.9687 - val_loss: 0.1905 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 656/10000\n",
      "24/24 [==============================] - 1s 47ms/step - loss: 0.0460 - accuracy: 0.9878 - f1_score: 0.9679 - val_loss: 0.1915 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 657/10000\n",
      "24/24 [==============================] - 1s 39ms/step - loss: 0.0476 - accuracy: 0.9905 - f1_score: 0.9738 - val_loss: 0.1908 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 658/10000\n",
      "24/24 [==============================] - 1s 35ms/step - loss: 0.0531 - accuracy: 0.9810 - f1_score: 0.9548 - val_loss: 0.1905 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 659/10000\n",
      "24/24 [==============================] - 1s 43ms/step - loss: 0.0509 - accuracy: 0.9810 - f1_score: 0.9614 - val_loss: 0.1905 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 660/10000\n",
      "24/24 [==============================] - 1s 42ms/step - loss: 0.0471 - accuracy: 0.9810 - f1_score: 0.9516 - val_loss: 0.1894 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 661/10000\n",
      "24/24 [==============================] - 1s 40ms/step - loss: 0.0459 - accuracy: 0.9824 - f1_score: 0.9565 - val_loss: 0.1898 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 662/10000\n",
      "24/24 [==============================] - 1s 43ms/step - loss: 0.0446 - accuracy: 0.9878 - f1_score: 0.9708 - val_loss: 0.1898 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 663/10000\n",
      "24/24 [==============================] - 1s 45ms/step - loss: 0.0497 - accuracy: 0.9864 - f1_score: 0.9667 - val_loss: 0.1910 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 664/10000\n",
      "24/24 [==============================] - 1s 34ms/step - loss: 0.0523 - accuracy: 0.9837 - f1_score: 0.9566 - val_loss: 0.1908 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 665/10000\n",
      "24/24 [==============================] - 1s 34ms/step - loss: 0.0458 - accuracy: 0.9837 - f1_score: 0.9599 - val_loss: 0.1909 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 666/10000\n",
      "24/24 [==============================] - 1s 42ms/step - loss: 0.0484 - accuracy: 0.9851 - f1_score: 0.9659 - val_loss: 0.1906 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 667/10000\n",
      "24/24 [==============================] - 1s 41ms/step - loss: 0.0498 - accuracy: 0.9796 - f1_score: 0.9424 - val_loss: 0.1891 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 668/10000\n",
      "24/24 [==============================] - 1s 36ms/step - loss: 0.0555 - accuracy: 0.9810 - f1_score: 0.9495 - val_loss: 0.1812 - val_accuracy: 0.9383 - val_f1_score: 0.8448\n",
      "Epoch 669/10000\n",
      "24/24 [==============================] - 1s 45ms/step - loss: 0.0525 - accuracy: 0.9796 - f1_score: 0.9481 - val_loss: 0.1831 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 670/10000\n",
      "24/24 [==============================] - 1s 42ms/step - loss: 0.0520 - accuracy: 0.9864 - f1_score: 0.9668 - val_loss: 0.1847 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 671/10000\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0446 - accuracy: 0.9878 - f1_score: 0.9749 - val_loss: 0.1864 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 672/10000\n",
      "24/24 [==============================] - 1s 35ms/step - loss: 0.0448 - accuracy: 0.9878 - f1_score: 0.9675 - val_loss: 0.1874 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 673/10000\n",
      "24/24 [==============================] - 1s 42ms/step - loss: 0.0520 - accuracy: 0.9851 - f1_score: 0.9611 - val_loss: 0.1883 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 674/10000\n",
      "24/24 [==============================] - 1s 42ms/step - loss: 0.0552 - accuracy: 0.9796 - f1_score: 0.9498 - val_loss: 0.1885 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 675/10000\n",
      "24/24 [==============================] - 1s 45ms/step - loss: 0.0527 - accuracy: 0.9796 - f1_score: 0.9504 - val_loss: 0.1896 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 676/10000\n",
      "24/24 [==============================] - 1s 44ms/step - loss: 0.0443 - accuracy: 0.9851 - f1_score: 0.9650 - val_loss: 0.1898 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 677/10000\n",
      "24/24 [==============================] - 1s 44ms/step - loss: 0.0502 - accuracy: 0.9837 - f1_score: 0.9496 - val_loss: 0.1889 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 678/10000\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0537 - accuracy: 0.9824 - f1_score: 0.9559 - val_loss: 0.1884 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 679/10000\n",
      "24/24 [==============================] - 1s 34ms/step - loss: 0.0400 - accuracy: 0.9864 - f1_score: 0.9598 - val_loss: 0.1888 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 680/10000\n",
      "24/24 [==============================] - 1s 44ms/step - loss: 0.0415 - accuracy: 0.9878 - f1_score: 0.9675 - val_loss: 0.1896 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 681/10000\n",
      "24/24 [==============================] - 1s 41ms/step - loss: 0.0568 - accuracy: 0.9810 - f1_score: 0.9585 - val_loss: 0.1898 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 682/10000\n",
      "24/24 [==============================] - 1s 41ms/step - loss: 0.0467 - accuracy: 0.9864 - f1_score: 0.9691 - val_loss: 0.1877 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 683/10000\n",
      "24/24 [==============================] - 1s 44ms/step - loss: 0.0539 - accuracy: 0.9796 - f1_score: 0.9465 - val_loss: 0.1877 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 684/10000\n",
      "24/24 [==============================] - 1s 43ms/step - loss: 0.0629 - accuracy: 0.9783 - f1_score: 0.9556 - val_loss: 0.1897 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 685/10000\n",
      "24/24 [==============================] - 1s 34ms/step - loss: 0.0473 - accuracy: 0.9837 - f1_score: 0.9671 - val_loss: 0.1900 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 686/10000\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0438 - accuracy: 0.9864 - f1_score: 0.9667 - val_loss: 0.1899 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 687/10000\n",
      "24/24 [==============================] - 1s 48ms/step - loss: 0.0469 - accuracy: 0.9824 - f1_score: 0.9665 - val_loss: 0.1905 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 688/10000\n",
      "24/24 [==============================] - 1s 40ms/step - loss: 0.0463 - accuracy: 0.9891 - f1_score: 0.9729 - val_loss: 0.1904 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 689/10000\n",
      "24/24 [==============================] - 1s 48ms/step - loss: 0.0514 - accuracy: 0.9796 - f1_score: 0.9505 - val_loss: 0.1898 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 690/10000\n",
      "24/24 [==============================] - 1s 41ms/step - loss: 0.0525 - accuracy: 0.9837 - f1_score: 0.9599 - val_loss: 0.1895 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 691/10000\n",
      "24/24 [==============================] - 1s 40ms/step - loss: 0.0535 - accuracy: 0.9837 - f1_score: 0.9604 - val_loss: 0.1895 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 692/10000\n",
      "24/24 [==============================] - 1s 43ms/step - loss: 0.0413 - accuracy: 0.9864 - f1_score: 0.9610 - val_loss: 0.1898 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 693/10000\n",
      "24/24 [==============================] - 1s 45ms/step - loss: 0.0489 - accuracy: 0.9864 - f1_score: 0.9769 - val_loss: 0.1895 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 694/10000\n",
      "24/24 [==============================] - 1s 35ms/step - loss: 0.0484 - accuracy: 0.9851 - f1_score: 0.9622 - val_loss: 0.1893 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 695/10000\n",
      "24/24 [==============================] - 1s 40ms/step - loss: 0.0500 - accuracy: 0.9796 - f1_score: 0.9497 - val_loss: 0.1902 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 696/10000\n",
      "24/24 [==============================] - 1s 40ms/step - loss: 0.0473 - accuracy: 0.9878 - f1_score: 0.9782 - val_loss: 0.1849 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 697/10000\n",
      "24/24 [==============================] - 1s 41ms/step - loss: 0.0456 - accuracy: 0.9851 - f1_score: 0.9580 - val_loss: 0.1851 - val_accuracy: 0.9444 - val_f1_score: 0.8797\n",
      "Epoch 698/10000\n",
      "24/24 [==============================] - 1s 41ms/step - loss: 0.0479 - accuracy: 0.9783 - f1_score: 0.9375 - val_loss: 0.1862 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 699/10000\n",
      "24/24 [==============================] - 1s 34ms/step - loss: 0.0457 - accuracy: 0.9837 - f1_score: 0.9535 - val_loss: 0.1872 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 700/10000\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0460 - accuracy: 0.9810 - f1_score: 0.9548 - val_loss: 0.1871 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 701/10000\n",
      "24/24 [==============================] - 1s 40ms/step - loss: 0.0418 - accuracy: 0.9837 - f1_score: 0.9575 - val_loss: 0.1865 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 702/10000\n",
      "24/24 [==============================] - 1s 38ms/step - loss: 0.0467 - accuracy: 0.9851 - f1_score: 0.9523 - val_loss: 0.1867 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 703/10000\n",
      "24/24 [==============================] - 1s 38ms/step - loss: 0.0516 - accuracy: 0.9824 - f1_score: 0.9626 - val_loss: 0.1874 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 704/10000\n",
      "24/24 [==============================] - 1s 41ms/step - loss: 0.0496 - accuracy: 0.9824 - f1_score: 0.9592 - val_loss: 0.1887 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 705/10000\n",
      "24/24 [==============================] - 1s 34ms/step - loss: 0.0475 - accuracy: 0.9864 - f1_score: 0.9624 - val_loss: 0.1890 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 706/10000\n",
      "24/24 [==============================] - 1s 36ms/step - loss: 0.0589 - accuracy: 0.9810 - f1_score: 0.9587 - val_loss: 0.1889 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 707/10000\n",
      "24/24 [==============================] - 1s 41ms/step - loss: 0.0457 - accuracy: 0.9824 - f1_score: 0.9554 - val_loss: 0.1889 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 708/10000\n",
      "24/24 [==============================] - 1s 41ms/step - loss: 0.0471 - accuracy: 0.9851 - f1_score: 0.9721 - val_loss: 0.1888 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 709/10000\n",
      "24/24 [==============================] - 1s 40ms/step - loss: 0.0419 - accuracy: 0.9864 - f1_score: 0.9598 - val_loss: 0.1886 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 710/10000\n",
      "24/24 [==============================] - 1s 37ms/step - loss: 0.0610 - accuracy: 0.9810 - f1_score: 0.9580 - val_loss: 0.1889 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 711/10000\n",
      "24/24 [==============================] - 1s 34ms/step - loss: 0.0443 - accuracy: 0.9878 - f1_score: 0.9690 - val_loss: 0.1860 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 712/10000\n",
      "24/24 [==============================] - 1s 39ms/step - loss: 0.0511 - accuracy: 0.9810 - f1_score: 0.9510 - val_loss: 0.1857 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 713/10000\n",
      "24/24 [==============================] - 1s 40ms/step - loss: 0.0401 - accuracy: 0.9891 - f1_score: 0.9688 - val_loss: 0.1855 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 714/10000\n",
      "24/24 [==============================] - 1s 42ms/step - loss: 0.0398 - accuracy: 0.9878 - f1_score: 0.9679 - val_loss: 0.1865 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 715/10000\n",
      "24/24 [==============================] - 1s 42ms/step - loss: 0.0580 - accuracy: 0.9810 - f1_score: 0.9614 - val_loss: 0.1879 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 716/10000\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0430 - accuracy: 0.9851 - f1_score: 0.9611 - val_loss: 0.1882 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 717/10000\n",
      "24/24 [==============================] - 1s 34ms/step - loss: 0.0416 - accuracy: 0.9851 - f1_score: 0.9555 - val_loss: 0.1805 - val_accuracy: 0.9444 - val_f1_score: 0.8542\n",
      "Epoch 718/10000\n",
      "24/24 [==============================] - 1s 40ms/step - loss: 0.0475 - accuracy: 0.9864 - f1_score: 0.9662 - val_loss: 0.1816 - val_accuracy: 0.9568 - val_f1_score: 0.8984\n",
      "Epoch 719/10000\n",
      "24/24 [==============================] - 1s 37ms/step - loss: 0.0449 - accuracy: 0.9796 - f1_score: 0.9455 - val_loss: 0.1830 - val_accuracy: 0.9568 - val_f1_score: 0.8984\n",
      "Epoch 720/10000\n",
      "24/24 [==============================] - 1s 38ms/step - loss: 0.0440 - accuracy: 0.9891 - f1_score: 0.9793 - val_loss: 0.1846 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 721/10000\n",
      "24/24 [==============================] - 1s 41ms/step - loss: 0.0508 - accuracy: 0.9810 - f1_score: 0.9544 - val_loss: 0.1861 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 722/10000\n",
      "24/24 [==============================] - 1s 35ms/step - loss: 0.0554 - accuracy: 0.9824 - f1_score: 0.9664 - val_loss: 0.1866 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 723/10000\n",
      "24/24 [==============================] - 1s 32ms/step - loss: 0.0520 - accuracy: 0.9810 - f1_score: 0.9574 - val_loss: 0.1870 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 724/10000\n",
      "24/24 [==============================] - 1s 39ms/step - loss: 0.0548 - accuracy: 0.9796 - f1_score: 0.9547 - val_loss: 0.1871 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 725/10000\n",
      "24/24 [==============================] - 1s 41ms/step - loss: 0.0532 - accuracy: 0.9878 - f1_score: 0.9642 - val_loss: 0.1882 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 726/10000\n",
      "24/24 [==============================] - 1s 41ms/step - loss: 0.0461 - accuracy: 0.9810 - f1_score: 0.9470 - val_loss: 0.1887 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 727/10000\n",
      "24/24 [==============================] - 1s 36ms/step - loss: 0.0459 - accuracy: 0.9878 - f1_score: 0.9616 - val_loss: 0.1883 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 728/10000\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0407 - accuracy: 0.9905 - f1_score: 0.9774 - val_loss: 0.1878 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 729/10000\n",
      "24/24 [==============================] - 1s 40ms/step - loss: 0.0517 - accuracy: 0.9810 - f1_score: 0.9478 - val_loss: 0.1875 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 730/10000\n",
      "24/24 [==============================] - 1s 38ms/step - loss: 0.0436 - accuracy: 0.9851 - f1_score: 0.9592 - val_loss: 0.1881 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 731/10000\n",
      "24/24 [==============================] - 1s 38ms/step - loss: 0.0549 - accuracy: 0.9796 - f1_score: 0.9568 - val_loss: 0.1884 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 732/10000\n",
      "24/24 [==============================] - 1s 41ms/step - loss: 0.0494 - accuracy: 0.9851 - f1_score: 0.9592 - val_loss: 0.1877 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 733/10000\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0392 - accuracy: 0.9851 - f1_score: 0.9623 - val_loss: 0.1881 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 734/10000\n",
      "24/24 [==============================] - 1s 35ms/step - loss: 0.0475 - accuracy: 0.9810 - f1_score: 0.9542 - val_loss: 0.1883 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 735/10000\n",
      "24/24 [==============================] - 1s 41ms/step - loss: 0.0387 - accuracy: 0.9878 - f1_score: 0.9604 - val_loss: 0.1886 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 736/10000\n",
      "24/24 [==============================] - 1s 42ms/step - loss: 0.0398 - accuracy: 0.9878 - f1_score: 0.9604 - val_loss: 0.1893 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 737/10000\n",
      "24/24 [==============================] - 1s 41ms/step - loss: 0.0446 - accuracy: 0.9796 - f1_score: 0.9387 - val_loss: 0.1905 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 738/10000\n",
      "24/24 [==============================] - 1s 42ms/step - loss: 0.0428 - accuracy: 0.9864 - f1_score: 0.9635 - val_loss: 0.1899 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 739/10000\n",
      "24/24 [==============================] - 1s 46ms/step - loss: 0.0429 - accuracy: 0.9837 - f1_score: 0.9605 - val_loss: 0.1889 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 740/10000\n",
      "24/24 [==============================] - 1s 44ms/step - loss: 0.0396 - accuracy: 0.9891 - f1_score: 0.9725 - val_loss: 0.1885 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 741/10000\n",
      "24/24 [==============================] - 1s 44ms/step - loss: 0.0486 - accuracy: 0.9769 - f1_score: 0.9434 - val_loss: 0.1875 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 742/10000\n",
      "24/24 [==============================] - 1s 44ms/step - loss: 0.0552 - accuracy: 0.9769 - f1_score: 0.9402 - val_loss: 0.1865 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 743/10000\n",
      "24/24 [==============================] - 1s 43ms/step - loss: 0.0447 - accuracy: 0.9837 - f1_score: 0.9642 - val_loss: 0.1875 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 744/10000\n",
      "24/24 [==============================] - 1s 45ms/step - loss: 0.0484 - accuracy: 0.9783 - f1_score: 0.9344 - val_loss: 0.1880 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 745/10000\n",
      "24/24 [==============================] - 1s 50ms/step - loss: 0.0430 - accuracy: 0.9864 - f1_score: 0.9591 - val_loss: 0.1876 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 746/10000\n",
      "24/24 [==============================] - 1s 40ms/step - loss: 0.0383 - accuracy: 0.9878 - f1_score: 0.9670 - val_loss: 0.1870 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 747/10000\n",
      "24/24 [==============================] - 1s 38ms/step - loss: 0.0454 - accuracy: 0.9891 - f1_score: 0.9661 - val_loss: 0.1873 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 748/10000\n",
      "24/24 [==============================] - 1s 39ms/step - loss: 0.0379 - accuracy: 0.9891 - f1_score: 0.9797 - val_loss: 0.1869 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 749/10000\n",
      "24/24 [==============================] - 1s 41ms/step - loss: 0.0423 - accuracy: 0.9878 - f1_score: 0.9631 - val_loss: 0.1874 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 750/10000\n",
      "24/24 [==============================] - 1s 44ms/step - loss: 0.0443 - accuracy: 0.9851 - f1_score: 0.9623 - val_loss: 0.1873 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 751/10000\n",
      "24/24 [==============================] - 1s 43ms/step - loss: 0.0402 - accuracy: 0.9851 - f1_score: 0.9613 - val_loss: 0.1881 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 752/10000\n",
      "24/24 [==============================] - 1s 40ms/step - loss: 0.0478 - accuracy: 0.9783 - f1_score: 0.9454 - val_loss: 0.1885 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 753/10000\n",
      "24/24 [==============================] - 1s 43ms/step - loss: 0.0528 - accuracy: 0.9851 - f1_score: 0.9665 - val_loss: 0.1895 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 754/10000\n",
      "24/24 [==============================] - 1s 44ms/step - loss: 0.0365 - accuracy: 0.9905 - f1_score: 0.9733 - val_loss: 0.1894 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 755/10000\n",
      "24/24 [==============================] - 1s 41ms/step - loss: 0.0381 - accuracy: 0.9891 - f1_score: 0.9692 - val_loss: 0.1894 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 756/10000\n",
      "24/24 [==============================] - 1s 43ms/step - loss: 0.0487 - accuracy: 0.9878 - f1_score: 0.9712 - val_loss: 0.1885 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 757/10000\n",
      "24/24 [==============================] - 1s 42ms/step - loss: 0.0358 - accuracy: 0.9905 - f1_score: 0.9741 - val_loss: 0.1879 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 758/10000\n",
      "24/24 [==============================] - 1s 41ms/step - loss: 0.0389 - accuracy: 0.9864 - f1_score: 0.9578 - val_loss: 0.1882 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 759/10000\n",
      "24/24 [==============================] - 1s 42ms/step - loss: 0.0424 - accuracy: 0.9851 - f1_score: 0.9579 - val_loss: 0.1887 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 760/10000\n",
      "24/24 [==============================] - 1s 42ms/step - loss: 0.0408 - accuracy: 0.9891 - f1_score: 0.9725 - val_loss: 0.1889 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 761/10000\n",
      "24/24 [==============================] - 1s 43ms/step - loss: 0.0639 - accuracy: 0.9769 - f1_score: 0.9576 - val_loss: 0.1893 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 762/10000\n",
      "24/24 [==============================] - 1s 36ms/step - loss: 0.0419 - accuracy: 0.9810 - f1_score: 0.9502 - val_loss: 0.1883 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 763/10000\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0560 - accuracy: 0.9810 - f1_score: 0.9581 - val_loss: 0.1886 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 764/10000\n",
      "24/24 [==============================] - 1s 39ms/step - loss: 0.0394 - accuracy: 0.9851 - f1_score: 0.9650 - val_loss: 0.1888 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 765/10000\n",
      "24/24 [==============================] - 1s 41ms/step - loss: 0.0324 - accuracy: 0.9891 - f1_score: 0.9623 - val_loss: 0.1881 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 766/10000\n",
      "24/24 [==============================] - 1s 41ms/step - loss: 0.0397 - accuracy: 0.9878 - f1_score: 0.9636 - val_loss: 0.1884 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 767/10000\n",
      "24/24 [==============================] - 1s 40ms/step - loss: 0.0391 - accuracy: 0.9864 - f1_score: 0.9704 - val_loss: 0.1886 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 768/10000\n",
      "24/24 [==============================] - 1s 40ms/step - loss: 0.0452 - accuracy: 0.9796 - f1_score: 0.9466 - val_loss: 0.1881 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 769/10000\n",
      "24/24 [==============================] - 1s 40ms/step - loss: 0.0459 - accuracy: 0.9891 - f1_score: 0.9756 - val_loss: 0.1887 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 770/10000\n",
      "24/24 [==============================] - 1s 39ms/step - loss: 0.0509 - accuracy: 0.9810 - f1_score: 0.9548 - val_loss: 0.1893 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 771/10000\n",
      "24/24 [==============================] - 1s 39ms/step - loss: 0.0439 - accuracy: 0.9864 - f1_score: 0.9630 - val_loss: 0.1891 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 772/10000\n",
      "24/24 [==============================] - 1s 43ms/step - loss: 0.0399 - accuracy: 0.9824 - f1_score: 0.9483 - val_loss: 0.1888 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 773/10000\n",
      "24/24 [==============================] - 1s 36ms/step - loss: 0.0346 - accuracy: 0.9864 - f1_score: 0.9630 - val_loss: 0.1898 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 774/10000\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0484 - accuracy: 0.9864 - f1_score: 0.9770 - val_loss: 0.1891 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 775/10000\n",
      "24/24 [==============================] - 1s 36ms/step - loss: 0.0350 - accuracy: 0.9878 - f1_score: 0.9648 - val_loss: 0.1888 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 776/10000\n",
      "24/24 [==============================] - 1s 48ms/step - loss: 0.0373 - accuracy: 0.9891 - f1_score: 0.9643 - val_loss: 0.1890 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 777/10000\n",
      "24/24 [==============================] - 1s 42ms/step - loss: 0.0488 - accuracy: 0.9769 - f1_score: 0.9394 - val_loss: 0.1897 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 778/10000\n",
      "24/24 [==============================] - 1s 39ms/step - loss: 0.0458 - accuracy: 0.9837 - f1_score: 0.9647 - val_loss: 0.1898 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 779/10000\n",
      "24/24 [==============================] - 1s 40ms/step - loss: 0.0445 - accuracy: 0.9851 - f1_score: 0.9579 - val_loss: 0.1899 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 780/10000\n",
      "24/24 [==============================] - 1s 42ms/step - loss: 0.0453 - accuracy: 0.9878 - f1_score: 0.9675 - val_loss: 0.1894 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 781/10000\n",
      "24/24 [==============================] - 1s 35ms/step - loss: 0.0534 - accuracy: 0.9783 - f1_score: 0.9406 - val_loss: 0.1896 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 782/10000\n",
      "24/24 [==============================] - 1s 38ms/step - loss: 0.0411 - accuracy: 0.9891 - f1_score: 0.9692 - val_loss: 0.1892 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 783/10000\n",
      "24/24 [==============================] - 1s 37ms/step - loss: 0.0459 - accuracy: 0.9810 - f1_score: 0.9509 - val_loss: 0.1888 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 784/10000\n",
      "24/24 [==============================] - 1s 38ms/step - loss: 0.0430 - accuracy: 0.9851 - f1_score: 0.9579 - val_loss: 0.1888 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 785/10000\n",
      "24/24 [==============================] - 1s 35ms/step - loss: 0.0435 - accuracy: 0.9824 - f1_score: 0.9560 - val_loss: 0.1887 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 786/10000\n",
      "24/24 [==============================] - 1s 32ms/step - loss: 0.0409 - accuracy: 0.9851 - f1_score: 0.9548 - val_loss: 0.1889 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 787/10000\n",
      "24/24 [==============================] - 1s 32ms/step - loss: 0.0525 - accuracy: 0.9756 - f1_score: 0.9421 - val_loss: 0.1895 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 788/10000\n",
      "24/24 [==============================] - 1s 34ms/step - loss: 0.0332 - accuracy: 0.9905 - f1_score: 0.9679 - val_loss: 0.1895 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 789/10000\n",
      "24/24 [==============================] - 1s 34ms/step - loss: 0.0459 - accuracy: 0.9851 - f1_score: 0.9617 - val_loss: 0.1892 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 790/10000\n",
      "24/24 [==============================] - 1s 34ms/step - loss: 0.0452 - accuracy: 0.9783 - f1_score: 0.9415 - val_loss: 0.1895 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 791/10000\n",
      "24/24 [==============================] - 1s 35ms/step - loss: 0.0383 - accuracy: 0.9851 - f1_score: 0.9586 - val_loss: 0.1888 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 792/10000\n",
      "24/24 [==============================] - 1s 34ms/step - loss: 0.0431 - accuracy: 0.9851 - f1_score: 0.9573 - val_loss: 0.1886 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 793/10000\n",
      "24/24 [==============================] - 1s 34ms/step - loss: 0.0562 - accuracy: 0.9810 - f1_score: 0.9543 - val_loss: 0.1880 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 794/10000\n",
      "24/24 [==============================] - 1s 35ms/step - loss: 0.0402 - accuracy: 0.9837 - f1_score: 0.9642 - val_loss: 0.1881 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 795/10000\n",
      "24/24 [==============================] - 1s 41ms/step - loss: 0.0419 - accuracy: 0.9837 - f1_score: 0.9560 - val_loss: 0.1883 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 796/10000\n",
      "24/24 [==============================] - 1s 36ms/step - loss: 0.0463 - accuracy: 0.9810 - f1_score: 0.9524 - val_loss: 0.1885 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 797/10000\n",
      "24/24 [==============================] - 1s 34ms/step - loss: 0.0515 - accuracy: 0.9810 - f1_score: 0.9541 - val_loss: 0.1887 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 798/10000\n",
      "24/24 [==============================] - 1s 32ms/step - loss: 0.0474 - accuracy: 0.9783 - f1_score: 0.9494 - val_loss: 0.1898 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 799/10000\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0372 - accuracy: 0.9878 - f1_score: 0.9685 - val_loss: 0.1899 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 800/10000\n",
      "24/24 [==============================] - 1s 35ms/step - loss: 0.0301 - accuracy: 0.9905 - f1_score: 0.9668 - val_loss: 0.1896 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 801/10000\n",
      "24/24 [==============================] - 1s 38ms/step - loss: 0.0357 - accuracy: 0.9878 - f1_score: 0.9648 - val_loss: 0.1893 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 802/10000\n",
      "24/24 [==============================] - 1s 35ms/step - loss: 0.0433 - accuracy: 0.9837 - f1_score: 0.9573 - val_loss: 0.1888 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 803/10000\n",
      "24/24 [==============================] - 1s 35ms/step - loss: 0.0417 - accuracy: 0.9878 - f1_score: 0.9680 - val_loss: 0.1884 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 804/10000\n",
      "24/24 [==============================] - 1s 37ms/step - loss: 0.0540 - accuracy: 0.9783 - f1_score: 0.9446 - val_loss: 0.1880 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 805/10000\n",
      "24/24 [==============================] - 1s 37ms/step - loss: 0.0509 - accuracy: 0.9796 - f1_score: 0.9529 - val_loss: 0.1897 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 806/10000\n",
      "24/24 [==============================] - 1s 36ms/step - loss: 0.0379 - accuracy: 0.9837 - f1_score: 0.9535 - val_loss: 0.1884 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 807/10000\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0402 - accuracy: 0.9810 - f1_score: 0.9479 - val_loss: 0.1894 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 808/10000\n",
      "24/24 [==============================] - 1s 37ms/step - loss: 0.0412 - accuracy: 0.9878 - f1_score: 0.9716 - val_loss: 0.1891 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 809/10000\n",
      "24/24 [==============================] - 1s 38ms/step - loss: 0.0427 - accuracy: 0.9891 - f1_score: 0.9697 - val_loss: 0.1884 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 810/10000\n",
      "24/24 [==============================] - 1s 36ms/step - loss: 0.0545 - accuracy: 0.9824 - f1_score: 0.9592 - val_loss: 0.1878 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 811/10000\n",
      "24/24 [==============================] - 1s 34ms/step - loss: 0.0372 - accuracy: 0.9878 - f1_score: 0.9680 - val_loss: 0.1883 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 812/10000\n",
      "24/24 [==============================] - 1s 35ms/step - loss: 0.0483 - accuracy: 0.9796 - f1_score: 0.9436 - val_loss: 0.1886 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 813/10000\n",
      "24/24 [==============================] - 1s 36ms/step - loss: 0.0411 - accuracy: 0.9824 - f1_score: 0.9412 - val_loss: 0.1892 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 814/10000\n",
      "24/24 [==============================] - 1s 36ms/step - loss: 0.0417 - accuracy: 0.9851 - f1_score: 0.9586 - val_loss: 0.1897 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 815/10000\n",
      "24/24 [==============================] - 1s 35ms/step - loss: 0.0361 - accuracy: 0.9824 - f1_score: 0.9523 - val_loss: 0.1874 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 816/10000\n",
      "24/24 [==============================] - 1s 36ms/step - loss: 0.0365 - accuracy: 0.9878 - f1_score: 0.9637 - val_loss: 0.1873 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 817/10000\n",
      "24/24 [==============================] - 1s 44ms/step - loss: 0.0447 - accuracy: 0.9851 - f1_score: 0.9655 - val_loss: 0.1855 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 818/10000\n",
      "24/24 [==============================] - 1s 44ms/step - loss: 0.0340 - accuracy: 0.9919 - f1_score: 0.9784 - val_loss: 0.1853 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 819/10000\n",
      "24/24 [==============================] - 1s 39ms/step - loss: 0.0436 - accuracy: 0.9837 - f1_score: 0.9527 - val_loss: 0.1860 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 820/10000\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0468 - accuracy: 0.9864 - f1_score: 0.9635 - val_loss: 0.1860 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 821/10000\n",
      "24/24 [==============================] - 1s 32ms/step - loss: 0.0389 - accuracy: 0.9851 - f1_score: 0.9580 - val_loss: 0.1862 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 822/10000\n",
      "24/24 [==============================] - 1s 38ms/step - loss: 0.0389 - accuracy: 0.9837 - f1_score: 0.9573 - val_loss: 0.1866 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 823/10000\n",
      "24/24 [==============================] - 1s 37ms/step - loss: 0.0400 - accuracy: 0.9824 - f1_score: 0.9499 - val_loss: 0.1868 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 824/10000\n",
      "24/24 [==============================] - 1s 36ms/step - loss: 0.0384 - accuracy: 0.9864 - f1_score: 0.9641 - val_loss: 0.1876 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 825/10000\n",
      "24/24 [==============================] - 1s 35ms/step - loss: 0.0448 - accuracy: 0.9824 - f1_score: 0.9654 - val_loss: 0.1884 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 826/10000\n",
      "24/24 [==============================] - 1s 34ms/step - loss: 0.0378 - accuracy: 0.9878 - f1_score: 0.9648 - val_loss: 0.1880 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 827/10000\n",
      "24/24 [==============================] - 1s 37ms/step - loss: 0.0497 - accuracy: 0.9837 - f1_score: 0.9611 - val_loss: 0.1881 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 828/10000\n",
      "24/24 [==============================] - 1s 38ms/step - loss: 0.0328 - accuracy: 0.9878 - f1_score: 0.9611 - val_loss: 0.1877 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 829/10000\n",
      "24/24 [==============================] - 1s 37ms/step - loss: 0.0414 - accuracy: 0.9864 - f1_score: 0.9630 - val_loss: 0.1883 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 830/10000\n",
      "24/24 [==============================] - 1s 36ms/step - loss: 0.0519 - accuracy: 0.9824 - f1_score: 0.9560 - val_loss: 0.1875 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 831/10000\n",
      "24/24 [==============================] - 1s 34ms/step - loss: 0.0395 - accuracy: 0.9851 - f1_score: 0.9579 - val_loss: 0.1869 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 832/10000\n",
      "24/24 [==============================] - 1s 36ms/step - loss: 0.0377 - accuracy: 0.9905 - f1_score: 0.9737 - val_loss: 0.1867 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 833/10000\n",
      "24/24 [==============================] - 1s 43ms/step - loss: 0.0372 - accuracy: 0.9864 - f1_score: 0.9560 - val_loss: 0.1870 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 834/10000\n",
      "24/24 [==============================] - 1s 40ms/step - loss: 0.0394 - accuracy: 0.9891 - f1_score: 0.9764 - val_loss: 0.1867 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 835/10000\n",
      "24/24 [==============================] - 1s 38ms/step - loss: 0.0485 - accuracy: 0.9837 - f1_score: 0.9679 - val_loss: 0.1865 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 836/10000\n",
      "24/24 [==============================] - 1s 35ms/step - loss: 0.0348 - accuracy: 0.9878 - f1_score: 0.9708 - val_loss: 0.1862 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 837/10000\n",
      "24/24 [==============================] - 1s 34ms/step - loss: 0.0392 - accuracy: 0.9864 - f1_score: 0.9663 - val_loss: 0.1861 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 838/10000\n",
      "24/24 [==============================] - 1s 38ms/step - loss: 0.0374 - accuracy: 0.9864 - f1_score: 0.9624 - val_loss: 0.1859 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 839/10000\n",
      "24/24 [==============================] - 1s 37ms/step - loss: 0.0453 - accuracy: 0.9810 - f1_score: 0.9548 - val_loss: 0.1852 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 840/10000\n",
      "24/24 [==============================] - 1s 36ms/step - loss: 0.0351 - accuracy: 0.9864 - f1_score: 0.9635 - val_loss: 0.1865 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 841/10000\n",
      "24/24 [==============================] - 1s 35ms/step - loss: 0.0424 - accuracy: 0.9837 - f1_score: 0.9610 - val_loss: 0.1862 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 842/10000\n",
      "24/24 [==============================] - 1s 37ms/step - loss: 0.0405 - accuracy: 0.9864 - f1_score: 0.9667 - val_loss: 0.1855 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 843/10000\n",
      "24/24 [==============================] - 1s 35ms/step - loss: 0.0353 - accuracy: 0.9851 - f1_score: 0.9555 - val_loss: 0.1856 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 844/10000\n",
      "24/24 [==============================] - 1s 37ms/step - loss: 0.0503 - accuracy: 0.9796 - f1_score: 0.9423 - val_loss: 0.1827 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 845/10000\n",
      "24/24 [==============================] - 1s 37ms/step - loss: 0.0468 - accuracy: 0.9796 - f1_score: 0.9503 - val_loss: 0.1832 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 846/10000\n",
      "24/24 [==============================] - 1s 35ms/step - loss: 0.0457 - accuracy: 0.9864 - f1_score: 0.9734 - val_loss: 0.1835 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 847/10000\n",
      "24/24 [==============================] - 1s 35ms/step - loss: 0.0447 - accuracy: 0.9796 - f1_score: 0.9504 - val_loss: 0.1837 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 848/10000\n",
      "24/24 [==============================] - 1s 35ms/step - loss: 0.0369 - accuracy: 0.9878 - f1_score: 0.9611 - val_loss: 0.1819 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 849/10000\n",
      "24/24 [==============================] - 1s 36ms/step - loss: 0.0440 - accuracy: 0.9810 - f1_score: 0.9509 - val_loss: 0.1827 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 850/10000\n",
      "24/24 [==============================] - 1s 38ms/step - loss: 0.0328 - accuracy: 0.9864 - f1_score: 0.9598 - val_loss: 0.1840 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 851/10000\n",
      "24/24 [==============================] - 1s 36ms/step - loss: 0.0374 - accuracy: 0.9878 - f1_score: 0.9671 - val_loss: 0.1843 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 852/10000\n",
      "24/24 [==============================] - 1s 35ms/step - loss: 0.0431 - accuracy: 0.9864 - f1_score: 0.9624 - val_loss: 0.1828 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 853/10000\n",
      "24/24 [==============================] - 1s 37ms/step - loss: 0.0390 - accuracy: 0.9864 - f1_score: 0.9560 - val_loss: 0.1818 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 854/10000\n",
      "24/24 [==============================] - 1s 37ms/step - loss: 0.0373 - accuracy: 0.9878 - f1_score: 0.9611 - val_loss: 0.1825 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 855/10000\n",
      "24/24 [==============================] - 1s 37ms/step - loss: 0.0501 - accuracy: 0.9824 - f1_score: 0.9561 - val_loss: 0.1825 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 856/10000\n",
      "24/24 [==============================] - 1s 36ms/step - loss: 0.0397 - accuracy: 0.9837 - f1_score: 0.9580 - val_loss: 0.1836 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 857/10000\n",
      "24/24 [==============================] - 1s 38ms/step - loss: 0.0343 - accuracy: 0.9851 - f1_score: 0.9586 - val_loss: 0.1842 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 858/10000\n",
      "24/24 [==============================] - 1s 38ms/step - loss: 0.0470 - accuracy: 0.9824 - f1_score: 0.9546 - val_loss: 0.1845 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 859/10000\n",
      "24/24 [==============================] - 1s 37ms/step - loss: 0.0384 - accuracy: 0.9864 - f1_score: 0.9629 - val_loss: 0.1852 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 860/10000\n",
      "24/24 [==============================] - 1s 36ms/step - loss: 0.0319 - accuracy: 0.9891 - f1_score: 0.9623 - val_loss: 0.1851 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 861/10000\n",
      "24/24 [==============================] - 1s 36ms/step - loss: 0.0491 - accuracy: 0.9783 - f1_score: 0.9455 - val_loss: 0.1841 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 862/10000\n",
      "24/24 [==============================] - 1s 34ms/step - loss: 0.0316 - accuracy: 0.9946 - f1_score: 0.9842 - val_loss: 0.1852 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 863/10000\n",
      "24/24 [==============================] - 1s 34ms/step - loss: 0.0412 - accuracy: 0.9851 - f1_score: 0.9579 - val_loss: 0.1852 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 864/10000\n",
      "24/24 [==============================] - 1s 37ms/step - loss: 0.0417 - accuracy: 0.9905 - f1_score: 0.9706 - val_loss: 0.1848 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 865/10000\n",
      "24/24 [==============================] - 1s 35ms/step - loss: 0.0388 - accuracy: 0.9864 - f1_score: 0.9592 - val_loss: 0.1844 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 866/10000\n",
      "24/24 [==============================] - 1s 35ms/step - loss: 0.0325 - accuracy: 0.9864 - f1_score: 0.9552 - val_loss: 0.1835 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 867/10000\n",
      "24/24 [==============================] - 1s 35ms/step - loss: 0.0429 - accuracy: 0.9837 - f1_score: 0.9617 - val_loss: 0.1835 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 868/10000\n",
      "24/24 [==============================] - 1s 34ms/step - loss: 0.0398 - accuracy: 0.9837 - f1_score: 0.9543 - val_loss: 0.1834 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 869/10000\n",
      "24/24 [==============================] - 1s 34ms/step - loss: 0.0401 - accuracy: 0.9864 - f1_score: 0.9668 - val_loss: 0.1842 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 870/10000\n",
      "24/24 [==============================] - 1s 35ms/step - loss: 0.0483 - accuracy: 0.9810 - f1_score: 0.9543 - val_loss: 0.1845 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 871/10000\n",
      "24/24 [==============================] - 1s 35ms/step - loss: 0.0421 - accuracy: 0.9864 - f1_score: 0.9701 - val_loss: 0.1846 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 872/10000\n",
      "24/24 [==============================] - 1s 34ms/step - loss: 0.0355 - accuracy: 0.9864 - f1_score: 0.9591 - val_loss: 0.1852 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 873/10000\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0328 - accuracy: 0.9919 - f1_score: 0.9746 - val_loss: 0.1855 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 874/10000\n",
      "24/24 [==============================] - 1s 34ms/step - loss: 0.0399 - accuracy: 0.9810 - f1_score: 0.9549 - val_loss: 0.1856 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 875/10000\n",
      "24/24 [==============================] - 1s 34ms/step - loss: 0.0400 - accuracy: 0.9878 - f1_score: 0.9685 - val_loss: 0.1857 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 876/10000\n",
      "24/24 [==============================] - 1s 34ms/step - loss: 0.0333 - accuracy: 0.9891 - f1_score: 0.9655 - val_loss: 0.1848 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 877/10000\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0448 - accuracy: 0.9810 - f1_score: 0.9441 - val_loss: 0.1850 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 878/10000\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0383 - accuracy: 0.9824 - f1_score: 0.9554 - val_loss: 0.1847 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 879/10000\n",
      "24/24 [==============================] - 1s 34ms/step - loss: 0.0372 - accuracy: 0.9837 - f1_score: 0.9527 - val_loss: 0.1851 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 880/10000\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0501 - accuracy: 0.9810 - f1_score: 0.9485 - val_loss: 0.1844 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 881/10000\n",
      "24/24 [==============================] - 1s 34ms/step - loss: 0.0381 - accuracy: 0.9891 - f1_score: 0.9693 - val_loss: 0.1837 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 882/10000\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0357 - accuracy: 0.9878 - f1_score: 0.9642 - val_loss: 0.1833 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 883/10000\n",
      "24/24 [==============================] - 1s 32ms/step - loss: 0.0383 - accuracy: 0.9864 - f1_score: 0.9635 - val_loss: 0.1837 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 884/10000\n",
      "24/24 [==============================] - 1s 34ms/step - loss: 0.0415 - accuracy: 0.9864 - f1_score: 0.9618 - val_loss: 0.1845 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 885/10000\n",
      "24/24 [==============================] - 1s 34ms/step - loss: 0.0373 - accuracy: 0.9878 - f1_score: 0.9648 - val_loss: 0.1850 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 886/10000\n",
      "24/24 [==============================] - 1s 34ms/step - loss: 0.0350 - accuracy: 0.9851 - f1_score: 0.9579 - val_loss: 0.1849 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 887/10000\n",
      "24/24 [==============================] - 1s 32ms/step - loss: 0.0434 - accuracy: 0.9864 - f1_score: 0.9734 - val_loss: 0.1848 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 888/10000\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0332 - accuracy: 0.9905 - f1_score: 0.9695 - val_loss: 0.1841 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 889/10000\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0353 - accuracy: 0.9878 - f1_score: 0.9680 - val_loss: 0.1842 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 890/10000\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0359 - accuracy: 0.9864 - f1_score: 0.9635 - val_loss: 0.1843 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 891/10000\n",
      "24/24 [==============================] - 1s 32ms/step - loss: 0.0378 - accuracy: 0.9837 - f1_score: 0.9574 - val_loss: 0.1836 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 892/10000\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0327 - accuracy: 0.9878 - f1_score: 0.9709 - val_loss: 0.1840 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 893/10000\n",
      "24/24 [==============================] - 1s 35ms/step - loss: 0.0420 - accuracy: 0.9824 - f1_score: 0.9530 - val_loss: 0.1843 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 894/10000\n",
      "24/24 [==============================] - 1s 35ms/step - loss: 0.0364 - accuracy: 0.9891 - f1_score: 0.9687 - val_loss: 0.1856 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 895/10000\n",
      "24/24 [==============================] - 1s 34ms/step - loss: 0.0437 - accuracy: 0.9837 - f1_score: 0.9605 - val_loss: 0.1852 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 896/10000\n",
      "24/24 [==============================] - 1s 35ms/step - loss: 0.0380 - accuracy: 0.9851 - f1_score: 0.9618 - val_loss: 0.1841 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 897/10000\n",
      "24/24 [==============================] - 1s 34ms/step - loss: 0.0335 - accuracy: 0.9878 - f1_score: 0.9642 - val_loss: 0.1840 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 898/10000\n",
      "24/24 [==============================] - 1s 36ms/step - loss: 0.0325 - accuracy: 0.9878 - f1_score: 0.9675 - val_loss: 0.1843 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 899/10000\n",
      "24/24 [==============================] - 1s 35ms/step - loss: 0.0377 - accuracy: 0.9851 - f1_score: 0.9612 - val_loss: 0.1845 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 900/10000\n",
      "24/24 [==============================] - 1s 35ms/step - loss: 0.0370 - accuracy: 0.9837 - f1_score: 0.9487 - val_loss: 0.1839 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 901/10000\n",
      "24/24 [==============================] - 1s 36ms/step - loss: 0.0384 - accuracy: 0.9878 - f1_score: 0.9685 - val_loss: 0.1844 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 902/10000\n",
      "24/24 [==============================] - 1s 38ms/step - loss: 0.0318 - accuracy: 0.9919 - f1_score: 0.9746 - val_loss: 0.1841 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 903/10000\n",
      "24/24 [==============================] - 1s 39ms/step - loss: 0.0335 - accuracy: 0.9891 - f1_score: 0.9617 - val_loss: 0.1845 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 904/10000\n",
      "24/24 [==============================] - 1s 38ms/step - loss: 0.0425 - accuracy: 0.9837 - f1_score: 0.9610 - val_loss: 0.1835 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 905/10000\n",
      "24/24 [==============================] - 1s 36ms/step - loss: 0.0430 - accuracy: 0.9851 - f1_score: 0.9580 - val_loss: 0.1841 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 906/10000\n",
      "24/24 [==============================] - 1s 36ms/step - loss: 0.0373 - accuracy: 0.9878 - f1_score: 0.9642 - val_loss: 0.1833 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 907/10000\n",
      "24/24 [==============================] - 1s 36ms/step - loss: 0.0328 - accuracy: 0.9905 - f1_score: 0.9700 - val_loss: 0.1836 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 908/10000\n",
      "24/24 [==============================] - 1s 36ms/step - loss: 0.0324 - accuracy: 0.9851 - f1_score: 0.9579 - val_loss: 0.1838 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 909/10000\n",
      "24/24 [==============================] - 1s 37ms/step - loss: 0.0324 - accuracy: 0.9878 - f1_score: 0.9643 - val_loss: 0.1838 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 910/10000\n",
      "24/24 [==============================] - 1s 37ms/step - loss: 0.0352 - accuracy: 0.9878 - f1_score: 0.9648 - val_loss: 0.1833 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 911/10000\n",
      "24/24 [==============================] - 1s 39ms/step - loss: 0.0396 - accuracy: 0.9851 - f1_score: 0.9611 - val_loss: 0.1839 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 912/10000\n",
      "24/24 [==============================] - 1s 35ms/step - loss: 0.0405 - accuracy: 0.9837 - f1_score: 0.9574 - val_loss: 0.1833 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 913/10000\n",
      "24/24 [==============================] - 1s 36ms/step - loss: 0.0311 - accuracy: 0.9932 - f1_score: 0.9802 - val_loss: 0.1837 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 914/10000\n",
      "24/24 [==============================] - 1s 35ms/step - loss: 0.0388 - accuracy: 0.9824 - f1_score: 0.9443 - val_loss: 0.1843 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 915/10000\n",
      "24/24 [==============================] - 1s 35ms/step - loss: 0.0403 - accuracy: 0.9864 - f1_score: 0.9624 - val_loss: 0.1845 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 916/10000\n",
      "24/24 [==============================] - 1s 36ms/step - loss: 0.0422 - accuracy: 0.9851 - f1_score: 0.9586 - val_loss: 0.1857 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 917/10000\n",
      "24/24 [==============================] - 1s 38ms/step - loss: 0.0333 - accuracy: 0.9891 - f1_score: 0.9693 - val_loss: 0.1836 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 918/10000\n",
      "24/24 [==============================] - 1s 37ms/step - loss: 0.0408 - accuracy: 0.9864 - f1_score: 0.9636 - val_loss: 0.1826 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 919/10000\n",
      "24/24 [==============================] - 1s 37ms/step - loss: 0.0309 - accuracy: 0.9905 - f1_score: 0.9700 - val_loss: 0.1822 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 920/10000\n",
      "24/24 [==============================] - 1s 38ms/step - loss: 0.0388 - accuracy: 0.9824 - f1_score: 0.9561 - val_loss: 0.1817 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 921/10000\n",
      "24/24 [==============================] - 1s 39ms/step - loss: 0.0338 - accuracy: 0.9851 - f1_score: 0.9555 - val_loss: 0.1825 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 922/10000\n",
      "24/24 [==============================] - 1s 37ms/step - loss: 0.0445 - accuracy: 0.9824 - f1_score: 0.9602 - val_loss: 0.1824 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 923/10000\n",
      "24/24 [==============================] - 1s 37ms/step - loss: 0.0354 - accuracy: 0.9851 - f1_score: 0.9548 - val_loss: 0.1829 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 924/10000\n",
      "24/24 [==============================] - 1s 38ms/step - loss: 0.0437 - accuracy: 0.9864 - f1_score: 0.9700 - val_loss: 0.1835 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 925/10000\n",
      "24/24 [==============================] - 1s 37ms/step - loss: 0.0432 - accuracy: 0.9824 - f1_score: 0.9491 - val_loss: 0.1831 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 926/10000\n",
      "24/24 [==============================] - 1s 38ms/step - loss: 0.0408 - accuracy: 0.9837 - f1_score: 0.9574 - val_loss: 0.1830 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 927/10000\n",
      "24/24 [==============================] - 1s 37ms/step - loss: 0.0346 - accuracy: 0.9905 - f1_score: 0.9805 - val_loss: 0.1823 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 928/10000\n",
      "24/24 [==============================] - 1s 36ms/step - loss: 0.0400 - accuracy: 0.9891 - f1_score: 0.9721 - val_loss: 0.1827 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 929/10000\n",
      "24/24 [==============================] - 1s 38ms/step - loss: 0.0319 - accuracy: 0.9891 - f1_score: 0.9693 - val_loss: 0.1828 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 930/10000\n",
      "24/24 [==============================] - 1s 37ms/step - loss: 0.0375 - accuracy: 0.9824 - f1_score: 0.9474 - val_loss: 0.1826 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 931/10000\n",
      "24/24 [==============================] - 1s 36ms/step - loss: 0.0335 - accuracy: 0.9851 - f1_score: 0.9592 - val_loss: 0.1825 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 932/10000\n",
      "24/24 [==============================] - 1s 35ms/step - loss: 0.0334 - accuracy: 0.9919 - f1_score: 0.9820 - val_loss: 0.1822 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 933/10000\n",
      "24/24 [==============================] - 1s 34ms/step - loss: 0.0374 - accuracy: 0.9891 - f1_score: 0.9693 - val_loss: 0.1815 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 934/10000\n",
      "24/24 [==============================] - 1s 35ms/step - loss: 0.0345 - accuracy: 0.9824 - f1_score: 0.9559 - val_loss: 0.1792 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 935/10000\n",
      "24/24 [==============================] - 1s 38ms/step - loss: 0.0367 - accuracy: 0.9824 - f1_score: 0.9489 - val_loss: 0.1793 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 936/10000\n",
      "24/24 [==============================] - 1s 39ms/step - loss: 0.0349 - accuracy: 0.9864 - f1_score: 0.9663 - val_loss: 0.1790 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 937/10000\n",
      "24/24 [==============================] - 1s 39ms/step - loss: 0.0406 - accuracy: 0.9851 - f1_score: 0.9623 - val_loss: 0.1796 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 938/10000\n",
      "24/24 [==============================] - 1s 39ms/step - loss: 0.0405 - accuracy: 0.9837 - f1_score: 0.9599 - val_loss: 0.1795 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 939/10000\n",
      "24/24 [==============================] - 1s 41ms/step - loss: 0.0370 - accuracy: 0.9878 - f1_score: 0.9709 - val_loss: 0.1805 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 940/10000\n",
      "24/24 [==============================] - 1s 38ms/step - loss: 0.0344 - accuracy: 0.9891 - f1_score: 0.9689 - val_loss: 0.1803 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 941/10000\n",
      "24/24 [==============================] - 1s 39ms/step - loss: 0.0356 - accuracy: 0.9891 - f1_score: 0.9687 - val_loss: 0.1803 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 942/10000\n",
      "24/24 [==============================] - 1s 39ms/step - loss: 0.0423 - accuracy: 0.9851 - f1_score: 0.9611 - val_loss: 0.1808 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 943/10000\n",
      "24/24 [==============================] - 1s 40ms/step - loss: 0.0428 - accuracy: 0.9810 - f1_score: 0.9542 - val_loss: 0.1813 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 944/10000\n",
      "24/24 [==============================] - 1s 39ms/step - loss: 0.0326 - accuracy: 0.9891 - f1_score: 0.9661 - val_loss: 0.1819 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 945/10000\n",
      "24/24 [==============================] - 1s 39ms/step - loss: 0.0449 - accuracy: 0.9824 - f1_score: 0.9461 - val_loss: 0.1811 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 946/10000\n",
      "24/24 [==============================] - 1s 40ms/step - loss: 0.0328 - accuracy: 0.9905 - f1_score: 0.9700 - val_loss: 0.1819 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 947/10000\n",
      "24/24 [==============================] - 1s 40ms/step - loss: 0.0327 - accuracy: 0.9864 - f1_score: 0.9567 - val_loss: 0.1801 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 948/10000\n",
      "24/24 [==============================] - 1s 39ms/step - loss: 0.0355 - accuracy: 0.9878 - f1_score: 0.9637 - val_loss: 0.1816 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 949/10000\n",
      "24/24 [==============================] - 1s 41ms/step - loss: 0.0330 - accuracy: 0.9837 - f1_score: 0.9535 - val_loss: 0.1818 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 950/10000\n",
      "24/24 [==============================] - 1s 42ms/step - loss: 0.0345 - accuracy: 0.9864 - f1_score: 0.9630 - val_loss: 0.1821 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 951/10000\n",
      "24/24 [==============================] - 1s 41ms/step - loss: 0.0321 - accuracy: 0.9905 - f1_score: 0.9742 - val_loss: 0.1816 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 952/10000\n",
      "24/24 [==============================] - 1s 40ms/step - loss: 0.0385 - accuracy: 0.9824 - f1_score: 0.9581 - val_loss: 0.1820 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 953/10000\n",
      "24/24 [==============================] - 1s 39ms/step - loss: 0.0499 - accuracy: 0.9851 - f1_score: 0.9688 - val_loss: 0.1827 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 954/10000\n",
      "24/24 [==============================] - 1s 39ms/step - loss: 0.0356 - accuracy: 0.9824 - f1_score: 0.9443 - val_loss: 0.1817 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 955/10000\n",
      "24/24 [==============================] - 1s 41ms/step - loss: 0.0404 - accuracy: 0.9851 - f1_score: 0.9586 - val_loss: 0.1814 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 956/10000\n",
      "24/24 [==============================] - 1s 40ms/step - loss: 0.0361 - accuracy: 0.9837 - f1_score: 0.9567 - val_loss: 0.1813 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 957/10000\n",
      "24/24 [==============================] - 1s 39ms/step - loss: 0.0335 - accuracy: 0.9891 - f1_score: 0.9797 - val_loss: 0.1808 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 958/10000\n",
      "24/24 [==============================] - 1s 38ms/step - loss: 0.0343 - accuracy: 0.9864 - f1_score: 0.9527 - val_loss: 0.1816 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 959/10000\n",
      "24/24 [==============================] - 1s 37ms/step - loss: 0.0316 - accuracy: 0.9864 - f1_score: 0.9592 - val_loss: 0.1819 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 960/10000\n",
      "24/24 [==============================] - 1s 36ms/step - loss: 0.0409 - accuracy: 0.9851 - f1_score: 0.9572 - val_loss: 0.1818 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 961/10000\n",
      "24/24 [==============================] - 1s 35ms/step - loss: 0.0452 - accuracy: 0.9810 - f1_score: 0.9471 - val_loss: 0.1814 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 962/10000\n",
      "24/24 [==============================] - 1s 37ms/step - loss: 0.0351 - accuracy: 0.9878 - f1_score: 0.9636 - val_loss: 0.1824 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 963/10000\n",
      "24/24 [==============================] - 1s 39ms/step - loss: 0.0401 - accuracy: 0.9837 - f1_score: 0.9527 - val_loss: 0.1828 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 964/10000\n",
      "24/24 [==============================] - 1s 40ms/step - loss: 0.0349 - accuracy: 0.9851 - f1_score: 0.9554 - val_loss: 0.1826 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 965/10000\n",
      "24/24 [==============================] - 1s 38ms/step - loss: 0.0334 - accuracy: 0.9864 - f1_score: 0.9605 - val_loss: 0.1822 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 966/10000\n",
      "24/24 [==============================] - 1s 40ms/step - loss: 0.0419 - accuracy: 0.9796 - f1_score: 0.9389 - val_loss: 0.1830 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 967/10000\n",
      "24/24 [==============================] - 1s 40ms/step - loss: 0.0334 - accuracy: 0.9919 - f1_score: 0.9820 - val_loss: 0.1839 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 968/10000\n",
      "24/24 [==============================] - 1s 38ms/step - loss: 0.0360 - accuracy: 0.9878 - f1_score: 0.9604 - val_loss: 0.1813 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 969/10000\n",
      "24/24 [==============================] - 1s 40ms/step - loss: 0.0346 - accuracy: 0.9891 - f1_score: 0.9682 - val_loss: 0.1757 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 970/10000\n",
      "24/24 [==============================] - 1s 38ms/step - loss: 0.0395 - accuracy: 0.9810 - f1_score: 0.9431 - val_loss: 0.1768 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 971/10000\n",
      "24/24 [==============================] - 1s 38ms/step - loss: 0.0424 - accuracy: 0.9796 - f1_score: 0.9490 - val_loss: 0.1783 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 972/10000\n",
      "24/24 [==============================] - 1s 36ms/step - loss: 0.0357 - accuracy: 0.9837 - f1_score: 0.9637 - val_loss: 0.1794 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 973/10000\n",
      "24/24 [==============================] - 1s 36ms/step - loss: 0.0354 - accuracy: 0.9824 - f1_score: 0.9523 - val_loss: 0.1803 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 974/10000\n",
      "24/24 [==============================] - 1s 36ms/step - loss: 0.0460 - accuracy: 0.9810 - f1_score: 0.9613 - val_loss: 0.1800 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 975/10000\n",
      "24/24 [==============================] - 1s 38ms/step - loss: 0.0307 - accuracy: 0.9919 - f1_score: 0.9786 - val_loss: 0.1794 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 976/10000\n",
      "24/24 [==============================] - 1s 36ms/step - loss: 0.0360 - accuracy: 0.9864 - f1_score: 0.9521 - val_loss: 0.1808 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 977/10000\n",
      "24/24 [==============================] - 1s 38ms/step - loss: 0.0351 - accuracy: 0.9891 - f1_score: 0.9697 - val_loss: 0.1802 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 978/10000\n",
      "24/24 [==============================] - 1s 37ms/step - loss: 0.0361 - accuracy: 0.9851 - f1_score: 0.9655 - val_loss: 0.1805 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 979/10000\n",
      "24/24 [==============================] - 1s 37ms/step - loss: 0.0379 - accuracy: 0.9824 - f1_score: 0.9530 - val_loss: 0.1812 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 980/10000\n",
      "24/24 [==============================] - 1s 37ms/step - loss: 0.0313 - accuracy: 0.9905 - f1_score: 0.9668 - val_loss: 0.1808 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 981/10000\n",
      "24/24 [==============================] - 1s 37ms/step - loss: 0.0326 - accuracy: 0.9891 - f1_score: 0.9687 - val_loss: 0.1808 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 982/10000\n",
      "24/24 [==============================] - 1s 39ms/step - loss: 0.0379 - accuracy: 0.9864 - f1_score: 0.9630 - val_loss: 0.1807 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 983/10000\n",
      "24/24 [==============================] - 1s 39ms/step - loss: 0.0333 - accuracy: 0.9864 - f1_score: 0.9598 - val_loss: 0.1808 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 984/10000\n",
      "24/24 [==============================] - 1s 39ms/step - loss: 0.0372 - accuracy: 0.9891 - f1_score: 0.9796 - val_loss: 0.1792 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 985/10000\n",
      "24/24 [==============================] - 1s 38ms/step - loss: 0.0373 - accuracy: 0.9878 - f1_score: 0.9643 - val_loss: 0.1794 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 986/10000\n",
      "24/24 [==============================] - 1s 38ms/step - loss: 0.0345 - accuracy: 0.9864 - f1_score: 0.9630 - val_loss: 0.1795 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 987/10000\n",
      "24/24 [==============================] - 1s 36ms/step - loss: 0.0372 - accuracy: 0.9837 - f1_score: 0.9566 - val_loss: 0.1799 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 988/10000\n",
      "24/24 [==============================] - 1s 39ms/step - loss: 0.0382 - accuracy: 0.9864 - f1_score: 0.9662 - val_loss: 0.1805 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 989/10000\n",
      "24/24 [==============================] - 1s 34ms/step - loss: 0.0400 - accuracy: 0.9851 - f1_score: 0.9655 - val_loss: 0.1805 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 990/10000\n",
      "24/24 [==============================] - 1s 35ms/step - loss: 0.0397 - accuracy: 0.9824 - f1_score: 0.9491 - val_loss: 0.1813 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 991/10000\n",
      "24/24 [==============================] - 1s 35ms/step - loss: 0.0359 - accuracy: 0.9864 - f1_score: 0.9578 - val_loss: 0.1802 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 992/10000\n",
      "24/24 [==============================] - 1s 35ms/step - loss: 0.0348 - accuracy: 0.9864 - f1_score: 0.9591 - val_loss: 0.1815 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 993/10000\n",
      "24/24 [==============================] - 1s 35ms/step - loss: 0.0349 - accuracy: 0.9878 - f1_score: 0.9643 - val_loss: 0.1818 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 994/10000\n",
      "24/24 [==============================] - 1s 36ms/step - loss: 0.0348 - accuracy: 0.9837 - f1_score: 0.9505 - val_loss: 0.1812 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 995/10000\n",
      "24/24 [==============================] - 1s 38ms/step - loss: 0.0332 - accuracy: 0.9891 - f1_score: 0.9733 - val_loss: 0.1813 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 996/10000\n",
      "24/24 [==============================] - 1s 35ms/step - loss: 0.0361 - accuracy: 0.9878 - f1_score: 0.9713 - val_loss: 0.1806 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 997/10000\n",
      "24/24 [==============================] - 1s 40ms/step - loss: 0.0357 - accuracy: 0.9837 - f1_score: 0.9496 - val_loss: 0.1811 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 998/10000\n",
      "24/24 [==============================] - 1s 43ms/step - loss: 0.0343 - accuracy: 0.9878 - f1_score: 0.9712 - val_loss: 0.1807 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 999/10000\n",
      "24/24 [==============================] - 1s 38ms/step - loss: 0.0328 - accuracy: 0.9878 - f1_score: 0.9604 - val_loss: 0.1810 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 1000/10000\n",
      "24/24 [==============================] - 1s 36ms/step - loss: 0.0298 - accuracy: 0.9864 - f1_score: 0.9636 - val_loss: 0.1807 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 1001/10000\n",
      "24/24 [==============================] - 1s 39ms/step - loss: 0.0263 - accuracy: 0.9959 - f1_score: 0.9892 - val_loss: 0.1812 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 1002/10000\n",
      "24/24 [==============================] - 1s 37ms/step - loss: 0.0334 - accuracy: 0.9851 - f1_score: 0.9606 - val_loss: 0.1807 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 1003/10000\n",
      "24/24 [==============================] - 1s 34ms/step - loss: 0.0313 - accuracy: 0.9851 - f1_score: 0.9540 - val_loss: 0.1809 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 1004/10000\n",
      "24/24 [==============================] - 1s 35ms/step - loss: 0.0377 - accuracy: 0.9837 - f1_score: 0.9543 - val_loss: 0.1816 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 1005/10000\n",
      "24/24 [==============================] - 1s 38ms/step - loss: 0.0304 - accuracy: 0.9919 - f1_score: 0.9717 - val_loss: 0.1822 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 1006/10000\n",
      "24/24 [==============================] - 1s 37ms/step - loss: 0.0399 - accuracy: 0.9824 - f1_score: 0.9523 - val_loss: 0.1822 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 1007/10000\n",
      "24/24 [==============================] - 1s 36ms/step - loss: 0.0451 - accuracy: 0.9769 - f1_score: 0.9513 - val_loss: 0.1823 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 1008/10000\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0340 - accuracy: 0.9891 - f1_score: 0.9655 - val_loss: 0.1826 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 1009/10000\n",
      "24/24 [==============================] - 1s 35ms/step - loss: 0.0409 - accuracy: 0.9851 - f1_score: 0.9606 - val_loss: 0.1825 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 1010/10000\n",
      "24/24 [==============================] - 1s 39ms/step - loss: 0.0295 - accuracy: 0.9878 - f1_score: 0.9679 - val_loss: 0.1827 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 1011/10000\n",
      "24/24 [==============================] - 1s 40ms/step - loss: 0.0364 - accuracy: 0.9837 - f1_score: 0.9504 - val_loss: 0.1815 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 1012/10000\n",
      "24/24 [==============================] - 1s 39ms/step - loss: 0.0361 - accuracy: 0.9851 - f1_score: 0.9516 - val_loss: 0.1810 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 1013/10000\n",
      "24/24 [==============================] - 1s 39ms/step - loss: 0.0393 - accuracy: 0.9878 - f1_score: 0.9749 - val_loss: 0.1824 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 1014/10000\n",
      "24/24 [==============================] - 1s 37ms/step - loss: 0.0273 - accuracy: 0.9891 - f1_score: 0.9697 - val_loss: 0.1827 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 1015/10000\n",
      "24/24 [==============================] - 1s 38ms/step - loss: 0.0286 - accuracy: 0.9905 - f1_score: 0.9705 - val_loss: 0.1823 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 1016/10000\n",
      "24/24 [==============================] - 1s 36ms/step - loss: 0.0434 - accuracy: 0.9796 - f1_score: 0.9387 - val_loss: 0.1750 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 1017/10000\n",
      "24/24 [==============================] - 1s 37ms/step - loss: 0.0345 - accuracy: 0.9837 - f1_score: 0.9495 - val_loss: 0.1764 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 1018/10000\n",
      "24/24 [==============================] - 1s 37ms/step - loss: 0.0322 - accuracy: 0.9878 - f1_score: 0.9648 - val_loss: 0.1774 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 1019/10000\n",
      "24/24 [==============================] - 1s 39ms/step - loss: 0.0262 - accuracy: 0.9878 - f1_score: 0.9573 - val_loss: 0.1784 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 1020/10000\n",
      "24/24 [==============================] - 1s 53ms/step - loss: 0.0311 - accuracy: 0.9891 - f1_score: 0.9721 - val_loss: 0.1784 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 1021/10000\n",
      "24/24 [==============================] - 1s 39ms/step - loss: 0.0528 - accuracy: 0.9824 - f1_score: 0.9632 - val_loss: 0.1788 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 1022/10000\n",
      "24/24 [==============================] - 1s 40ms/step - loss: 0.0326 - accuracy: 0.9905 - f1_score: 0.9774 - val_loss: 0.1789 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 1023/10000\n",
      "24/24 [==============================] - 1s 38ms/step - loss: 0.0303 - accuracy: 0.9891 - f1_score: 0.9698 - val_loss: 0.1791 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 1024/10000\n",
      "24/24 [==============================] - 1s 36ms/step - loss: 0.0389 - accuracy: 0.9851 - f1_score: 0.9571 - val_loss: 0.1787 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 1025/10000\n",
      "24/24 [==============================] - 1s 48ms/step - loss: 0.0340 - accuracy: 0.9878 - f1_score: 0.9720 - val_loss: 0.1802 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 1026/10000\n",
      "24/24 [==============================] - 1s 43ms/step - loss: 0.0329 - accuracy: 0.9864 - f1_score: 0.9630 - val_loss: 0.1806 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 1027/10000\n",
      "24/24 [==============================] - 1s 37ms/step - loss: 0.0271 - accuracy: 0.9905 - f1_score: 0.9700 - val_loss: 0.1805 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 1028/10000\n",
      "24/24 [==============================] - 1s 37ms/step - loss: 0.0337 - accuracy: 0.9864 - f1_score: 0.9630 - val_loss: 0.1788 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 1029/10000\n",
      "24/24 [==============================] - 1s 37ms/step - loss: 0.0346 - accuracy: 0.9837 - f1_score: 0.9573 - val_loss: 0.1761 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 1030/10000\n",
      "24/24 [==============================] - 1s 37ms/step - loss: 0.0416 - accuracy: 0.9824 - f1_score: 0.9593 - val_loss: 0.1769 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 1031/10000\n",
      "24/24 [==============================] - 1s 37ms/step - loss: 0.0385 - accuracy: 0.9864 - f1_score: 0.9598 - val_loss: 0.1766 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 1032/10000\n",
      "24/24 [==============================] - 1s 36ms/step - loss: 0.0280 - accuracy: 0.9905 - f1_score: 0.9706 - val_loss: 0.1774 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 1033/10000\n",
      "24/24 [==============================] - 1s 36ms/step - loss: 0.0323 - accuracy: 0.9864 - f1_score: 0.9598 - val_loss: 0.1778 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 1034/10000\n",
      "24/24 [==============================] - 1s 36ms/step - loss: 0.0362 - accuracy: 0.9864 - f1_score: 0.9657 - val_loss: 0.1795 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 1035/10000\n",
      "24/24 [==============================] - 1s 37ms/step - loss: 0.0286 - accuracy: 0.9919 - f1_score: 0.9712 - val_loss: 0.1797 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 1036/10000\n",
      "24/24 [==============================] - 1s 36ms/step - loss: 0.0346 - accuracy: 0.9864 - f1_score: 0.9636 - val_loss: 0.1798 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 1037/10000\n",
      "24/24 [==============================] - 1s 36ms/step - loss: 0.0370 - accuracy: 0.9878 - f1_score: 0.9720 - val_loss: 0.1813 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 1038/10000\n",
      "24/24 [==============================] - 1s 36ms/step - loss: 0.0279 - accuracy: 0.9878 - f1_score: 0.9604 - val_loss: 0.1803 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 1039/10000\n",
      "24/24 [==============================] - 1s 38ms/step - loss: 0.0338 - accuracy: 0.9864 - f1_score: 0.9592 - val_loss: 0.1808 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 1040/10000\n",
      "24/24 [==============================] - 1s 43ms/step - loss: 0.0378 - accuracy: 0.9824 - f1_score: 0.9530 - val_loss: 0.1823 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 1041/10000\n",
      "24/24 [==============================] - 1s 39ms/step - loss: 0.0345 - accuracy: 0.9891 - f1_score: 0.9764 - val_loss: 0.1811 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 1042/10000\n",
      "24/24 [==============================] - 1s 38ms/step - loss: 0.0315 - accuracy: 0.9837 - f1_score: 0.9456 - val_loss: 0.1818 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 1043/10000\n",
      "24/24 [==============================] - 1s 38ms/step - loss: 0.0304 - accuracy: 0.9864 - f1_score: 0.9604 - val_loss: 0.1820 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 1044/10000\n",
      "24/24 [==============================] - 1s 40ms/step - loss: 0.0358 - accuracy: 0.9864 - f1_score: 0.9630 - val_loss: 0.1822 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 1045/10000\n",
      "24/24 [==============================] - 1s 40ms/step - loss: 0.0369 - accuracy: 0.9796 - f1_score: 0.9387 - val_loss: 0.1827 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 1046/10000\n",
      "24/24 [==============================] - 1s 39ms/step - loss: 0.0477 - accuracy: 0.9810 - f1_score: 0.9580 - val_loss: 0.1825 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 1047/10000\n",
      "24/24 [==============================] - 1s 37ms/step - loss: 0.0393 - accuracy: 0.9810 - f1_score: 0.9518 - val_loss: 0.1828 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 1048/10000\n",
      "24/24 [==============================] - 1s 39ms/step - loss: 0.0308 - accuracy: 0.9891 - f1_score: 0.9617 - val_loss: 0.1809 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 1049/10000\n",
      "24/24 [==============================] - 1s 38ms/step - loss: 0.0274 - accuracy: 0.9878 - f1_score: 0.9648 - val_loss: 0.1816 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 1050/10000\n",
      "24/24 [==============================] - 1s 37ms/step - loss: 0.0388 - accuracy: 0.9824 - f1_score: 0.9475 - val_loss: 0.1823 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 1051/10000\n",
      "24/24 [==============================] - 1s 36ms/step - loss: 0.0414 - accuracy: 0.9851 - f1_score: 0.9654 - val_loss: 0.1836 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 1052/10000\n",
      "24/24 [==============================] - 1s 36ms/step - loss: 0.0296 - accuracy: 0.9905 - f1_score: 0.9673 - val_loss: 0.1834 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 1053/10000\n",
      "24/24 [==============================] - 1s 38ms/step - loss: 0.0330 - accuracy: 0.9837 - f1_score: 0.9580 - val_loss: 0.1837 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 1054/10000\n",
      "24/24 [==============================] - 1s 36ms/step - loss: 0.0312 - accuracy: 0.9864 - f1_score: 0.9585 - val_loss: 0.1837 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 1055/10000\n",
      "24/24 [==============================] - 1s 38ms/step - loss: 0.0349 - accuracy: 0.9878 - f1_score: 0.9746 - val_loss: 0.1839 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 1056/10000\n",
      "24/24 [==============================] - 1s 37ms/step - loss: 0.0284 - accuracy: 0.9891 - f1_score: 0.9687 - val_loss: 0.1826 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 1057/10000\n",
      "24/24 [==============================] - 1s 37ms/step - loss: 0.0348 - accuracy: 0.9878 - f1_score: 0.9648 - val_loss: 0.1827 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 1058/10000\n",
      "24/24 [==============================] - 1s 35ms/step - loss: 0.0357 - accuracy: 0.9851 - f1_score: 0.9579 - val_loss: 0.1824 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 1059/10000\n",
      "24/24 [==============================] - 1s 35ms/step - loss: 0.0306 - accuracy: 0.9878 - f1_score: 0.9643 - val_loss: 0.1827 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 1060/10000\n",
      "24/24 [==============================] - 1s 34ms/step - loss: 0.0298 - accuracy: 0.9837 - f1_score: 0.9604 - val_loss: 0.1812 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 1061/10000\n",
      "24/24 [==============================] - 1s 34ms/step - loss: 0.0391 - accuracy: 0.9864 - f1_score: 0.9597 - val_loss: 0.1809 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 1062/10000\n",
      "24/24 [==============================] - 1s 35ms/step - loss: 0.0369 - accuracy: 0.9837 - f1_score: 0.9534 - val_loss: 0.1807 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 1063/10000\n",
      "24/24 [==============================] - 1s 35ms/step - loss: 0.0326 - accuracy: 0.9864 - f1_score: 0.9635 - val_loss: 0.1810 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 1064/10000\n",
      "24/24 [==============================] - 1s 35ms/step - loss: 0.0331 - accuracy: 0.9878 - f1_score: 0.9648 - val_loss: 0.1816 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 1065/10000\n",
      "24/24 [==============================] - 1s 35ms/step - loss: 0.0315 - accuracy: 0.9891 - f1_score: 0.9688 - val_loss: 0.1809 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 1066/10000\n",
      "24/24 [==============================] - 1s 35ms/step - loss: 0.0340 - accuracy: 0.9891 - f1_score: 0.9688 - val_loss: 0.1804 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 1067/10000\n",
      "24/24 [==============================] - 1s 34ms/step - loss: 0.0355 - accuracy: 0.9837 - f1_score: 0.9543 - val_loss: 0.1766 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 1068/10000\n",
      "24/24 [==============================] - 1s 35ms/step - loss: 0.0406 - accuracy: 0.9878 - f1_score: 0.9709 - val_loss: 0.1781 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 1069/10000\n",
      "24/24 [==============================] - 1s 35ms/step - loss: 0.0453 - accuracy: 0.9796 - f1_score: 0.9417 - val_loss: 0.1796 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 1070/10000\n",
      "24/24 [==============================] - 1s 35ms/step - loss: 0.0322 - accuracy: 0.9851 - f1_score: 0.9565 - val_loss: 0.1805 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 1071/10000\n",
      "24/24 [==============================] - 1s 36ms/step - loss: 0.0302 - accuracy: 0.9864 - f1_score: 0.9636 - val_loss: 0.1804 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 1072/10000\n",
      "24/24 [==============================] - 1s 35ms/step - loss: 0.0339 - accuracy: 0.9891 - f1_score: 0.9655 - val_loss: 0.1800 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 1073/10000\n",
      "24/24 [==============================] - 1s 35ms/step - loss: 0.0264 - accuracy: 0.9891 - f1_score: 0.9623 - val_loss: 0.1801 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 1074/10000\n",
      "24/24 [==============================] - 1s 34ms/step - loss: 0.0324 - accuracy: 0.9878 - f1_score: 0.9675 - val_loss: 0.1801 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 1075/10000\n",
      "24/24 [==============================] - 1s 35ms/step - loss: 0.0277 - accuracy: 0.9905 - f1_score: 0.9700 - val_loss: 0.1811 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 1076/10000\n",
      "24/24 [==============================] - 1s 35ms/step - loss: 0.0365 - accuracy: 0.9878 - f1_score: 0.9675 - val_loss: 0.1813 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 1077/10000\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0280 - accuracy: 0.9891 - f1_score: 0.9721 - val_loss: 0.1806 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 1078/10000\n",
      "24/24 [==============================] - 1s 34ms/step - loss: 0.0329 - accuracy: 0.9851 - f1_score: 0.9580 - val_loss: 0.1806 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 1079/10000\n",
      "24/24 [==============================] - 1s 35ms/step - loss: 0.0265 - accuracy: 0.9919 - f1_score: 0.9750 - val_loss: 0.1809 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 1080/10000\n",
      "24/24 [==============================] - 1s 35ms/step - loss: 0.0352 - accuracy: 0.9878 - f1_score: 0.9637 - val_loss: 0.1814 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 1081/10000\n",
      "24/24 [==============================] - 1s 35ms/step - loss: 0.0334 - accuracy: 0.9864 - f1_score: 0.9598 - val_loss: 0.1822 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 1082/10000\n",
      "24/24 [==============================] - 1s 34ms/step - loss: 0.0334 - accuracy: 0.9891 - f1_score: 0.9693 - val_loss: 0.1826 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 1083/10000\n",
      "24/24 [==============================] - 1s 35ms/step - loss: 0.0261 - accuracy: 0.9891 - f1_score: 0.9623 - val_loss: 0.1823 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 1084/10000\n",
      "24/24 [==============================] - 1s 35ms/step - loss: 0.0336 - accuracy: 0.9905 - f1_score: 0.9737 - val_loss: 0.1817 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 1085/10000\n",
      "24/24 [==============================] - 1s 35ms/step - loss: 0.0453 - accuracy: 0.9837 - f1_score: 0.9648 - val_loss: 0.1811 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 1086/10000\n",
      "24/24 [==============================] - 1s 35ms/step - loss: 0.0283 - accuracy: 0.9864 - f1_score: 0.9567 - val_loss: 0.1819 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 1087/10000\n",
      "24/24 [==============================] - 1s 37ms/step - loss: 0.0404 - accuracy: 0.9837 - f1_score: 0.9572 - val_loss: 0.1809 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 1088/10000\n",
      "24/24 [==============================] - 1s 37ms/step - loss: 0.0347 - accuracy: 0.9891 - f1_score: 0.9759 - val_loss: 0.1818 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 1089/10000\n",
      "24/24 [==============================] - 1s 35ms/step - loss: 0.0298 - accuracy: 0.9891 - f1_score: 0.9655 - val_loss: 0.1814 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 1090/10000\n",
      "24/24 [==============================] - 1s 37ms/step - loss: 0.0294 - accuracy: 0.9864 - f1_score: 0.9560 - val_loss: 0.1827 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 1091/10000\n",
      "24/24 [==============================] - 1s 36ms/step - loss: 0.0278 - accuracy: 0.9905 - f1_score: 0.9705 - val_loss: 0.1823 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 1092/10000\n",
      "24/24 [==============================] - 1s 48ms/step - loss: 0.0299 - accuracy: 0.9905 - f1_score: 0.9733 - val_loss: 0.1825 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 1093/10000\n",
      "24/24 [==============================] - 1s 49ms/step - loss: 0.0394 - accuracy: 0.9837 - f1_score: 0.9496 - val_loss: 0.1819 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 1094/10000\n",
      "24/24 [==============================] - 1s 49ms/step - loss: 0.0291 - accuracy: 0.9891 - f1_score: 0.9617 - val_loss: 0.1822 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 1095/10000\n",
      "24/24 [==============================] - 1s 43ms/step - loss: 0.0405 - accuracy: 0.9864 - f1_score: 0.9662 - val_loss: 0.1817 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 1096/10000\n",
      "24/24 [==============================] - 1s 52ms/step - loss: 0.0281 - accuracy: 0.9891 - f1_score: 0.9655 - val_loss: 0.1808 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 1097/10000\n",
      "24/24 [==============================] - 1s 43ms/step - loss: 0.0336 - accuracy: 0.9864 - f1_score: 0.9567 - val_loss: 0.1808 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 1098/10000\n",
      "24/24 [==============================] - 1s 39ms/step - loss: 0.0342 - accuracy: 0.9851 - f1_score: 0.9655 - val_loss: 0.1811 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 1099/10000\n",
      "24/24 [==============================] - 1s 38ms/step - loss: 0.0283 - accuracy: 0.9891 - f1_score: 0.9721 - val_loss: 0.1814 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 1100/10000\n",
      "24/24 [==============================] - 1s 42ms/step - loss: 0.0369 - accuracy: 0.9851 - f1_score: 0.9586 - val_loss: 0.1820 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 1101/10000\n",
      "24/24 [==============================] - 1s 40ms/step - loss: 0.0346 - accuracy: 0.9837 - f1_score: 0.9535 - val_loss: 0.1818 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 1102/10000\n",
      "24/24 [==============================] - 1s 39ms/step - loss: 0.0276 - accuracy: 0.9851 - f1_score: 0.9516 - val_loss: 0.1816 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 1103/10000\n",
      "24/24 [==============================] - 1s 42ms/step - loss: 0.0368 - accuracy: 0.9864 - f1_score: 0.9625 - val_loss: 0.1819 - val_accuracy: 0.9506 - val_f1_score: 0.8892\n",
      "Epoch 1104/10000\n",
      "13/24 [===============>..............] - ETA: 0s - loss: 0.0257 - accuracy: 0.9928 - f1_score: 0.9791"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[52], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m history_best \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_best\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Plot the losses\u001b[39;00m\n\u001b[1;32m      5\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(history_best\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m'\u001b[39m], label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTraining Loss\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/Desktop/ml_tokamak/venv/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/Desktop/ml_tokamak/venv/lib/python3.10/site-packages/keras/src/engine/training.py:1807\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1799\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1800\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1801\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1804\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   1805\u001b[0m ):\n\u001b[1;32m   1806\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1807\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1808\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1809\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/Desktop/ml_tokamak/venv/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/Desktop/ml_tokamak/venv/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:832\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    829\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    831\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 832\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    834\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    835\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/Desktop/ml_tokamak/venv/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:868\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    865\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    866\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    867\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 868\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    869\u001b[0m \u001b[43m      \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_config\u001b[49m\n\u001b[1;32m    870\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    871\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    872\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    873\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    874\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/Desktop/ml_tokamak/venv/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/ml_tokamak/venv/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1323\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1319\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1320\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1321\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1322\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1323\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1324\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1325\u001b[0m     args,\n\u001b[1;32m   1326\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1327\u001b[0m     executing_eagerly)\n\u001b[1;32m   1328\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/Desktop/ml_tokamak/venv/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[0;32m~/Desktop/ml_tokamak/venv/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[1;32m    261\u001b[0m     )\n",
      "File \u001b[0;32m~/Desktop/ml_tokamak/venv/lib/python3.10/site-packages/tensorflow/python/eager/context.py:1486\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1484\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1485\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1486\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1487\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1488\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1489\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1490\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1491\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1492\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1493\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1494\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1495\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1496\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1500\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1501\u001b[0m   )\n",
      "File \u001b[0;32m~/Desktop/ml_tokamak/venv/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "history_best = model_best.fit(X_train, y_train, epochs=10000, validation_data=(X_test, y_test))\n",
    "\n",
    "# Plot the losses\n",
    "plt.plot(history_best.history['loss'], label='Training Loss')\n",
    "plt.plot(history_best.history['val_loss'], label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Print the F1-score on the validation set\n",
    "_, _, f1_score_best = model_best.evaluate(X_test, y_test)\n",
    "print('F1-score on validation set:', f1_score_best)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "include_colab_link": true,
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
